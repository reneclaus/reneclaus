{"data": [{"a": [0.0, 2.0264381170272827, 1.8388928174972534, 1.6580923795700073, 1.330065369606018, 1.8188880681991577, 1.3494199514389038, 1.5201152563095093, 1.6687091588974, 1.2506784200668335, 1.2561920881271362, 1.496179461479187, 1.523908019065857, 1.5711787939071655, 1.907147765159607, 1.9683879613876343, 1.9901427030563354, 1.4956005811691284, 1.7961753606796265, 1.4219220876693726, 1.7162712812423706, 1.3370801210403442, 1.5431731939315796, 2.090752959251404, 1.6572378873825073, 1.4578763246536255, 1.6294163465499878, 1.3621047735214233, 1.3378368616104126, 1.6716755628585815, 1.9321364164352417, 1.8857945203781128, 1.2519539594650269, 1.8053244352340698, 1.5437663793563843, 1.4974762201309204, 1.729960322380066, 1.3354028463363647, 1.4883252382278442, 1.8653115034103394, 1.460797667503357, 1.5949491262435913, 2.0469497442245483, 1.5666571855545044, 1.72467839717865, 1.4746946096420288, 1.5740422010421753, 1.1340312957763672, 1.0462679862976074, 1.591391682624817, 1.314470648765564, 1.4516104459762573, 1.390825629234314, 1.5219563245773315, 1.8838833570480347, 1.2387596368789673, 1.7601608037948608, 2.205452799797058, 1.6817721128463745, 1.8223923444747925, 1.9196094274520874, 2.063369631767273, 1.787047266960144, 1.2990902662277222, 1.5085395574569702, 1.7126988172531128, 1.5467075109481812, 1.9512075185775757, 1.535183072090149, 1.499367594718933, 1.7551010847091675, 1.9848073720932007, 1.7177637815475464, 1.6668585538864136, 1.8292282819747925, 1.597800612449646, 2.293157458305359, 1.6165188550949097, 1.2723468542099, 1.3061593770980835, 1.641060709953308, 1.7363461256027222, 1.8949612379074097, 2.079105257987976, 1.9183567762374878, 1.6777962446212769, 1.7341550588607788, 1.8200949430465698, 1.912178874015808, 1.7591909170150757, 1.5237005949020386, 1.3891721963882446, 2.0519717931747437, 1.9226006269454956, 2.1311367750167847, 1.792542815208435, 1.889180064201355, 1.6156362295150757, 2.2291702032089233, 1.6264804601669312, 1.97752845287323, 1.8916157484054565, 1.5408858060836792, 1.7316664457321167, 1.7892426252365112, 2.16884982585907, 2.12527072429657, 1.8196381330490112, 1.9620498418807983, 2.0913275480270386, 1.4938071966171265, 1.105833888053894, 1.9344228506088257, 2.17274272441864, 1.7365058660507202, 1.9556864500045776, 2.0908931493759155, 1.7140744924545288, 1.622517466545105, 1.5338162183761597, 1.6808613538742065, 1.6970051527023315, 1.375792384147644, 1.425061583518982, 1.2568596601486206, 1.799420714378357, 1.8198355436325073, 1.7824205160140991, 1.927841067314148, 1.2623809576034546, 1.4786328077316284, 1.5007232427597046, 1.7346605062484741, 2.025098204612732, 2.0383681058883667, 1.7826279401779175, 2.161758780479431, 1.8481720685958862, 2.1540035009384155, 2.180721640586853, 2.0070470571517944, 2.3280805349349976, 1.8939660787582397, 2.051547408103943, 1.738329291343689, 2.1218308210372925, 2.1658581495285034, 2.073889136314392, 1.9844998121261597, 2.438413977622986, 2.5179442167282104, 2.0620235204696655, 2.13455331325531, 2.6077173948287964, 2.2848886251449585, 2.148577094078064, 2.0827401876449585, 2.3675225973129272, 2.017659068107605, 2.0870150327682495, 2.098495841026306, 2.362789034843445, 2.0462039709091187, 1.8531936407089233, 1.8284605741500854, 2.1098231077194214, 2.3672159910202026, 2.3338812589645386, 2.0466655492782593, 1.943630576133728], "b": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "c": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "hovertemplate": "<b>%{hovertext}</b><br><br>sort_idx=0<br>a=%{a}<br>b=%{b}<br>alibi=%{c}<br>prob=%{marker.color}<extra></extra>", "hovertext": ["Token: 0 (By)<br>Attend to token: 0 (By)<br>Tokens in past: 0<br>Probability: 1.0000<br>Alibi: 0.0<br>Attention: -2.5928<br>Bias: 3.4200", "Token: 1 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 1<br>Probability: 0.9937<br>Alibi: 0.0<br>Attention: -0.5663<br>Bias: 3.4200", "Token: 2 ( end)<br>Attend to token: 0 (By)<br>Tokens in past: 2<br>Probability: 0.9960<br>Alibi: 0.0<br>Attention: -0.7539<br>Bias: 3.4200", "Token: 3 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 3<br>Probability: 0.9839<br>Alibi: 0.0<br>Attention: -0.9347<br>Bias: 3.4200", "Token: 4 ( 2014)<br>Attend to token: 0 (By)<br>Tokens in past: 4<br>Probability: 0.9902<br>Alibi: 0.0<br>Attention: -1.2627<br>Bias: 3.4200", "Token: 5 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 5<br>Probability: 0.9896<br>Alibi: 0.0<br>Attention: -0.7739<br>Bias: 3.4200", "Token: 6 ( we)<br>Attend to token: 0 (By)<br>Tokens in past: 6<br>Probability: 0.9779<br>Alibi: 0.0<br>Attention: -1.2433<br>Bias: 3.4200", "Token: 7 ( plan)<br>Attend to token: 0 (By)<br>Tokens in past: 7<br>Probability: 0.9872<br>Alibi: 0.0<br>Attention: -1.0726<br>Bias: 3.4200", "Token: 8 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 8<br>Probability: 0.9757<br>Alibi: 0.0<br>Attention: -0.9240<br>Bias: 3.4200", "Token: 9 ( rev)<br>Attend to token: 0 (By)<br>Tokens in past: 9<br>Probability: 0.9607<br>Alibi: 0.0<br>Attention: -1.3421<br>Bias: 3.4200", "Token: 10 (amp)<br>Attend to token: 0 (By)<br>Tokens in past: 10<br>Probability: 0.9781<br>Alibi: 0.0<br>Attention: -1.3366<br>Bias: 3.4200", "Token: 11 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 11<br>Probability: 0.9748<br>Alibi: 0.0<br>Attention: -1.0966<br>Bias: 3.4200", "Token: 12 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 12<br>Probability: 0.9748<br>Alibi: 0.0<br>Attention: -1.0688<br>Bias: 3.4200", "Token: 13 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 13<br>Probability: 0.9606<br>Alibi: 0.0<br>Attention: -1.0216<br>Bias: 3.4200", "Token: 14 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 14<br>Probability: 0.9852<br>Alibi: 0.0<br>Attention: -0.6856<br>Bias: 3.4200", "Token: 15 ( disease)<br>Attend to token: 0 (By)<br>Tokens in past: 15<br>Probability: 0.9827<br>Alibi: 0.0<br>Attention: -0.6244<br>Bias: 3.4200", "Token: 16 ( prevention)<br>Attend to token: 0 (By)<br>Tokens in past: 16<br>Probability: 0.9689<br>Alibi: 0.0<br>Attention: -0.6026<br>Bias: 3.4200", "Token: 17 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 17<br>Probability: 0.9445<br>Alibi: 0.0<br>Attention: -1.0972<br>Bias: 3.4200", "Token: 18 ( program)<br>Attend to token: 0 (By)<br>Tokens in past: 18<br>Probability: 0.9768<br>Alibi: 0.0<br>Attention: -0.7966<br>Bias: 3.4200", "Token: 19 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 19<br>Probability: 0.9596<br>Alibi: 0.0<br>Attention: -1.1708<br>Bias: 3.4200", "Token: 20 ( which)<br>Attend to token: 0 (By)<br>Tokens in past: 20<br>Probability: 0.9351<br>Alibi: 0.0<br>Attention: -0.8765<br>Bias: 3.4200", "Token: 21 ( was)<br>Attend to token: 0 (By)<br>Tokens in past: 21<br>Probability: 0.9535<br>Alibi: 0.0<br>Attention: -1.2557<br>Bias: 3.4200", "Token: 22 ( suspended)<br>Attend to token: 0 (By)<br>Tokens in past: 22<br>Probability: 0.9575<br>Alibi: 0.0<br>Attention: -1.0496<br>Bias: 3.4200", "Token: 23 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 23<br>Probability: 0.9452<br>Alibi: 0.0<br>Attention: -0.5020<br>Bias: 3.4200", "Token: 24 ( September)<br>Attend to token: 0 (By)<br>Tokens in past: 24<br>Probability: 0.8238<br>Alibi: 0.0<br>Attention: -0.9355<br>Bias: 3.4200", "Token: 25 ( 2013)<br>Attend to token: 0 (By)<br>Tokens in past: 25<br>Probability: 0.9150<br>Alibi: 0.0<br>Attention: -1.1349<br>Bias: 3.4200", "Token: 26 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 26<br>Probability: 0.9142<br>Alibi: 0.0<br>Attention: -0.9633<br>Bias: 3.4200", "Token: 27 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 27<br>Probability: 0.8937<br>Alibi: 0.0<br>Attention: -1.2306<br>Bias: 3.4200", "Token: 28 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 28<br>Probability: 0.9503<br>Alibi: 0.0<br>Attention: -1.2549<br>Bias: 3.4200", "Token: 29 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 29<br>Probability: 0.9701<br>Alibi: 0.0<br>Attention: -0.9211<br>Bias: 3.4200", "Token: 30 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 30<br>Probability: 0.9787<br>Alibi: 0.0<br>Attention: -0.6606<br>Bias: 3.4200", "Token: 31 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 31<br>Probability: 0.9683<br>Alibi: 0.0<br>Attention: -0.7070<br>Bias: 3.4200", "Token: 32 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 32<br>Probability: 0.9305<br>Alibi: 0.0<br>Attention: -1.3408<br>Bias: 3.4200", "Token: 33 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 33<br>Probability: 0.9234<br>Alibi: 0.0<br>Attention: -0.7874<br>Bias: 3.4200", "Token: 34 ( at)<br>Attend to token: 0 (By)<br>Tokens in past: 34<br>Probability: 0.9479<br>Alibi: 0.0<br>Attention: -1.0490<br>Bias: 3.4200", "Token: 35 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 35<br>Probability: 0.9388<br>Alibi: 0.0<br>Attention: -1.0953<br>Bias: 3.4200", "Token: 36 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 36<br>Probability: 0.9628<br>Alibi: 0.0<br>Attention: -0.8628<br>Bias: 3.4200", "Token: 37 ( centers)<br>Attend to token: 0 (By)<br>Tokens in past: 37<br>Probability: 0.9384<br>Alibi: 0.0<br>Attention: -1.2574<br>Bias: 3.4200", "Token: 38 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 38<br>Probability: 0.9159<br>Alibi: 0.0<br>Attention: -1.1044<br>Bias: 3.4200", "Token: 39 ( group)<br>Attend to token: 0 (By)<br>Tokens in past: 39<br>Probability: 0.9533<br>Alibi: 0.0<br>Attention: -0.7274<br>Bias: 3.4200", "Token: 40 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 40<br>Probability: 0.9116<br>Alibi: 0.0<br>Attention: -1.1320<br>Bias: 3.4200", "Token: 41 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 41<br>Probability: 0.9431<br>Alibi: 0.0<br>Attention: -0.9978<br>Bias: 3.4200", "Token: 42 ( specific)<br>Attend to token: 0 (By)<br>Tokens in past: 42<br>Probability: 0.9278<br>Alibi: 0.0<br>Attention: -0.5458<br>Bias: 3.4200", "Token: 43 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 43<br>Probability: 0.9278<br>Alibi: 0.0<br>Attention: -1.0261<br>Bias: 3.4200", "Token: 44 ( ()<br>Attend to token: 0 (By)<br>Tokens in past: 44<br>Probability: 0.9406<br>Alibi: 0.0<br>Attention: -0.8681<br>Bias: 3.4200", "Token: 45 (Di)<br>Attend to token: 0 (By)<br>Tokens in past: 45<br>Probability: 0.9536<br>Alibi: 0.0<br>Attention: -1.1181<br>Bias: 3.4200", "Token: 46 (abetes)<br>Attend to token: 0 (By)<br>Tokens in past: 46<br>Probability: 0.9187<br>Alibi: 0.0<br>Attention: -1.0187<br>Bias: 3.4200", "Token: 47 (,.)<br>Attend to token: 0 (By)<br>Tokens in past: 47<br>Probability: 0.9184<br>Alibi: 0.0<br>Attention: -1.4587<br>Bias: 3.4200", "Token: 48 ( Hy)<br>Attend to token: 0 (By)<br>Tokens in past: 48<br>Probability: 0.9184<br>Alibi: 0.0<br>Attention: -1.5465<br>Bias: 3.4200", "Token: 49 (pert)<br>Attend to token: 0 (By)<br>Tokens in past: 49<br>Probability: 0.9339<br>Alibi: 0.0<br>Attention: -1.0014<br>Bias: 3.4200", "Token: 50 (ension)<br>Attend to token: 0 (By)<br>Tokens in past: 50<br>Probability: 0.8986<br>Alibi: 0.0<br>Attention: -1.2783<br>Bias: 3.4200", "Token: 51 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 51<br>Probability: 0.9169<br>Alibi: 0.0<br>Attention: -1.1411<br>Bias: 3.4200", "Token: 52 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 52<br>Probability: 0.9312<br>Alibi: 0.0<br>Attention: -1.2019<br>Bias: 3.4200", "Token: 53 (.),)<br>Attend to token: 0 (By)<br>Tokens in past: 53<br>Probability: 0.9032<br>Alibi: 0.0<br>Attention: -1.0708<br>Bias: 3.4200", "Token: 54 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 54<br>Probability: 0.9156<br>Alibi: 0.0<br>Attention: -0.7089<br>Bias: 3.4200", "Token: 55 ( well)<br>Attend to token: 0 (By)<br>Tokens in past: 55<br>Probability: 0.8945<br>Alibi: 0.0<br>Attention: -1.3540<br>Bias: 3.4200", "Token: 56 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 56<br>Probability: 0.9358<br>Alibi: 0.0<br>Attention: -0.8326<br>Bias: 3.4200", "Token: 57 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 57<br>Probability: 0.9717<br>Alibi: 0.0<br>Attention: -0.3873<br>Bias: 3.4200", "Token: 58 ( forums)<br>Attend to token: 0 (By)<br>Tokens in past: 58<br>Probability: 0.8802<br>Alibi: 0.0<br>Attention: -0.9110<br>Bias: 3.4200", "Token: 59 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 59<br>Probability: 0.9100<br>Alibi: 0.0<br>Attention: -0.7704<br>Bias: 3.4200", "Token: 60 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 60<br>Probability: 0.9669<br>Alibi: 0.0<br>Attention: -0.6731<br>Bias: 3.4200", "Token: 61 ( fair)<br>Attend to token: 0 (By)<br>Tokens in past: 61<br>Probability: 0.9339<br>Alibi: 0.0<br>Attention: -0.5294<br>Bias: 3.4200", "Token: 62 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 62<br>Probability: 0.8881<br>Alibi: 0.0<br>Attention: -0.8057<br>Bias: 3.4200", "Token: 63 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 63<br>Probability: 0.8359<br>Alibi: 0.0<br>Attention: -1.2937<br>Bias: 3.4200", "Token: 64 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 64<br>Probability: 0.9179<br>Alibi: 0.0<br>Attention: -1.0842<br>Bias: 3.4200", "Token: 65 ( recruit)<br>Attend to token: 0 (By)<br>Tokens in past: 65<br>Probability: 0.9345<br>Alibi: 0.0<br>Attention: -0.8801<br>Bias: 3.4200", "Token: 66 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 66<br>Probability: 0.9263<br>Alibi: 0.0<br>Attention: -1.0460<br>Bias: 3.4200", "Token: 67 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 67<br>Probability: 0.9605<br>Alibi: 0.0<br>Attention: -0.6415<br>Bias: 3.4200", "Token: 68 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 68<br>Probability: 0.8763<br>Alibi: 0.0<br>Attention: -1.0576<br>Bias: 3.4200", "Token: 69 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 69<br>Probability: 0.8989<br>Alibi: 0.0<br>Attention: -1.0934<br>Bias: 3.4200", "Token: 70 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 70<br>Probability: 0.9116<br>Alibi: 0.0<br>Attention: -0.8377<br>Bias: 3.4200", "Token: 71 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 71<br>Probability: 0.9185<br>Alibi: 0.0<br>Attention: -0.6079<br>Bias: 3.4200", "Token: 72 ( assessment)<br>Attend to token: 0 (By)<br>Tokens in past: 72<br>Probability: 0.7887<br>Alibi: 0.0<br>Attention: -0.8750<br>Bias: 3.4200", "Token: 73 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 73<br>Probability: 0.8937<br>Alibi: 0.0<br>Attention: -0.9259<br>Bias: 3.4200", "Token: 74 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 74<br>Probability: 0.8914<br>Alibi: 0.0<br>Attention: -0.7635<br>Bias: 3.4200", "Token: 75 ( area)<br>Attend to token: 0 (By)<br>Tokens in past: 75<br>Probability: 0.8358<br>Alibi: 0.0<br>Attention: -0.9950<br>Bias: 3.4200", "Token: 76 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 76<br>Probability: 0.9467<br>Alibi: 0.0<br>Attention: -0.2996<br>Bias: 3.4200", "Token: 77 ( intervention)<br>Attend to token: 0 (By)<br>Tokens in past: 77<br>Probability: 0.8599<br>Alibi: 0.0<br>Attention: -0.9762<br>Bias: 3.4200", "Token: 78 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 78<br>Probability: 0.8505<br>Alibi: 0.0<br>Attention: -1.3204<br>Bias: 3.4200", "Token: 79 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 79<br>Probability: 0.8540<br>Alibi: 0.0<br>Attention: -1.2866<br>Bias: 3.4200", "Token: 80 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 80<br>Probability: 0.9155<br>Alibi: 0.0<br>Attention: -0.9517<br>Bias: 3.4200", "Token: 81 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 81<br>Probability: 0.9109<br>Alibi: 0.0<br>Attention: -0.8564<br>Bias: 3.4200", "Token: 82 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 82<br>Probability: 0.9469<br>Alibi: 0.0<br>Attention: -0.6978<br>Bias: 3.4200", "Token: 83 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 83<br>Probability: 0.9221<br>Alibi: 0.0<br>Attention: -0.5136<br>Bias: 3.4200", "Token: 84 ( economic)<br>Attend to token: 0 (By)<br>Tokens in past: 84<br>Probability: 0.9102<br>Alibi: 0.0<br>Attention: -0.6744<br>Bias: 3.4200", "Token: 85 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 85<br>Probability: 0.8869<br>Alibi: 0.0<br>Attention: -0.9150<br>Bias: 3.4200", "Token: 86 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 86<br>Probability: 0.8351<br>Alibi: 0.0<br>Attention: -0.8586<br>Bias: 3.4200", "Token: 87 ( educate)<br>Attend to token: 0 (By)<br>Tokens in past: 87<br>Probability: 0.9352<br>Alibi: 0.0<br>Attention: -0.7727<br>Bias: 3.4200", "Token: 88 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 88<br>Probability: 0.9409<br>Alibi: 0.0<br>Attention: -0.6806<br>Bias: 3.4200", "Token: 89 ( encourage)<br>Attend to token: 0 (By)<br>Tokens in past: 89<br>Probability: 0.9471<br>Alibi: 0.0<br>Attention: -0.8336<br>Bias: 3.4200", "Token: 90 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 90<br>Probability: 0.8394<br>Alibi: 0.0<br>Attention: -1.0691<br>Bias: 3.4200", "Token: 91 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 91<br>Probability: 0.8866<br>Alibi: 0.0<br>Attention: -1.2036<br>Bias: 3.4200", "Token: 92 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 92<br>Probability: 0.9316<br>Alibi: 0.0<br>Attention: -0.5408<br>Bias: 3.4200", "Token: 93 ( preventive)<br>Attend to token: 0 (By)<br>Tokens in past: 93<br>Probability: 0.8628<br>Alibi: 0.0<br>Attention: -0.6702<br>Bias: 3.4200", "Token: 94 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 94<br>Probability: 0.9221<br>Alibi: 0.0<br>Attention: -0.4616<br>Bias: 3.4200", "Token: 95 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 95<br>Probability: 0.8601<br>Alibi: 0.0<br>Attention: -0.8002<br>Bias: 3.4200", "Token: 96 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 96<br>Probability: 0.8659<br>Alibi: 0.0<br>Attention: -0.7036<br>Bias: 3.4200", "Token: 97 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 97<br>Probability: 0.8858<br>Alibi: 0.0<br>Attention: -0.9771<br>Bias: 3.4200", "Token: 98 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 98<br>Probability: 0.9078<br>Alibi: 0.0<br>Attention: -0.3636<br>Bias: 3.4200", "Token: 99 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 99<br>Probability: 0.8143<br>Alibi: 0.0<br>Attention: -0.9663<br>Bias: 3.4200", "Token: 100 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 100<br>Probability: 0.8958<br>Alibi: 0.0<br>Attention: -0.6152<br>Bias: 3.4200", "Token: 101 ( prenatal)<br>Attend to token: 0 (By)<br>Tokens in past: 101<br>Probability: 0.8995<br>Alibi: 0.0<br>Attention: -0.7011<br>Bias: 3.4200", "Token: 102 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 102<br>Probability: 0.8473<br>Alibi: 0.0<br>Attention: -1.0519<br>Bias: 3.4200", "Token: 103 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 103<br>Probability: 0.9091<br>Alibi: 0.0<br>Attention: -0.8611<br>Bias: 3.4200", "Token: 104 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 104<br>Probability: 0.9319<br>Alibi: 0.0<br>Attention: -0.8035<br>Bias: 3.4200", "Token: 105 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 105<br>Probability: 0.9584<br>Alibi: 0.0<br>Attention: -0.4239<br>Bias: 3.4200", "Token: 106 ( maintenance)<br>Attend to token: 0 (By)<br>Tokens in past: 106<br>Probability: 0.8904<br>Alibi: 0.0<br>Attention: -0.4675<br>Bias: 3.4200", "Token: 107 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 107<br>Probability: 0.9233<br>Alibi: 0.0<br>Attention: -0.7731<br>Bias: 3.4200", "Token: 108 ( chronic)<br>Attend to token: 0 (By)<br>Tokens in past: 108<br>Probability: 0.9175<br>Alibi: 0.0<br>Attention: -0.6307<br>Bias: 3.4200", "Token: 109 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 109<br>Probability: 0.9590<br>Alibi: 0.0<br>Attention: -0.5014<br>Bias: 3.4200", "Token: 110 ( diseases)<br>Attend to token: 0 (By)<br>Tokens in past: 110<br>Probability: 0.8508<br>Alibi: 0.0<br>Attention: -1.0989<br>Bias: 3.4200", "Token: 111 (..)<br>Attend to token: 0 (By)<br>Tokens in past: 111<br>Probability: 0.7407<br>Alibi: 0.0<br>Attention: -1.4869<br>Bias: 3.4200", "Token: 112 ( The)<br>Attend to token: 0 (By)<br>Tokens in past: 112<br>Probability: 0.9205<br>Alibi: 0.0<br>Attention: -0.6583<br>Bias: 3.4200", "Token: 113 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 113<br>Probability: 0.9520<br>Alibi: 0.0<br>Attention: -0.4200<br>Bias: 3.4200", "Token: 114 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 114<br>Probability: 0.8845<br>Alibi: 0.0<br>Attention: -0.8562<br>Bias: 3.4200", "Token: 115 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 115<br>Probability: 0.9182<br>Alibi: 0.0<br>Attention: -0.6371<br>Bias: 3.4200", "Token: 116 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 116<br>Probability: 0.9062<br>Alibi: 0.0<br>Attention: -0.5019<br>Bias: 3.4200", "Token: 117 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 117<br>Probability: 0.8483<br>Alibi: 0.0<br>Attention: -0.8787<br>Bias: 3.4200", "Token: 118 ( pregnant)<br>Attend to token: 0 (By)<br>Tokens in past: 118<br>Probability: 0.9171<br>Alibi: 0.0<br>Attention: -0.9702<br>Bias: 3.4200", "Token: 119 ( women)<br>Attend to token: 0 (By)<br>Tokens in past: 119<br>Probability: 0.8941<br>Alibi: 0.0<br>Attention: -1.0589<br>Bias: 3.4200", "Token: 120 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 120<br>Probability: 0.9017<br>Alibi: 0.0<br>Attention: -0.9119<br>Bias: 3.4200", "Token: 121 ( newborn)<br>Attend to token: 0 (By)<br>Tokens in past: 121<br>Probability: 0.8726<br>Alibi: 0.0<br>Attention: -0.8957<br>Bias: 3.4200", "Token: 122 (s)<br>Attend to token: 0 (By)<br>Tokens in past: 122<br>Probability: 0.8132<br>Alibi: 0.0<br>Attention: -1.2170<br>Bias: 3.4200", "Token: 123 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 123<br>Probability: 0.8465<br>Alibi: 0.0<br>Attention: -1.1677<br>Bias: 3.4200", "Token: 124 ( infants)<br>Attend to token: 0 (By)<br>Tokens in past: 124<br>Probability: 0.8074<br>Alibi: 0.0<br>Attention: -1.3359<br>Bias: 3.4200", "Token: 125 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 125<br>Probability: 0.9186<br>Alibi: 0.0<br>Attention: -0.7933<br>Bias: 3.4200", "Token: 126 ( high)<br>Attend to token: 0 (By)<br>Tokens in past: 126<br>Probability: 0.9640<br>Alibi: 0.0<br>Attention: -0.7729<br>Bias: 3.4200", "Token: 127 ( risk)<br>Attend to token: 0 (By)<br>Tokens in past: 127<br>Probability: 0.9166<br>Alibi: 0.0<br>Attention: -0.8103<br>Bias: 3.4200", "Token: 128 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 128<br>Probability: 0.9498<br>Alibi: 0.0<br>Attention: -0.6649<br>Bias: 3.4200", "Token: 129 ( malnutrition)<br>Attend to token: 0 (By)<br>Tokens in past: 129<br>Probability: 0.9320<br>Alibi: 0.0<br>Attention: -1.3304<br>Bias: 3.4200", "Token: 130 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 130<br>Probability: 0.9300<br>Alibi: 0.0<br>Attention: -1.1141<br>Bias: 3.4200", "Token: 131 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 131<br>Probability: 0.9332<br>Alibi: 0.0<br>Attention: -1.0920<br>Bias: 3.4200", "Token: 132 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 132<br>Probability: 0.9297<br>Alibi: 0.0<br>Attention: -0.8581<br>Bias: 3.4200", "Token: 133 ( obtain)<br>Attend to token: 0 (By)<br>Tokens in past: 133<br>Probability: 0.9261<br>Alibi: 0.0<br>Attention: -0.5677<br>Bias: 3.4200", "Token: 134 ( proper)<br>Attend to token: 0 (By)<br>Tokens in past: 134<br>Probability: 0.9175<br>Alibi: 0.0<br>Attention: -0.5544<br>Bias: 3.4200", "Token: 135 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 135<br>Probability: 0.8597<br>Alibi: 0.0<br>Attention: -0.8101<br>Bias: 3.4200", "Token: 136 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 136<br>Probability: 0.9049<br>Alibi: 0.0<br>Attention: -0.4310<br>Bias: 3.4200", "Token: 137 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 137<br>Probability: 0.8488<br>Alibi: 0.0<br>Attention: -0.7446<br>Bias: 3.4200", "Token: 138 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 138<br>Probability: 0.9252<br>Alibi: 0.0<br>Attention: -0.4388<br>Bias: 3.4200", "Token: 139 ( food)<br>Attend to token: 0 (By)<br>Tokens in past: 139<br>Probability: 0.9475<br>Alibi: 0.0<br>Attention: -0.4120<br>Bias: 3.4200", "Token: 140 ( assistance)<br>Attend to token: 0 (By)<br>Tokens in past: 140<br>Probability: 0.8858<br>Alibi: 0.0<br>Attention: -0.5857<br>Bias: 3.4200", "Token: 141 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 141<br>Probability: 0.9334<br>Alibi: 0.0<br>Attention: -0.2647<br>Bias: 3.4200", "Token: 142 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 142<br>Probability: 0.8989<br>Alibi: 0.0<br>Attention: -0.6988<br>Bias: 3.4200", "Token: 143 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 143<br>Probability: 0.8576<br>Alibi: 0.0<br>Attention: -0.5412<br>Bias: 3.4200", "Token: 144 ( They)<br>Attend to token: 0 (By)<br>Tokens in past: 144<br>Probability: 0.8631<br>Alibi: 0.0<br>Attention: -0.8544<br>Bias: 3.4200", "Token: 145 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 145<br>Probability: 0.9320<br>Alibi: 0.0<br>Attention: -0.4709<br>Bias: 3.4200", "Token: 146 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 146<br>Probability: 0.9224<br>Alibi: 0.0<br>Attention: -0.4269<br>Bias: 3.4200", "Token: 147 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 147<br>Probability: 0.9060<br>Alibi: 0.0<br>Attention: -0.5189<br>Bias: 3.4200", "Token: 148 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 148<br>Probability: 0.8987<br>Alibi: 0.0<br>Attention: -0.6083<br>Bias: 3.4200", "Token: 149 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 149<br>Probability: 0.9262<br>Alibi: 0.0<br>Attention: -0.1543<br>Bias: 3.4200", "Token: 150 ( certain)<br>Attend to token: 0 (By)<br>Tokens in past: 150<br>Probability: 0.8965<br>Alibi: 0.0<br>Attention: -0.0748<br>Bias: 3.4200", "Token: 151 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 151<br>Probability: 0.8665<br>Alibi: 0.0<br>Attention: -0.5307<br>Bias: 3.4200", "Token: 152 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 152<br>Probability: 0.9023<br>Alibi: 0.0<br>Attention: -0.4582<br>Bias: 3.4200", "Token: 153 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 153<br>Probability: 0.9248<br>Alibi: 0.0<br>Attention: 0.0150<br>Bias: 3.4200", "Token: 154 ( HIV)<br>Attend to token: 0 (By)<br>Tokens in past: 154<br>Probability: 0.9543<br>Alibi: 0.0<br>Attention: -0.3079<br>Bias: 3.4200", "Token: 155 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 155<br>Probability: 0.8641<br>Alibi: 0.0<br>Attention: -0.4442<br>Bias: 3.4200", "Token: 156 ( Tu)<br>Attend to token: 0 (By)<br>Tokens in past: 156<br>Probability: 0.9184<br>Alibi: 0.0<br>Attention: -0.5100<br>Bias: 3.4200", "Token: 157 (ber)<br>Attend to token: 0 (By)<br>Tokens in past: 157<br>Probability: 0.9490<br>Alibi: 0.0<br>Attention: -0.2252<br>Bias: 3.4200", "Token: 158 (culosis)<br>Attend to token: 0 (By)<br>Tokens in past: 158<br>Probability: 0.9296<br>Alibi: 0.0<br>Attention: -0.5751<br>Bias: 3.4200", "Token: 159 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 159<br>Probability: 0.8915<br>Alibi: 0.0<br>Attention: -0.5057<br>Bias: 3.4200", "Token: 160 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 160<br>Probability: 0.9250<br>Alibi: 0.0<br>Attention: -0.4943<br>Bias: 3.4200", "Token: 161 ( Mal)<br>Attend to token: 0 (By)<br>Tokens in past: 161<br>Probability: 0.9697<br>Alibi: 0.0<br>Attention: -0.2300<br>Bias: 3.4200", "Token: 162 (aria)<br>Attend to token: 0 (By)<br>Tokens in past: 162<br>Probability: 0.9125<br>Alibi: 0.0<br>Attention: -0.5465<br>Bias: 3.4200", "Token: 163 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 163<br>Probability: 0.9210<br>Alibi: 0.0<br>Attention: -0.7396<br>Bias: 3.4200", "Token: 164 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 164<br>Probability: 0.9465<br>Alibi: 0.0<br>Attention: -0.7643<br>Bias: 3.4200", "Token: 165 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 165<br>Probability: 0.9371<br>Alibi: 0.0<br>Attention: -0.4829<br>Bias: 3.4200", "Token: 166 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 166<br>Probability: 0.9336<br>Alibi: 0.0<br>Attention: -0.2255<br>Bias: 3.4200", "Token: 167 ( available)<br>Attend to token: 0 (By)<br>Tokens in past: 167<br>Probability: 0.8513<br>Alibi: 0.0<br>Attention: -0.2589<br>Bias: 3.4200", "Token: 168 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 168<br>Probability: 0.8363<br>Alibi: 0.0<br>Attention: -0.5461<br>Bias: 3.4200", "Token: 169 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 169<br>Probability: 0.8468<br>Alibi: 0.0<br>Attention: -0.6491<br>Bias: 3.4200"], "legendgroup": "0", "marker": {"color": [1.0, 0.9936657547950745, 0.9960468411445618, 0.9839460253715515, 0.990164577960968, 0.989560604095459, 0.977901816368103, 0.9872410297393799, 0.9757387042045593, 0.960705041885376, 0.9780614376068115, 0.9747886657714844, 0.9748260378837585, 0.9606311917304993, 0.9851561784744263, 0.982703447341919, 0.968944251537323, 0.9445222616195679, 0.9767653346061707, 0.9596154689788818, 0.9351415634155273, 0.9534961581230164, 0.9574640393257141, 0.9451984763145447, 0.8238042593002319, 0.9150010347366333, 0.914243757724762, 0.8936535716056824, 0.9502699375152588, 0.9701149463653564, 0.9786909818649292, 0.968315839767456, 0.9304713010787964, 0.9234217405319214, 0.9479290246963501, 0.9387691020965576, 0.9627904295921326, 0.9384450912475586, 0.9158713817596436, 0.9532575607299805, 0.9116467833518982, 0.9431323409080505, 0.9277533888816833, 0.9278398156166077, 0.9405709505081177, 0.9536169767379761, 0.9186943173408508, 0.9184410572052002, 0.9184019565582275, 0.9339371919631958, 0.8986207842826843, 0.9169276356697083, 0.9311801195144653, 0.9031718969345093, 0.9156381487846375, 0.8944723010063171, 0.9357634782791138, 0.9717061519622803, 0.8801943063735962, 0.9100431203842163, 0.9668583273887634, 0.9338803291320801, 0.8881083726882935, 0.8359238505363464, 0.9179436564445496, 0.934466540813446, 0.9263080954551697, 0.9605392217636108, 0.8762727379798889, 0.8989323377609253, 0.9116402268409729, 0.9185158014297485, 0.7887077927589417, 0.8936759233474731, 0.8913577795028687, 0.835767388343811, 0.9467055201530457, 0.8599319458007812, 0.8504974842071533, 0.8539538979530334, 0.9154649972915649, 0.910921037197113, 0.946914553642273, 0.9221240878105164, 0.9102197289466858, 0.8868520259857178, 0.8351331949234009, 0.9351738691329956, 0.9408807754516602, 0.9471059441566467, 0.8394368886947632, 0.8865984678268433, 0.9315541386604309, 0.8628483414649963, 0.9221261739730835, 0.8600669503211975, 0.8658618330955505, 0.8857754468917847, 0.9077754020690918, 0.8143138289451599, 0.895781934261322, 0.8995037078857422, 0.8472689986228943, 0.9090858697891235, 0.9318716526031494, 0.9583901762962341, 0.8904039859771729, 0.9233338236808777, 0.9174798130989075, 0.9589669108390808, 0.850832998752594, 0.7407497763633728, 0.9204994440078735, 0.9519593715667725, 0.8844699859619141, 0.9181559681892395, 0.9061765074729919, 0.8483333587646484, 0.9170666933059692, 0.8940787315368652, 0.9016764760017395, 0.8726145029067993, 0.8131532073020935, 0.846496045589447, 0.8073888421058655, 0.9185889959335327, 0.9640031456947327, 0.9165565371513367, 0.9498305320739746, 0.932039201259613, 0.9300310611724854, 0.9331874847412109, 0.9297217726707458, 0.9260970950126648, 0.9175138473510742, 0.8596822023391724, 0.9049083590507507, 0.8488431572914124, 0.9252395033836365, 0.9474936723709106, 0.8858070969581604, 0.9334298372268677, 0.8989360928535461, 0.8576174378395081, 0.8630947470664978, 0.9319685697555542, 0.9223906397819519, 0.9059877991676331, 0.8987172842025757, 0.9262069463729858, 0.8964991569519043, 0.8664504885673523, 0.9022623300552368, 0.9248034358024597, 0.9542699456214905, 0.8640521764755249, 0.9184202551841736, 0.9489916563034058, 0.9296221137046814, 0.8915243744850159, 0.9250128865242004, 0.9697183966636658, 0.9124889969825745, 0.921014666557312, 0.9464630484580994, 0.9370943307876587, 0.9336476922035217, 0.8513283133506775, 0.8363413214683533, 0.8467560410499573], "coloraxis": "coloraxis", "opacity": 0.5, "symbol": "circle"}, "mode": "markers", "name": "0", "showlegend": true, "subplot": "ternary", "type": "scatterternary"}], "layout": {"coloraxis": {"colorbar": {"title": {"text": "prob"}}, "colorscale": [[0.0, "rgb(0,0,255)"], [1.0, "rgb(255,0,0)"]]}, "legend": {"orientation": "h", "title": {"text": "sort_idx"}, "tracegroupgap": 0}, "margin": {"t": 60}, "template": {"data": {"candlestick": [{"decreasing": {"line": {"color": "#ff2b2b"}}, "increasing": {"line": {"color": "#29b09d"}}, "type": "candlestick"}], "contourcarpet": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contourcarpet"}], "contour": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contour"}], "heatmap": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "heatmap"}], "histogram2d": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "histogram2d"}], "icicle": [{"textfont": {"color": "white"}, "type": "icicle"}], "sankey": [{"textfont": {"color": "#808495"}, "type": "sankey"}], "scatter": [{"marker": {"line": {"width": 0}}, "type": "scatter"}], "table": [{"cells": {"fill": {"color": "#ffffff"}, "font": {"color": "#262730"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "header": {"fill": {"color": "rgba(248, 249, 251, 1)"}, "font": {"color": "#808495"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "type": "table"}], "waterfall": [{"connector": {"line": {"color": "#808495", "width": 2}}, "decreasing": {"marker": {"color": "#ff2b2b"}}, "increasing": {"marker": {"color": "#29b09d"}}, "totals": {"marker": {"color": "#0068c9"}}, "type": "waterfall"}]}, "layout": {"coloraxis": {"colorbar": {"len": 0.75, "outlinecolor": "rgba(0,0,0,0)", "outlinewidth": 8, "thickness": 16, "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}}, "xpad": 24, "y": 0.5745}}, "colorscale": {"diverging": [[0.0, "#7d353b"], [0.1, "#bd4043"], [0.2, "#ff4b4b"], [0.3, "#ff8c8c"], [0.4, "#ffc7c7"], [0.5, "#a6dcff"], [0.6, "#60b4ff"], [0.7, "#1c83e1"], [0.8, "#0054a3"], [0.9, "#004280"], [1.0, "#000031"]], "sequential": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "sequentialminus": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]]}, "colorway": ["#0068c9", "#83c9ff", "#ff2b2b", "#ffabab", "#29b09d", "#7defa1", "#ff8700", "#ffd16a", "#6d3fc0", "#d5dae5"], "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}, "hoverlabel": {"bgcolor": "#ffffff", "bordercolor": "rgba(49, 51, 63, 0.2)", "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "legend": {"bordercolor": "rgba(0,0,0,0)", "borderwidth": 0, "font": {"color": "#262730", "size": 12}, "title": {"font": {"color": "#808495", "size": 12}, "side": "top"}, "valign": "top"}, "margin": {"l": 0, "pad": 8, "r": 0}, "paper_bgcolor": "#ffffff", "plot_bgcolor": "#ffffff", "ternary": {"aaxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "baxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "bgcolor": "#ffffff", "caxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}}, "title": {"font": {"color": "#31333F", "family": "\"Source Sans Pro\", sans-serif", "size": 16}, "pad": {"l": 4}, "x": 0, "xanchor": "left"}, "xaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "rangeselector": {"bgcolor": "#ffffff", "bordercolor": "#e6eaf1", "borderwidth": 1, "x": 0}, "showgrid": false, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "title": {"font": {"color": "#808495", "size": 14}, "standoff": 20}, "zeroline": false, "zerolinecolor": "#e6eaf1"}, "yaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}, "standoff": 24}, "zerolinecolor": "#e6eaf1"}}}, "ternary": {"aaxis": {"title": {"text": "attention"}}, "baxis": {"title": {"text": "bias"}}, "caxis": {"title": {"text": "alibi"}}, "domain": {"x": [0.0, 1.0], "y": [0.0, 1.0]}}, "title": {"text": "Attention Breakdown (Layer 17, Head 24)"}}, "metadata": {"sentence_id": 0, "layer_id": 17, "head_id": 24, "accounted_probability": 0.5, "max_tokens_per_row": 11, "creation_date": "2025-01-23 00:04:47.976484", "page": {"page_script_hash": "a81f7f5ae171c15a95155bca2157e9b6", "page_name": "ATTN_-_Attention_Focus", "icon": "", "script_path": "/workspaces/llm-research/app/pages/301_ATTN - Attention Focus.py"}}}