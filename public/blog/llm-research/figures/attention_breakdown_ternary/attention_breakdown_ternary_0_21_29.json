{"data": [{"a": [0.0, 1.3987865447998047, 0.9585301876068115, 1.2540597915649414, 1.200819730758667, 1.213841438293457, 1.112567663192749, 0.7500350475311279, 0.9994192123413086, 0.7199242115020752, 0.8426940441131592, 0.7487466335296631, 0.8296430110931396, 1.0665338039398193, 1.0442554950714111, 0.6577764749526978, 1.230774164199829, 0.7178206443786621, 1.049281120300293, 0.8441038131713867, 0.8706881999969482, 0.6735758781433105, 1.0612971782684326, 1.2508883476257324, 1.0792055130004883, 1.1608824729919434, 0.7789955139160156, 0.7730302810668945, 0.6945006847381592, 0.6957442760467529, 0.9176235198974609, 1.0769038200378418, 0.8096997737884521, 1.0675458908081055, 0.9398963451385498, 0.903597354888916, 1.020484447479248, 1.1299514770507812, 0.935795783996582, 0.6766431331634521, 0.924715518951416, 0.8291225433349609, 0.867119550704956, 0.924701452255249, 0.9022848606109619, 1.1323916912078857, 0.6365313529968262, 0.8872480392456055, 1.2129971981048584, 1.4130911827087402, 1.0538380146026611, 1.1995770931243896, 0.7248008251190186, 1.1545450687408447, 0.7042765617370605, 0.7373247146606445, 0.9808249473571777, 1.1186938285827637, 1.2143797874450684, 1.1768107414245605, 1.2970912456512451, 1.3374929428100586, 0.795076847076416, 0.863006591796875, 0.900742769241333, 0.8787555694580078, 0.90860915184021, 1.1715798377990723, 1.0114777088165283, 0.9597439765930176, 1.24648118019104, 0.8121998310089111, 1.177868366241455, 0.8879554271697998, 0.7796235084533691, 0.7814149856567383, 0.8634989261627197, 0.5619964599609375, 0.7932355403900146, 1.010979175567627, 0.8976616859436035, 0.7873537540435791, 1.109053134918213, 1.1287989616394043, 1.008521318435669, 1.0364785194396973, 0.9231665134429932, 0.9264926910400391, 1.07826828956604, 1.0096683502197266, 0.999910831451416, 1.2951033115386963, 1.3761913776397705, 1.4497520923614502, 1.4236629009246826, 1.30198335647583, 1.0990715026855469, 1.0594711303710938, 1.6982128620147705, 1.1059086322784424, 1.4995005130767822, 1.2978479862213135, 1.491680383682251, 1.554192304611206, 1.4715259075164795, 1.4378583431243896, 1.4746966361999512, 1.30570387840271, 1.599388599395752, 1.2344379425048828, 1.4740688800811768, 0.9681470394134521, 0.8689005374908447, 1.3638107776641846, 1.5508534908294678, 1.3230249881744385, 1.3205678462982178, 1.395498514175415, 1.0773260593414307, 1.0837972164154053, 1.448242425918579, 1.0777263641357422, 1.0585105419158936, 1.4704582691192627, 1.176255702972412, 1.1777551174163818, 1.0243232250213623, 1.1140878200531006, 1.2478857040405273, 0.980954647064209, 0.8305873870849609, 0.7945892810821533, 1.0187809467315674, 1.2203240394592285, 1.2254912853240967, 1.0753028392791748, 1.0412871837615967, 1.0110840797424316, 1.5046541690826416, 1.3156654834747314, 1.261315107345581, 1.4496498107910156, 1.0804617404937744, 1.185356855392456, 1.1318747997283936, 1.2802841663360596, 1.2181284427642822, 1.6415302753448486, 1.4661622047424316, 1.6607375144958496, 1.5978076457977295, 1.5857484340667725, 1.5201737880706787, 1.822218656539917, 1.0957953929901123, 1.770582914352417, 1.281538963317871, 1.511247158050537, 1.159529447555542, 1.643425464630127, 1.492708444595337, 1.4420576095581055, 1.2343032360076904, 0.9613735675811768, 0.8962948322296143, 1.2048163414001465, 1.2694482803344727, 1.3043098449707031, 1.392082929611206, 1.2176101207733154], "b": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "c": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "hovertemplate": "<b>%{hovertext}</b><br><br>sort_idx=0<br>a=%{a}<br>b=%{b}<br>alibi=%{c}<br>prob=%{marker.color}<extra></extra>", "hovertext": ["Token: 0 (By)<br>Attend to token: 0 (By)<br>Tokens in past: 0<br>Probability: 1.0000<br>Alibi: 0.0<br>Attention: -2.1035<br>Bias: 3.3090", "Token: 1 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 1<br>Probability: 0.9913<br>Alibi: 0.0<br>Attention: -0.7048<br>Bias: 3.3090", "Token: 2 ( end)<br>Attend to token: 0 (By)<br>Tokens in past: 2<br>Probability: 0.9977<br>Alibi: 0.0<br>Attention: -1.1450<br>Bias: 3.3090", "Token: 3 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 3<br>Probability: 0.9940<br>Alibi: 0.0<br>Attention: -0.8495<br>Bias: 3.3090", "Token: 4 ( 2014)<br>Attend to token: 0 (By)<br>Tokens in past: 4<br>Probability: 0.9950<br>Alibi: 0.0<br>Attention: -0.9027<br>Bias: 3.3090", "Token: 5 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 5<br>Probability: 0.9927<br>Alibi: 0.0<br>Attention: -0.8897<br>Bias: 3.3090", "Token: 6 ( we)<br>Attend to token: 0 (By)<br>Tokens in past: 6<br>Probability: 0.9834<br>Alibi: 0.0<br>Attention: -0.9910<br>Bias: 3.3090", "Token: 7 ( plan)<br>Attend to token: 0 (By)<br>Tokens in past: 7<br>Probability: 0.9826<br>Alibi: 0.0<br>Attention: -1.3535<br>Bias: 3.3090", "Token: 8 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 8<br>Probability: 0.9739<br>Alibi: 0.0<br>Attention: -1.1041<br>Bias: 3.3090", "Token: 9 ( rev)<br>Attend to token: 0 (By)<br>Tokens in past: 9<br>Probability: 0.9792<br>Alibi: 0.0<br>Attention: -1.3836<br>Bias: 3.3090", "Token: 10 (amp)<br>Attend to token: 0 (By)<br>Tokens in past: 10<br>Probability: 0.9580<br>Alibi: 0.0<br>Attention: -1.2608<br>Bias: 3.3090", "Token: 11 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 11<br>Probability: 0.9436<br>Alibi: 0.0<br>Attention: -1.3548<br>Bias: 3.3090", "Token: 12 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 12<br>Probability: 0.9763<br>Alibi: 0.0<br>Attention: -1.2739<br>Bias: 3.3090", "Token: 13 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 13<br>Probability: 0.9794<br>Alibi: 0.0<br>Attention: -1.0370<br>Bias: 3.3090", "Token: 14 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 14<br>Probability: 0.9677<br>Alibi: 0.0<br>Attention: -1.0593<br>Bias: 3.3090", "Token: 15 ( disease)<br>Attend to token: 0 (By)<br>Tokens in past: 15<br>Probability: 0.9857<br>Alibi: 0.0<br>Attention: -1.4458<br>Bias: 3.3090", "Token: 16 ( prevention)<br>Attend to token: 0 (By)<br>Tokens in past: 16<br>Probability: 0.9915<br>Alibi: 0.0<br>Attention: -0.8728<br>Bias: 3.3090", "Token: 17 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 17<br>Probability: 0.9785<br>Alibi: 0.0<br>Attention: -1.3857<br>Bias: 3.3090", "Token: 18 ( program)<br>Attend to token: 0 (By)<br>Tokens in past: 18<br>Probability: 0.9778<br>Alibi: 0.0<br>Attention: -1.0543<br>Bias: 3.3090", "Token: 19 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 19<br>Probability: 0.9706<br>Alibi: 0.0<br>Attention: -1.2594<br>Bias: 3.3090", "Token: 20 ( which)<br>Attend to token: 0 (By)<br>Tokens in past: 20<br>Probability: 0.9688<br>Alibi: 0.0<br>Attention: -1.2329<br>Bias: 3.3090", "Token: 21 ( was)<br>Attend to token: 0 (By)<br>Tokens in past: 21<br>Probability: 0.9661<br>Alibi: 0.0<br>Attention: -1.4300<br>Bias: 3.3090", "Token: 22 ( suspended)<br>Attend to token: 0 (By)<br>Tokens in past: 22<br>Probability: 0.9869<br>Alibi: 0.0<br>Attention: -1.0422<br>Bias: 3.3090", "Token: 23 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 23<br>Probability: 0.9855<br>Alibi: 0.0<br>Attention: -0.8527<br>Bias: 3.3090", "Token: 24 ( September)<br>Attend to token: 0 (By)<br>Tokens in past: 24<br>Probability: 0.9920<br>Alibi: 0.0<br>Attention: -1.0243<br>Bias: 3.3090", "Token: 25 ( 2013)<br>Attend to token: 0 (By)<br>Tokens in past: 25<br>Probability: 0.9916<br>Alibi: 0.0<br>Attention: -0.9427<br>Bias: 3.3090", "Token: 26 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 26<br>Probability: 0.9841<br>Alibi: 0.0<br>Attention: -1.3245<br>Bias: 3.3090", "Token: 27 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 27<br>Probability: 0.9491<br>Alibi: 0.0<br>Attention: -1.3305<br>Bias: 3.3090", "Token: 28 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 28<br>Probability: 0.9323<br>Alibi: 0.0<br>Attention: -1.4090<br>Bias: 3.3090", "Token: 29 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 29<br>Probability: 0.9722<br>Alibi: 0.0<br>Attention: -1.4078<br>Bias: 3.3090", "Token: 30 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 30<br>Probability: 0.9905<br>Alibi: 0.0<br>Attention: -1.1859<br>Bias: 3.3090", "Token: 31 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 31<br>Probability: 0.9893<br>Alibi: 0.0<br>Attention: -1.0266<br>Bias: 3.3090", "Token: 32 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 32<br>Probability: 0.9820<br>Alibi: 0.0<br>Attention: -1.2938<br>Bias: 3.3090", "Token: 33 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 33<br>Probability: 0.9845<br>Alibi: 0.0<br>Attention: -1.0360<br>Bias: 3.3090", "Token: 34 ( at)<br>Attend to token: 0 (By)<br>Tokens in past: 34<br>Probability: 0.9241<br>Alibi: 0.0<br>Attention: -1.1636<br>Bias: 3.3090", "Token: 35 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 35<br>Probability: 0.9293<br>Alibi: 0.0<br>Attention: -1.1999<br>Bias: 3.3090", "Token: 36 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 36<br>Probability: 0.8923<br>Alibi: 0.0<br>Attention: -1.0831<br>Bias: 3.3090", "Token: 37 ( centers)<br>Attend to token: 0 (By)<br>Tokens in past: 37<br>Probability: 0.9815<br>Alibi: 0.0<br>Attention: -0.9736<br>Bias: 3.3090", "Token: 38 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 38<br>Probability: 0.9287<br>Alibi: 0.0<br>Attention: -1.1677<br>Bias: 3.3090", "Token: 39 ( group)<br>Attend to token: 0 (By)<br>Tokens in past: 39<br>Probability: 0.9199<br>Alibi: 0.0<br>Attention: -1.4269<br>Bias: 3.3090", "Token: 40 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 40<br>Probability: 0.9838<br>Alibi: 0.0<br>Attention: -1.1788<br>Bias: 3.3090", "Token: 41 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 41<br>Probability: 0.9686<br>Alibi: 0.0<br>Attention: -1.2744<br>Bias: 3.3090", "Token: 42 ( specific)<br>Attend to token: 0 (By)<br>Tokens in past: 42<br>Probability: 0.9719<br>Alibi: 0.0<br>Attention: -1.2364<br>Bias: 3.3090", "Token: 43 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 43<br>Probability: 0.9848<br>Alibi: 0.0<br>Attention: -1.1788<br>Bias: 3.3090", "Token: 44 ( ()<br>Attend to token: 0 (By)<br>Tokens in past: 44<br>Probability: 0.9821<br>Alibi: 0.0<br>Attention: -1.2013<br>Bias: 3.3090", "Token: 45 (Di)<br>Attend to token: 0 (By)<br>Tokens in past: 45<br>Probability: 0.7873<br>Alibi: 0.0<br>Attention: -0.9711<br>Bias: 3.3090", "Token: 46 (abetes)<br>Attend to token: 0 (By)<br>Tokens in past: 46<br>Probability: 0.8931<br>Alibi: 0.0<br>Attention: -1.4670<br>Bias: 3.3090", "Token: 47 (,.)<br>Attend to token: 0 (By)<br>Tokens in past: 47<br>Probability: 0.9672<br>Alibi: 0.0<br>Attention: -1.2163<br>Bias: 3.3090", "Token: 48 ( Hy)<br>Attend to token: 0 (By)<br>Tokens in past: 48<br>Probability: 0.9714<br>Alibi: 0.0<br>Attention: -0.8905<br>Bias: 3.3090", "Token: 49 (pert)<br>Attend to token: 0 (By)<br>Tokens in past: 49<br>Probability: 0.9888<br>Alibi: 0.0<br>Attention: -0.6904<br>Bias: 3.3090", "Token: 50 (ension)<br>Attend to token: 0 (By)<br>Tokens in past: 50<br>Probability: 0.9823<br>Alibi: 0.0<br>Attention: -1.0497<br>Bias: 3.3090", "Token: 51 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 51<br>Probability: 0.9711<br>Alibi: 0.0<br>Attention: -0.9040<br>Bias: 3.3090", "Token: 52 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 52<br>Probability: 0.9848<br>Alibi: 0.0<br>Attention: -1.3787<br>Bias: 3.3090", "Token: 53 (.),)<br>Attend to token: 0 (By)<br>Tokens in past: 53<br>Probability: 0.9659<br>Alibi: 0.0<br>Attention: -0.9490<br>Bias: 3.3090", "Token: 54 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 54<br>Probability: 0.9696<br>Alibi: 0.0<br>Attention: -1.3993<br>Bias: 3.3090", "Token: 55 ( well)<br>Attend to token: 0 (By)<br>Tokens in past: 55<br>Probability: 0.9796<br>Alibi: 0.0<br>Attention: -1.3662<br>Bias: 3.3090", "Token: 56 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 56<br>Probability: 0.9565<br>Alibi: 0.0<br>Attention: -1.1227<br>Bias: 3.3090", "Token: 57 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 57<br>Probability: 0.9622<br>Alibi: 0.0<br>Attention: -0.9848<br>Bias: 3.3090", "Token: 58 ( forums)<br>Attend to token: 0 (By)<br>Tokens in past: 58<br>Probability: 0.9798<br>Alibi: 0.0<br>Attention: -0.8892<br>Bias: 3.3090", "Token: 59 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 59<br>Probability: 0.9595<br>Alibi: 0.0<br>Attention: -0.9267<br>Bias: 3.3090", "Token: 60 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 60<br>Probability: 0.9810<br>Alibi: 0.0<br>Attention: -0.8064<br>Bias: 3.3090", "Token: 61 ( fair)<br>Attend to token: 0 (By)<br>Tokens in past: 61<br>Probability: 0.9790<br>Alibi: 0.0<br>Attention: -0.7660<br>Bias: 3.3090", "Token: 62 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 62<br>Probability: 0.9753<br>Alibi: 0.0<br>Attention: -1.3085<br>Bias: 3.3090", "Token: 63 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 63<br>Probability: 0.9682<br>Alibi: 0.0<br>Attention: -1.2405<br>Bias: 3.3090", "Token: 64 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 64<br>Probability: 0.9709<br>Alibi: 0.0<br>Attention: -1.2028<br>Bias: 3.3090", "Token: 65 ( recruit)<br>Attend to token: 0 (By)<br>Tokens in past: 65<br>Probability: 0.9641<br>Alibi: 0.0<br>Attention: -1.2248<br>Bias: 3.3090", "Token: 66 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 66<br>Probability: 0.9564<br>Alibi: 0.0<br>Attention: -1.1949<br>Bias: 3.3090", "Token: 67 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 67<br>Probability: 0.9867<br>Alibi: 0.0<br>Attention: -0.9320<br>Bias: 3.3090", "Token: 68 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 68<br>Probability: 0.9854<br>Alibi: 0.0<br>Attention: -1.0921<br>Bias: 3.3090", "Token: 69 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 69<br>Probability: 0.9401<br>Alibi: 0.0<br>Attention: -1.1438<br>Bias: 3.3090", "Token: 70 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 70<br>Probability: 0.9673<br>Alibi: 0.0<br>Attention: -0.8571<br>Bias: 3.3090", "Token: 71 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 71<br>Probability: 0.9742<br>Alibi: 0.0<br>Attention: -1.2913<br>Bias: 3.3090", "Token: 72 ( assessment)<br>Attend to token: 0 (By)<br>Tokens in past: 72<br>Probability: 0.9786<br>Alibi: 0.0<br>Attention: -0.9257<br>Bias: 3.3090", "Token: 73 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 73<br>Probability: 0.8285<br>Alibi: 0.0<br>Attention: -1.2156<br>Bias: 3.3090", "Token: 74 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 74<br>Probability: 0.8403<br>Alibi: 0.0<br>Attention: -1.3239<br>Bias: 3.3090", "Token: 75 ( area)<br>Attend to token: 0 (By)<br>Tokens in past: 75<br>Probability: 0.9524<br>Alibi: 0.0<br>Attention: -1.3221<br>Bias: 3.3090", "Token: 76 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 76<br>Probability: 0.8293<br>Alibi: 0.0<br>Attention: -1.2400<br>Bias: 3.3090", "Token: 77 ( intervention)<br>Attend to token: 0 (By)<br>Tokens in past: 77<br>Probability: 0.8879<br>Alibi: 0.0<br>Attention: -1.5415<br>Bias: 3.3090", "Token: 78 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 78<br>Probability: 0.9698<br>Alibi: 0.0<br>Attention: -1.3103<br>Bias: 3.3090", "Token: 79 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 79<br>Probability: 0.9592<br>Alibi: 0.0<br>Attention: -1.0926<br>Bias: 3.3090", "Token: 80 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 80<br>Probability: 0.9574<br>Alibi: 0.0<br>Attention: -1.2059<br>Bias: 3.3090", "Token: 81 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 81<br>Probability: 0.9365<br>Alibi: 0.0<br>Attention: -1.3162<br>Bias: 3.3090", "Token: 82 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 82<br>Probability: 0.9663<br>Alibi: 0.0<br>Attention: -0.9945<br>Bias: 3.3090", "Token: 83 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 83<br>Probability: 0.9689<br>Alibi: 0.0<br>Attention: -0.9747<br>Bias: 3.3090", "Token: 84 ( economic)<br>Attend to token: 0 (By)<br>Tokens in past: 84<br>Probability: 0.9699<br>Alibi: 0.0<br>Attention: -1.0950<br>Bias: 3.3090", "Token: 85 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 85<br>Probability: 0.9775<br>Alibi: 0.0<br>Attention: -1.0671<br>Bias: 3.3090", "Token: 86 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 86<br>Probability: 0.9673<br>Alibi: 0.0<br>Attention: -1.1804<br>Bias: 3.3090", "Token: 87 ( educate)<br>Attend to token: 0 (By)<br>Tokens in past: 87<br>Probability: 0.9735<br>Alibi: 0.0<br>Attention: -1.1770<br>Bias: 3.3090", "Token: 88 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 88<br>Probability: 0.9633<br>Alibi: 0.0<br>Attention: -1.0253<br>Bias: 3.3090", "Token: 89 ( encourage)<br>Attend to token: 0 (By)<br>Tokens in past: 89<br>Probability: 0.9769<br>Alibi: 0.0<br>Attention: -1.0939<br>Bias: 3.3090", "Token: 90 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 90<br>Probability: 0.9843<br>Alibi: 0.0<br>Attention: -1.1036<br>Bias: 3.3090", "Token: 91 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 91<br>Probability: 0.9886<br>Alibi: 0.0<br>Attention: -0.8084<br>Bias: 3.3090", "Token: 92 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 92<br>Probability: 0.9508<br>Alibi: 0.0<br>Attention: -0.7273<br>Bias: 3.3090", "Token: 93 ( preventive)<br>Attend to token: 0 (By)<br>Tokens in past: 93<br>Probability: 0.9919<br>Alibi: 0.0<br>Attention: -0.6538<br>Bias: 3.3090", "Token: 94 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 94<br>Probability: 0.9774<br>Alibi: 0.0<br>Attention: -0.6799<br>Bias: 3.3090", "Token: 95 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 95<br>Probability: 0.9890<br>Alibi: 0.0<br>Attention: -0.8016<br>Bias: 3.3090", "Token: 96 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 96<br>Probability: 0.9734<br>Alibi: 0.0<br>Attention: -1.0045<br>Bias: 3.3090", "Token: 97 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 97<br>Probability: 0.9783<br>Alibi: 0.0<br>Attention: -1.0441<br>Bias: 3.3090", "Token: 98 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 98<br>Probability: 0.9649<br>Alibi: 0.0<br>Attention: -0.4053<br>Bias: 3.3090", "Token: 99 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 99<br>Probability: 0.9776<br>Alibi: 0.0<br>Attention: -0.9976<br>Bias: 3.3090", "Token: 100 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 100<br>Probability: 0.9447<br>Alibi: 0.0<br>Attention: -0.6040<br>Bias: 3.3090", "Token: 101 ( prenatal)<br>Attend to token: 0 (By)<br>Tokens in past: 101<br>Probability: 0.9799<br>Alibi: 0.0<br>Attention: -0.8057<br>Bias: 3.3090", "Token: 102 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 102<br>Probability: 0.9900<br>Alibi: 0.0<br>Attention: -0.6119<br>Bias: 3.3090", "Token: 103 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 103<br>Probability: 0.9598<br>Alibi: 0.0<br>Attention: -0.5493<br>Bias: 3.3090", "Token: 104 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 104<br>Probability: 0.9688<br>Alibi: 0.0<br>Attention: -0.6320<br>Bias: 3.3090", "Token: 105 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 105<br>Probability: 0.9787<br>Alibi: 0.0<br>Attention: -0.6657<br>Bias: 3.3090", "Token: 106 ( maintenance)<br>Attend to token: 0 (By)<br>Tokens in past: 106<br>Probability: 0.9839<br>Alibi: 0.0<br>Attention: -0.6288<br>Bias: 3.3090", "Token: 107 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 107<br>Probability: 0.9708<br>Alibi: 0.0<br>Attention: -0.7978<br>Bias: 3.3090", "Token: 108 ( chronic)<br>Attend to token: 0 (By)<br>Tokens in past: 108<br>Probability: 0.9933<br>Alibi: 0.0<br>Attention: -0.5042<br>Bias: 3.3090", "Token: 109 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 109<br>Probability: 0.9816<br>Alibi: 0.0<br>Attention: -0.8691<br>Bias: 3.3090", "Token: 110 ( diseases)<br>Attend to token: 0 (By)<br>Tokens in past: 110<br>Probability: 0.9946<br>Alibi: 0.0<br>Attention: -0.6295<br>Bias: 3.3090", "Token: 111 (..)<br>Attend to token: 0 (By)<br>Tokens in past: 111<br>Probability: 0.9690<br>Alibi: 0.0<br>Attention: -1.1354<br>Bias: 3.3090", "Token: 112 ( The)<br>Attend to token: 0 (By)<br>Tokens in past: 112<br>Probability: 0.9600<br>Alibi: 0.0<br>Attention: -1.2346<br>Bias: 3.3090", "Token: 113 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 113<br>Probability: 0.9754<br>Alibi: 0.0<br>Attention: -0.7397<br>Bias: 3.3090", "Token: 114 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 114<br>Probability: 0.9841<br>Alibi: 0.0<br>Attention: -0.5527<br>Bias: 3.3090", "Token: 115 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 115<br>Probability: 0.9809<br>Alibi: 0.0<br>Attention: -0.7805<br>Bias: 3.3090", "Token: 116 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 116<br>Probability: 0.9730<br>Alibi: 0.0<br>Attention: -0.7830<br>Bias: 3.3090", "Token: 117 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 117<br>Probability: 0.9743<br>Alibi: 0.0<br>Attention: -0.7080<br>Bias: 3.3090", "Token: 118 ( pregnant)<br>Attend to token: 0 (By)<br>Tokens in past: 118<br>Probability: 0.9868<br>Alibi: 0.0<br>Attention: -1.0262<br>Bias: 3.3090", "Token: 119 ( women)<br>Attend to token: 0 (By)<br>Tokens in past: 119<br>Probability: 0.9872<br>Alibi: 0.0<br>Attention: -1.0197<br>Bias: 3.3090", "Token: 120 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 120<br>Probability: 0.9743<br>Alibi: 0.0<br>Attention: -0.6553<br>Bias: 3.3090", "Token: 121 ( newborn)<br>Attend to token: 0 (By)<br>Tokens in past: 121<br>Probability: 0.9904<br>Alibi: 0.0<br>Attention: -1.0258<br>Bias: 3.3090", "Token: 122 (s)<br>Attend to token: 0 (By)<br>Tokens in past: 122<br>Probability: 0.9932<br>Alibi: 0.0<br>Attention: -1.0450<br>Bias: 3.3090", "Token: 123 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 123<br>Probability: 0.9792<br>Alibi: 0.0<br>Attention: -0.6331<br>Bias: 3.3090", "Token: 124 ( infants)<br>Attend to token: 0 (By)<br>Tokens in past: 124<br>Probability: 0.9932<br>Alibi: 0.0<br>Attention: -0.9273<br>Bias: 3.3090", "Token: 125 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 125<br>Probability: 0.9789<br>Alibi: 0.0<br>Attention: -0.9258<br>Bias: 3.3090", "Token: 126 ( high)<br>Attend to token: 0 (By)<br>Tokens in past: 126<br>Probability: 0.9859<br>Alibi: 0.0<br>Attention: -1.0792<br>Bias: 3.3090", "Token: 127 ( risk)<br>Attend to token: 0 (By)<br>Tokens in past: 127<br>Probability: 0.9923<br>Alibi: 0.0<br>Attention: -0.9895<br>Bias: 3.3090", "Token: 128 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 128<br>Probability: 0.9854<br>Alibi: 0.0<br>Attention: -0.8557<br>Bias: 3.3090", "Token: 129 ( malnutrition)<br>Attend to token: 0 (By)<br>Tokens in past: 129<br>Probability: 0.9870<br>Alibi: 0.0<br>Attention: -1.1226<br>Bias: 3.3090", "Token: 130 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 130<br>Probability: 0.9657<br>Alibi: 0.0<br>Attention: -1.2730<br>Bias: 3.3090", "Token: 131 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 131<br>Probability: 0.9753<br>Alibi: 0.0<br>Attention: -1.3090<br>Bias: 3.3090", "Token: 132 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 132<br>Probability: 0.9876<br>Alibi: 0.0<br>Attention: -1.0848<br>Bias: 3.3090", "Token: 133 ( obtain)<br>Attend to token: 0 (By)<br>Tokens in past: 133<br>Probability: 0.9738<br>Alibi: 0.0<br>Attention: -0.8832<br>Bias: 3.3090", "Token: 134 ( proper)<br>Attend to token: 0 (By)<br>Tokens in past: 134<br>Probability: 0.9821<br>Alibi: 0.0<br>Attention: -0.8780<br>Bias: 3.3090", "Token: 135 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 135<br>Probability: 0.9897<br>Alibi: 0.0<br>Attention: -1.0282<br>Bias: 3.3090", "Token: 136 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 136<br>Probability: 0.9735<br>Alibi: 0.0<br>Attention: -1.0623<br>Bias: 3.3090", "Token: 137 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 137<br>Probability: 0.9840<br>Alibi: 0.0<br>Attention: -1.0925<br>Bias: 3.3090", "Token: 138 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 138<br>Probability: 0.9630<br>Alibi: 0.0<br>Attention: -0.5989<br>Bias: 3.3090", "Token: 139 ( food)<br>Attend to token: 0 (By)<br>Tokens in past: 139<br>Probability: 0.9821<br>Alibi: 0.0<br>Attention: -0.7879<br>Bias: 3.3090", "Token: 140 ( assistance)<br>Attend to token: 0 (By)<br>Tokens in past: 140<br>Probability: 0.9775<br>Alibi: 0.0<br>Attention: -0.8422<br>Bias: 3.3090", "Token: 141 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 141<br>Probability: 0.9583<br>Alibi: 0.0<br>Attention: -0.6539<br>Bias: 3.3090", "Token: 142 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 142<br>Probability: 0.9909<br>Alibi: 0.0<br>Attention: -1.0231<br>Bias: 3.3090", "Token: 143 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 143<br>Probability: 0.9829<br>Alibi: 0.0<br>Attention: -0.9182<br>Bias: 3.3090", "Token: 144 ( They)<br>Attend to token: 0 (By)<br>Tokens in past: 144<br>Probability: 0.9784<br>Alibi: 0.0<br>Attention: -0.9717<br>Bias: 3.3090", "Token: 145 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 145<br>Probability: 0.9835<br>Alibi: 0.0<br>Attention: -0.8233<br>Bias: 3.3090", "Token: 146 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 146<br>Probability: 0.9750<br>Alibi: 0.0<br>Attention: -0.8854<br>Bias: 3.3090", "Token: 147 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 147<br>Probability: 0.9820<br>Alibi: 0.0<br>Attention: -0.4620<br>Bias: 3.3090", "Token: 148 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 148<br>Probability: 0.9885<br>Alibi: 0.0<br>Attention: -0.6374<br>Bias: 3.3090", "Token: 149 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 149<br>Probability: 0.9754<br>Alibi: 0.0<br>Attention: -0.4428<br>Bias: 3.3090", "Token: 150 ( certain)<br>Attend to token: 0 (By)<br>Tokens in past: 150<br>Probability: 0.9834<br>Alibi: 0.0<br>Attention: -0.5057<br>Bias: 3.3090", "Token: 151 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 151<br>Probability: 0.9914<br>Alibi: 0.0<br>Attention: -0.5178<br>Bias: 3.3090", "Token: 152 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 152<br>Probability: 0.9796<br>Alibi: 0.0<br>Attention: -0.5834<br>Bias: 3.3090", "Token: 153 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 153<br>Probability: 0.9551<br>Alibi: 0.0<br>Attention: -0.2813<br>Bias: 3.3090", "Token: 154 ( HIV)<br>Attend to token: 0 (By)<br>Tokens in past: 154<br>Probability: 0.9578<br>Alibi: 0.0<br>Attention: -1.0077<br>Bias: 3.3090", "Token: 155 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 155<br>Probability: 0.9573<br>Alibi: 0.0<br>Attention: -0.3330<br>Bias: 3.3090", "Token: 156 ( Tu)<br>Attend to token: 0 (By)<br>Tokens in past: 156<br>Probability: 0.9866<br>Alibi: 0.0<br>Attention: -0.8220<br>Bias: 3.3090", "Token: 157 (ber)<br>Attend to token: 0 (By)<br>Tokens in past: 157<br>Probability: 0.9809<br>Alibi: 0.0<br>Attention: -0.5923<br>Bias: 3.3090", "Token: 158 (culosis)<br>Attend to token: 0 (By)<br>Tokens in past: 158<br>Probability: 0.9674<br>Alibi: 0.0<br>Attention: -0.9440<br>Bias: 3.3090", "Token: 159 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 159<br>Probability: 0.9234<br>Alibi: 0.0<br>Attention: -0.4601<br>Bias: 3.3090", "Token: 160 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 160<br>Probability: 0.9303<br>Alibi: 0.0<br>Attention: -0.6108<br>Bias: 3.3090", "Token: 161 ( Mal)<br>Attend to token: 0 (By)<br>Tokens in past: 161<br>Probability: 0.8943<br>Alibi: 0.0<br>Attention: -0.6615<br>Bias: 3.3090", "Token: 162 (aria)<br>Attend to token: 0 (By)<br>Tokens in past: 162<br>Probability: 0.9398<br>Alibi: 0.0<br>Attention: -0.8692<br>Bias: 3.3090", "Token: 163 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 163<br>Probability: 0.9460<br>Alibi: 0.0<br>Attention: -1.1422<br>Bias: 3.3090", "Token: 164 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 164<br>Probability: 0.9511<br>Alibi: 0.0<br>Attention: -1.2072<br>Bias: 3.3090", "Token: 165 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 165<br>Probability: 0.9774<br>Alibi: 0.0<br>Attention: -0.8987<br>Bias: 3.3090", "Token: 166 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 166<br>Probability: 0.8337<br>Alibi: 0.0<br>Attention: -0.8341<br>Bias: 3.3090", "Token: 167 ( available)<br>Attend to token: 0 (By)<br>Tokens in past: 167<br>Probability: 0.8876<br>Alibi: 0.0<br>Attention: -0.7992<br>Bias: 3.3090", "Token: 168 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 168<br>Probability: 0.9842<br>Alibi: 0.0<br>Attention: -0.7115<br>Bias: 3.3090", "Token: 169 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 169<br>Probability: 0.9731<br>Alibi: 0.0<br>Attention: -0.8859<br>Bias: 3.3090"], "legendgroup": "0", "marker": {"color": [1.0, 0.9913175106048584, 0.9977381229400635, 0.9939612746238708, 0.994955837726593, 0.9926758408546448, 0.9834088683128357, 0.9825844168663025, 0.9738856554031372, 0.9791508913040161, 0.9579599499702454, 0.9436426758766174, 0.9763330817222595, 0.9794425368309021, 0.9677069187164307, 0.9857426285743713, 0.9914531707763672, 0.9785070419311523, 0.9777700304985046, 0.9706137180328369, 0.9687938690185547, 0.9661301970481873, 0.9868633151054382, 0.9855456352233887, 0.9920486807823181, 0.9915701746940613, 0.9840946793556213, 0.9490916132926941, 0.9323409199714661, 0.9722071886062622, 0.9905233979225159, 0.9893006086349487, 0.9820175766944885, 0.9845241904258728, 0.9240851998329163, 0.9292861819267273, 0.8923144340515137, 0.9815493226051331, 0.9287484288215637, 0.9198712706565857, 0.9838128685951233, 0.968593418598175, 0.9718532562255859, 0.9848248362541199, 0.9821375012397766, 0.7873276472091675, 0.8931092619895935, 0.9672421813011169, 0.971351683139801, 0.9888078570365906, 0.9822633266448975, 0.9711058735847473, 0.9848316311836243, 0.9658992290496826, 0.9695850014686584, 0.9795560836791992, 0.956494927406311, 0.9622248411178589, 0.9798151254653931, 0.9594588279724121, 0.9809815883636475, 0.9789574146270752, 0.9752616882324219, 0.9681541919708252, 0.9709104299545288, 0.9641316533088684, 0.9564410448074341, 0.9866786599159241, 0.9854312539100647, 0.9401386380195618, 0.967275083065033, 0.9741988182067871, 0.9785670638084412, 0.8284891843795776, 0.8402778506278992, 0.9524174332618713, 0.8293037414550781, 0.8879172801971436, 0.9697843194007874, 0.9592074751853943, 0.9573857188224792, 0.9364710450172424, 0.9662812948226929, 0.9689092636108398, 0.9699411988258362, 0.9774553775787354, 0.9673416614532471, 0.9735055565834045, 0.9633100628852844, 0.9768798351287842, 0.9842830300331116, 0.988649845123291, 0.9507537484169006, 0.9919418096542358, 0.9773826003074646, 0.9889861345291138, 0.9733577370643616, 0.9782646894454956, 0.9648590087890625, 0.9776365756988525, 0.9446520209312439, 0.9799249172210693, 0.9900490045547485, 0.9597948789596558, 0.9688136577606201, 0.9787431359291077, 0.9838570356369019, 0.9708094000816345, 0.9933117032051086, 0.9816490411758423, 0.9946432113647461, 0.9690493941307068, 0.9600059986114502, 0.9754003882408142, 0.9841142892837524, 0.9808561205863953, 0.9730039834976196, 0.9742618799209595, 0.986799955368042, 0.987190842628479, 0.9742856025695801, 0.9904088377952576, 0.9931991696357727, 0.9791560173034668, 0.9931545257568359, 0.9788708090782166, 0.9859246611595154, 0.992336094379425, 0.9854292869567871, 0.9870079159736633, 0.9657392501831055, 0.9753308296203613, 0.9876271486282349, 0.9738368391990662, 0.9821439385414124, 0.989652156829834, 0.9735421538352966, 0.9839847683906555, 0.9630492925643921, 0.9821033477783203, 0.9774649143218994, 0.9582743644714355, 0.9908820390701294, 0.9829055070877075, 0.9784333109855652, 0.9835079908370972, 0.9750413298606873, 0.9819597601890564, 0.9884836077690125, 0.9754090905189514, 0.9833692908287048, 0.9914290308952332, 0.9796224236488342, 0.9550920724868774, 0.9578207731246948, 0.957302987575531, 0.9866165518760681, 0.9808761477470398, 0.9673752784729004, 0.9234168529510498, 0.9303131699562073, 0.8942703604698181, 0.9397566318511963, 0.9460334181785583, 0.9510858654975891, 0.9773863554000854, 0.8336782455444336, 0.8876238465309143, 0.984212338924408, 0.973118007183075], "coloraxis": "coloraxis", "opacity": 0.5, "symbol": "circle"}, "mode": "markers", "name": "0", "showlegend": true, "subplot": "ternary", "type": "scatterternary"}], "layout": {"coloraxis": {"colorbar": {"title": {"text": "prob"}}, "colorscale": [[0.0, "rgb(0,0,255)"], [1.0, "rgb(255,0,0)"]]}, "legend": {"orientation": "h", "title": {"text": "sort_idx"}, "tracegroupgap": 0}, "margin": {"t": 60}, "template": {"data": {"candlestick": [{"decreasing": {"line": {"color": "#ff2b2b"}}, "increasing": {"line": {"color": "#29b09d"}}, "type": "candlestick"}], "contourcarpet": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contourcarpet"}], "contour": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contour"}], "heatmap": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "heatmap"}], "histogram2d": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "histogram2d"}], "icicle": [{"textfont": {"color": "white"}, "type": "icicle"}], "sankey": [{"textfont": {"color": "#808495"}, "type": "sankey"}], "scatter": [{"marker": {"line": {"width": 0}}, "type": "scatter"}], "table": [{"cells": {"fill": {"color": "#ffffff"}, "font": {"color": "#262730"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "header": {"fill": {"color": "rgba(248, 249, 251, 1)"}, "font": {"color": "#808495"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "type": "table"}], "waterfall": [{"connector": {"line": {"color": "#808495", "width": 2}}, "decreasing": {"marker": {"color": "#ff2b2b"}}, "increasing": {"marker": {"color": "#29b09d"}}, "totals": {"marker": {"color": "#0068c9"}}, "type": "waterfall"}]}, "layout": {"coloraxis": {"colorbar": {"len": 0.75, "outlinecolor": "rgba(0,0,0,0)", "outlinewidth": 8, "thickness": 16, "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}}, "xpad": 24, "y": 0.5745}}, "colorscale": {"diverging": [[0.0, "#7d353b"], [0.1, "#bd4043"], [0.2, "#ff4b4b"], [0.3, "#ff8c8c"], [0.4, "#ffc7c7"], [0.5, "#a6dcff"], [0.6, "#60b4ff"], [0.7, "#1c83e1"], [0.8, "#0054a3"], [0.9, "#004280"], [1.0, "#000031"]], "sequential": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "sequentialminus": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]]}, "colorway": ["#0068c9", "#83c9ff", "#ff2b2b", "#ffabab", "#29b09d", "#7defa1", "#ff8700", "#ffd16a", "#6d3fc0", "#d5dae5"], "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}, "hoverlabel": {"bgcolor": "#ffffff", "bordercolor": "rgba(49, 51, 63, 0.2)", "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "legend": {"bordercolor": "rgba(0,0,0,0)", "borderwidth": 0, "font": {"color": "#262730", "size": 12}, "title": {"font": {"color": "#808495", "size": 12}, "side": "top"}, "valign": "top"}, "margin": {"l": 0, "pad": 8, "r": 0}, "paper_bgcolor": "#ffffff", "plot_bgcolor": "#ffffff", "ternary": {"aaxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "baxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "bgcolor": "#ffffff", "caxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}}, "title": {"font": {"color": "#31333F", "family": "\"Source Sans Pro\", sans-serif", "size": 16}, "pad": {"l": 4}, "x": 0, "xanchor": "left"}, "xaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "rangeselector": {"bgcolor": "#ffffff", "bordercolor": "#e6eaf1", "borderwidth": 1, "x": 0}, "showgrid": false, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "title": {"font": {"color": "#808495", "size": 14}, "standoff": 20}, "zeroline": false, "zerolinecolor": "#e6eaf1"}, "yaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}, "standoff": 24}, "zerolinecolor": "#e6eaf1"}}}, "ternary": {"aaxis": {"title": {"text": "attention"}}, "baxis": {"title": {"text": "bias"}}, "caxis": {"title": {"text": "alibi"}}, "domain": {"x": [0.0, 1.0], "y": [0.0, 1.0]}}, "title": {"text": "Attention Breakdown (Layer 21, Head 29)"}}, "metadata": {"sentence_id": 0, "layer_id": 21, "head_id": 29, "accounted_probability": 0.5, "max_tokens_per_row": 11, "creation_date": "2025-01-23 00:10:28.898477", "page": {"page_script_hash": "a81f7f5ae171c15a95155bca2157e9b6", "page_name": "ATTN_-_Attention_Focus", "icon": "", "script_path": "/workspaces/llm-research/app/pages/301_ATTN - Attention Focus.py"}}}