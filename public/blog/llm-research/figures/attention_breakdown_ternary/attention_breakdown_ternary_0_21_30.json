{"data": [{"a": [0.03668344020843506, 0.9864733219146729, 0.49482834339141846, 1.0923540592193604, 0.8120174407958984, 0.9639763832092285, 1.0123271942138672, 0.6836907863616943, 1.0878973007202148, 0.3558824062347412, 0.6626958847045898, 0.40043962001800537, 0.23414015769958496, 0.6072249412536621, 0.8160858154296875, 0.19503438472747803, 0.8021900653839111, 0.5466498136520386, 0.5395915508270264, 0.6629593372344971, 0.6812167167663574, 0.7413938045501709, 0.7632145881652832, 1.157454490661621, 0.7671067714691162, 0.6782283782958984, 0.688640832901001, 0.9543952941894531, 0.7183821201324463, 0.7418069839477539, 0.48065900802612305, 0.9469599723815918, 0.8200922012329102, 0.813389778137207, 1.030207872390747, 0.7861857414245605, 0.9023013114929199, 0.8256776332855225, 0.8444132804870605, 0.8917257785797119, 0.7450060844421387, 0.6196978092193604, 0.760465145111084, 0.7823817729949951, 0.7541055679321289, 0.4672720432281494, 0.4302133321762085, 0.9109959602355957, 0.8518483638763428, 0.44220149517059326, 0.6828436851501465, 0.9778833389282227, 0.646186113357544, 0.8838703632354736, 0.6812684535980225, 0.7557229995727539, 0.8838098049163818, 1.1243093013763428, 0.9012002944946289, 0.9030530452728271, 0.6941832304000854, 0.9812774658203125, 0.6335489749908447, 1.0695874691009521, 1.0049865245819092, 0.9807436466217041, 0.8594045639038086, 0.5881892442703247, 0.7641417980194092, 1.0200302600860596, 1.0930914878845215, 0.0, 0.4310460090637207, 0.6875276565551758, 0.6868528127670288, 0.7236542701721191, 0.9789743423461914, 0.6514248847961426, 0.4749220609664917, 0.8007888793945312, 0.8580548763275146, 0.7041304111480713, 0.7972855567932129, 1.0914433002471924, 0.3872328996658325, 0.5410366058349609, 0.6919934749603271, 0.9037644863128662, 0.8726904392242432, 0.8158032894134521, 0.8977978229522705, 1.2230534553527832, 1.234405517578125, 1.416616678237915, 1.3141193389892578, 0.930884599685669, 1.07997727394104, 0.8802428245544434, 1.5217816829681396, 1.0734009742736816, 1.4842700958251953, 1.0631580352783203, 1.0121243000030518, 1.464069128036499, 1.3553698062896729, 0.9803755283355713, 0.7445552349090576, 1.0143206119537354, 1.3686528205871582, 1.0278139114379883, 1.1962640285491943, 0.9918093681335449, 0.963857889175415, 0.651495099067688, 1.1778182983398438, 1.0553429126739502, 1.1536531448364258, 1.1775896549224854, 0.6112723350524902, 0.9124112129211426, 0.9858989715576172, 0.36945176124572754, 0.48569726943969727, 1.1629116535186768, 0.6932425498962402, 0.7660131454467773, 0.587824821472168, 0.5246013402938843, 0.8787198066711426, 0.6071163415908813, 0.7478456497192383, 0.5871627330780029, 0.8199105262756348, 1.1027917861938477, 0.9943459033966064, 0.8495602607727051, 0.7855181694030762, 0.95615553855896, 1.540229082107544, 0.5117437839508057, 0.6619738340377808, 1.4328877925872803, 0.8710806369781494, 0.8352935314178467, 0.9119794368743896, 1.044020175933838, 1.0949759483337402, 1.3119144439697266, 1.1866545677185059, 1.3885416984558105, 1.4339749813079834, 1.3872458934783936, 1.244605302810669, 1.4143660068511963, 1.0754656791687012, 1.4083466529846191, 1.101804494857788, 1.525956630706787, 0.921501636505127, 1.441890001296997, 1.2805020809173584, 1.405613660812378, 1.0550134181976318, 1.1195342540740967, 1.0381782054901123, 1.4264466762542725, 1.4287645816802979, 1.4904649257659912, 1.1095669269561768, 0.9673128128051758], "b": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "c": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "hovertemplate": "<b>%{hovertext}</b><br><br>sort_idx=0<br>a=%{a}<br>b=%{b}<br>alibi=%{c}<br>prob=%{marker.color}<extra></extra>", "hovertext": ["Token: 0 (By)<br>Attend to token: 0 (By)<br>Tokens in past: 0<br>Probability: 1.0000<br>Alibi: 0.0<br>Attention: -0.4367<br>Bias: 1.7696", "Token: 1 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 1<br>Probability: 0.9658<br>Alibi: 0.0<br>Attention: 0.5131<br>Bias: 1.7696", "Token: 2 ( end)<br>Attend to token: 0 (By)<br>Tokens in past: 2<br>Probability: 0.9915<br>Alibi: 0.0<br>Attention: 0.0214<br>Bias: 1.7696", "Token: 3 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 3<br>Probability: 0.9971<br>Alibi: 0.0<br>Attention: 0.6190<br>Bias: 1.7696", "Token: 4 ( 2014)<br>Attend to token: 0 (By)<br>Tokens in past: 4<br>Probability: 0.9732<br>Alibi: 0.0<br>Attention: 0.3386<br>Bias: 1.7696", "Token: 5 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 5<br>Probability: 0.9581<br>Alibi: 0.0<br>Attention: 0.4906<br>Bias: 1.7696", "Token: 6 ( we)<br>Attend to token: 0 (By)<br>Tokens in past: 6<br>Probability: 0.9837<br>Alibi: 0.0<br>Attention: 0.5389<br>Bias: 1.7696", "Token: 7 ( plan)<br>Attend to token: 0 (By)<br>Tokens in past: 7<br>Probability: 0.9801<br>Alibi: 0.0<br>Attention: 0.2103<br>Bias: 1.7696", "Token: 8 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 8<br>Probability: 0.9850<br>Alibi: 0.0<br>Attention: 0.6145<br>Bias: 1.7696", "Token: 9 ( rev)<br>Attend to token: 0 (By)<br>Tokens in past: 9<br>Probability: 0.9825<br>Alibi: 0.0<br>Attention: -0.1175<br>Bias: 1.7696", "Token: 10 (amp)<br>Attend to token: 0 (By)<br>Tokens in past: 10<br>Probability: 0.9597<br>Alibi: 0.0<br>Attention: 0.1893<br>Bias: 1.7696", "Token: 11 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 11<br>Probability: 0.9418<br>Alibi: 0.0<br>Attention: -0.0729<br>Bias: 1.7696", "Token: 12 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 12<br>Probability: 0.9188<br>Alibi: 0.0<br>Attention: -0.2392<br>Bias: 1.7696", "Token: 13 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 13<br>Probability: 0.9514<br>Alibi: 0.0<br>Attention: 0.1338<br>Bias: 1.7696", "Token: 14 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 14<br>Probability: 0.9501<br>Alibi: 0.0<br>Attention: 0.3427<br>Bias: 1.7696", "Token: 15 ( disease)<br>Attend to token: 0 (By)<br>Tokens in past: 15<br>Probability: 0.8082<br>Alibi: 0.0<br>Attention: -0.2783<br>Bias: 1.7696", "Token: 16 ( prevention)<br>Attend to token: 0 (By)<br>Tokens in past: 16<br>Probability: 0.9077<br>Alibi: 0.0<br>Attention: 0.3288<br>Bias: 1.7696", "Token: 17 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 17<br>Probability: 0.9350<br>Alibi: 0.0<br>Attention: 0.0733<br>Bias: 1.7696", "Token: 18 ( program)<br>Attend to token: 0 (By)<br>Tokens in past: 18<br>Probability: 0.9358<br>Alibi: 0.0<br>Attention: 0.0662<br>Bias: 1.7696", "Token: 19 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 19<br>Probability: 0.9624<br>Alibi: 0.0<br>Attention: 0.1896<br>Bias: 1.7696", "Token: 20 ( which)<br>Attend to token: 0 (By)<br>Tokens in past: 20<br>Probability: 0.9665<br>Alibi: 0.0<br>Attention: 0.2078<br>Bias: 1.7696", "Token: 21 ( was)<br>Attend to token: 0 (By)<br>Tokens in past: 21<br>Probability: 0.9774<br>Alibi: 0.0<br>Attention: 0.2680<br>Bias: 1.7696", "Token: 22 ( suspended)<br>Attend to token: 0 (By)<br>Tokens in past: 22<br>Probability: 0.9492<br>Alibi: 0.0<br>Attention: 0.2898<br>Bias: 1.7696", "Token: 23 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 23<br>Probability: 0.9726<br>Alibi: 0.0<br>Attention: 0.6841<br>Bias: 1.7696", "Token: 24 ( September)<br>Attend to token: 0 (By)<br>Tokens in past: 24<br>Probability: 0.9858<br>Alibi: 0.0<br>Attention: 0.2937<br>Bias: 1.7696", "Token: 25 ( 2013)<br>Attend to token: 0 (By)<br>Tokens in past: 25<br>Probability: 0.9740<br>Alibi: 0.0<br>Attention: 0.2048<br>Bias: 1.7696", "Token: 26 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 26<br>Probability: 0.9359<br>Alibi: 0.0<br>Attention: 0.2153<br>Bias: 1.7696", "Token: 27 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 27<br>Probability: 0.9473<br>Alibi: 0.0<br>Attention: 0.4810<br>Bias: 1.7696", "Token: 28 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 28<br>Probability: 0.9325<br>Alibi: 0.0<br>Attention: 0.2450<br>Bias: 1.7696", "Token: 29 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 29<br>Probability: 0.9682<br>Alibi: 0.0<br>Attention: 0.2684<br>Bias: 1.7696", "Token: 30 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 30<br>Probability: 0.8351<br>Alibi: 0.0<br>Attention: 0.0073<br>Bias: 1.7696", "Token: 31 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 31<br>Probability: 0.9229<br>Alibi: 0.0<br>Attention: 0.4736<br>Bias: 1.7696", "Token: 32 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 32<br>Probability: 0.9660<br>Alibi: 0.0<br>Attention: 0.3467<br>Bias: 1.7696", "Token: 33 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 33<br>Probability: 0.9530<br>Alibi: 0.0<br>Attention: 0.3400<br>Bias: 1.7696", "Token: 34 ( at)<br>Attend to token: 0 (By)<br>Tokens in past: 34<br>Probability: 0.9514<br>Alibi: 0.0<br>Attention: 0.5568<br>Bias: 1.7696", "Token: 35 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 35<br>Probability: 0.9135<br>Alibi: 0.0<br>Attention: 0.3128<br>Bias: 1.7696", "Token: 36 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 36<br>Probability: 0.8576<br>Alibi: 0.0<br>Attention: 0.4289<br>Bias: 1.7696", "Token: 37 ( centers)<br>Attend to token: 0 (By)<br>Tokens in past: 37<br>Probability: 0.9408<br>Alibi: 0.0<br>Attention: 0.3523<br>Bias: 1.7696", "Token: 38 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 38<br>Probability: 0.9297<br>Alibi: 0.0<br>Attention: 0.3710<br>Bias: 1.7696", "Token: 39 ( group)<br>Attend to token: 0 (By)<br>Tokens in past: 39<br>Probability: 0.9555<br>Alibi: 0.0<br>Attention: 0.4183<br>Bias: 1.7696", "Token: 40 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 40<br>Probability: 0.9708<br>Alibi: 0.0<br>Attention: 0.2716<br>Bias: 1.7696", "Token: 41 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 41<br>Probability: 0.9572<br>Alibi: 0.0<br>Attention: 0.1463<br>Bias: 1.7696", "Token: 42 ( specific)<br>Attend to token: 0 (By)<br>Tokens in past: 42<br>Probability: 0.9621<br>Alibi: 0.0<br>Attention: 0.2871<br>Bias: 1.7696", "Token: 43 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 43<br>Probability: 0.9726<br>Alibi: 0.0<br>Attention: 0.3090<br>Bias: 1.7696", "Token: 44 ( ()<br>Attend to token: 0 (By)<br>Tokens in past: 44<br>Probability: 0.9790<br>Alibi: 0.0<br>Attention: 0.2807<br>Bias: 1.7696", "Token: 45 (Di)<br>Attend to token: 0 (By)<br>Tokens in past: 45<br>Probability: 0.7428<br>Alibi: 0.0<br>Attention: -0.0061<br>Bias: 1.7696", "Token: 46 (abetes)<br>Attend to token: 0 (By)<br>Tokens in past: 46<br>Probability: 0.9589<br>Alibi: 0.0<br>Attention: -0.0432<br>Bias: 1.7696", "Token: 47 (,.)<br>Attend to token: 0 (By)<br>Tokens in past: 47<br>Probability: 0.9705<br>Alibi: 0.0<br>Attention: 0.4376<br>Bias: 1.7696", "Token: 48 ( Hy)<br>Attend to token: 0 (By)<br>Tokens in past: 48<br>Probability: 0.9596<br>Alibi: 0.0<br>Attention: 0.3785<br>Bias: 1.7696", "Token: 49 (pert)<br>Attend to token: 0 (By)<br>Tokens in past: 49<br>Probability: 0.9642<br>Alibi: 0.0<br>Attention: -0.0312<br>Bias: 1.7696", "Token: 50 (ension)<br>Attend to token: 0 (By)<br>Tokens in past: 50<br>Probability: 0.9461<br>Alibi: 0.0<br>Attention: 0.2095<br>Bias: 1.7696", "Token: 51 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 51<br>Probability: 0.9694<br>Alibi: 0.0<br>Attention: 0.5045<br>Bias: 1.7696", "Token: 52 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 52<br>Probability: 0.9795<br>Alibi: 0.0<br>Attention: 0.1728<br>Bias: 1.7696", "Token: 53 (.),)<br>Attend to token: 0 (By)<br>Tokens in past: 53<br>Probability: 0.9641<br>Alibi: 0.0<br>Attention: 0.4105<br>Bias: 1.7696", "Token: 54 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 54<br>Probability: 0.9681<br>Alibi: 0.0<br>Attention: 0.2079<br>Bias: 1.7696", "Token: 55 ( well)<br>Attend to token: 0 (By)<br>Tokens in past: 55<br>Probability: 0.9714<br>Alibi: 0.0<br>Attention: 0.2823<br>Bias: 1.7696", "Token: 56 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 56<br>Probability: 0.9644<br>Alibi: 0.0<br>Attention: 0.4104<br>Bias: 1.7696", "Token: 57 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 57<br>Probability: 0.9403<br>Alibi: 0.0<br>Attention: 0.6509<br>Bias: 1.7696", "Token: 58 ( forums)<br>Attend to token: 0 (By)<br>Tokens in past: 58<br>Probability: 0.9552<br>Alibi: 0.0<br>Attention: 0.4278<br>Bias: 1.7696", "Token: 59 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 59<br>Probability: 0.9458<br>Alibi: 0.0<br>Attention: 0.4297<br>Bias: 1.7696", "Token: 60 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 60<br>Probability: 0.6756<br>Alibi: 0.0<br>Attention: 0.2208<br>Bias: 1.7696", "Token: 61 ( fair)<br>Attend to token: 0 (By)<br>Tokens in past: 61<br>Probability: 0.9340<br>Alibi: 0.0<br>Attention: 0.5079<br>Bias: 1.7696", "Token: 62 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 62<br>Probability: 0.9008<br>Alibi: 0.0<br>Attention: 0.1602<br>Bias: 1.7696", "Token: 63 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 63<br>Probability: 0.9421<br>Alibi: 0.0<br>Attention: 0.5962<br>Bias: 1.7696", "Token: 64 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 64<br>Probability: 0.9549<br>Alibi: 0.0<br>Attention: 0.5316<br>Bias: 1.7696", "Token: 65 ( recruit)<br>Attend to token: 0 (By)<br>Tokens in past: 65<br>Probability: 0.9360<br>Alibi: 0.0<br>Attention: 0.5074<br>Bias: 1.7696", "Token: 66 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 66<br>Probability: 0.9440<br>Alibi: 0.0<br>Attention: 0.3860<br>Bias: 1.7696", "Token: 67 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 67<br>Probability: 0.6805<br>Alibi: 0.0<br>Attention: 0.1148<br>Bias: 1.7696", "Token: 68 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 68<br>Probability: 0.9282<br>Alibi: 0.0<br>Attention: 0.2908<br>Bias: 1.7696", "Token: 69 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 69<br>Probability: 0.9551<br>Alibi: 0.0<br>Attention: 0.5466<br>Bias: 1.7696", "Token: 70 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 70<br>Probability: 0.9538<br>Alibi: 0.0<br>Attention: 0.6197<br>Bias: 1.7696", "Token: 71 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 71<br>Probability: 0.7996<br>Alibi: 0.0<br>Attention: -0.4734<br>Bias: 1.7696", "Token: 72 ( assessment)<br>Attend to token: 0 (By)<br>Tokens in past: 72<br>Probability: 0.9342<br>Alibi: 0.0<br>Attention: -0.0423<br>Bias: 1.7696", "Token: 73 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 73<br>Probability: 0.9076<br>Alibi: 0.0<br>Attention: 0.2141<br>Bias: 1.7696", "Token: 74 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 74<br>Probability: 0.8959<br>Alibi: 0.0<br>Attention: 0.2135<br>Bias: 1.7696", "Token: 75 ( area)<br>Attend to token: 0 (By)<br>Tokens in past: 75<br>Probability: 0.9237<br>Alibi: 0.0<br>Attention: 0.2503<br>Bias: 1.7696", "Token: 76 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 76<br>Probability: 0.8965<br>Alibi: 0.0<br>Attention: 0.5056<br>Bias: 1.7696", "Token: 77 ( intervention)<br>Attend to token: 0 (By)<br>Tokens in past: 77<br>Probability: 0.9026<br>Alibi: 0.0<br>Attention: 0.1780<br>Bias: 1.7696", "Token: 78 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 78<br>Probability: 0.9315<br>Alibi: 0.0<br>Attention: 0.0015<br>Bias: 1.7696", "Token: 79 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 79<br>Probability: 0.9645<br>Alibi: 0.0<br>Attention: 0.3274<br>Bias: 1.7696", "Token: 80 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 80<br>Probability: 0.9619<br>Alibi: 0.0<br>Attention: 0.3847<br>Bias: 1.7696", "Token: 81 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 81<br>Probability: 0.9587<br>Alibi: 0.0<br>Attention: 0.2307<br>Bias: 1.7696", "Token: 82 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 82<br>Probability: 0.9263<br>Alibi: 0.0<br>Attention: 0.3239<br>Bias: 1.7696", "Token: 83 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 83<br>Probability: 0.9654<br>Alibi: 0.0<br>Attention: 0.6181<br>Bias: 1.7696", "Token: 84 ( economic)<br>Attend to token: 0 (By)<br>Tokens in past: 84<br>Probability: 0.8338<br>Alibi: 0.0<br>Attention: -0.0861<br>Bias: 1.7696", "Token: 85 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 85<br>Probability: 0.9175<br>Alibi: 0.0<br>Attention: 0.0677<br>Bias: 1.7696", "Token: 86 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 86<br>Probability: 0.9525<br>Alibi: 0.0<br>Attention: 0.2186<br>Bias: 1.7696", "Token: 87 ( educate)<br>Attend to token: 0 (By)<br>Tokens in past: 87<br>Probability: 0.9697<br>Alibi: 0.0<br>Attention: 0.4304<br>Bias: 1.7696", "Token: 88 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 88<br>Probability: 0.9568<br>Alibi: 0.0<br>Attention: 0.3993<br>Bias: 1.7696", "Token: 89 ( encourage)<br>Attend to token: 0 (By)<br>Tokens in past: 89<br>Probability: 0.9735<br>Alibi: 0.0<br>Attention: 0.3424<br>Bias: 1.7696", "Token: 90 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 90<br>Probability: 0.9688<br>Alibi: 0.0<br>Attention: 0.4244<br>Bias: 1.7696", "Token: 91 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 91<br>Probability: 0.9846<br>Alibi: 0.0<br>Attention: 0.7497<br>Bias: 1.7696", "Token: 92 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 92<br>Probability: 0.9645<br>Alibi: 0.0<br>Attention: 0.7610<br>Bias: 1.7696", "Token: 93 ( preventive)<br>Attend to token: 0 (By)<br>Tokens in past: 93<br>Probability: 0.9752<br>Alibi: 0.0<br>Attention: 0.9432<br>Bias: 1.7696", "Token: 94 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 94<br>Probability: 0.9721<br>Alibi: 0.0<br>Attention: 0.8407<br>Bias: 1.7696", "Token: 95 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 95<br>Probability: 0.9433<br>Alibi: 0.0<br>Attention: 0.4575<br>Bias: 1.7696", "Token: 96 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 96<br>Probability: 0.9564<br>Alibi: 0.0<br>Attention: 0.6066<br>Bias: 1.7696", "Token: 97 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 97<br>Probability: 0.9589<br>Alibi: 0.0<br>Attention: 0.4069<br>Bias: 1.7696", "Token: 98 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 98<br>Probability: 0.9655<br>Alibi: 0.0<br>Attention: 1.0484<br>Bias: 1.7696", "Token: 99 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 99<br>Probability: 0.9426<br>Alibi: 0.0<br>Attention: 0.6000<br>Bias: 1.7696", "Token: 100 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 100<br>Probability: 0.9681<br>Alibi: 0.0<br>Attention: 1.0109<br>Bias: 1.7696", "Token: 101 ( prenatal)<br>Attend to token: 0 (By)<br>Tokens in past: 101<br>Probability: 0.9724<br>Alibi: 0.0<br>Attention: 0.5898<br>Bias: 1.7696", "Token: 102 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 102<br>Probability: 0.9748<br>Alibi: 0.0<br>Attention: 0.5387<br>Bias: 1.7696", "Token: 103 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 103<br>Probability: 0.9793<br>Alibi: 0.0<br>Attention: 0.9907<br>Bias: 1.7696", "Token: 104 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 104<br>Probability: 0.9733<br>Alibi: 0.0<br>Attention: 0.8820<br>Bias: 1.7696", "Token: 105 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 105<br>Probability: 0.8152<br>Alibi: 0.0<br>Attention: 0.5070<br>Bias: 1.7696", "Token: 106 ( maintenance)<br>Attend to token: 0 (By)<br>Tokens in past: 106<br>Probability: 0.9055<br>Alibi: 0.0<br>Attention: 0.2712<br>Bias: 1.7696", "Token: 107 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 107<br>Probability: 0.9846<br>Alibi: 0.0<br>Attention: 0.5409<br>Bias: 1.7696", "Token: 108 ( chronic)<br>Attend to token: 0 (By)<br>Tokens in past: 108<br>Probability: 0.9891<br>Alibi: 0.0<br>Attention: 0.8953<br>Bias: 1.7696", "Token: 109 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 109<br>Probability: 0.9744<br>Alibi: 0.0<br>Attention: 0.5544<br>Bias: 1.7696", "Token: 110 ( diseases)<br>Attend to token: 0 (By)<br>Tokens in past: 110<br>Probability: 0.9743<br>Alibi: 0.0<br>Attention: 0.7229<br>Bias: 1.7696", "Token: 111 (..)<br>Attend to token: 0 (By)<br>Tokens in past: 111<br>Probability: 0.9111<br>Alibi: 0.0<br>Attention: 0.5184<br>Bias: 1.7696", "Token: 112 ( The)<br>Attend to token: 0 (By)<br>Tokens in past: 112<br>Probability: 0.9717<br>Alibi: 0.0<br>Attention: 0.4905<br>Bias: 1.7696", "Token: 113 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 113<br>Probability: 0.8248<br>Alibi: 0.0<br>Attention: 0.1781<br>Bias: 1.7696", "Token: 114 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 114<br>Probability: 0.9529<br>Alibi: 0.0<br>Attention: 0.7044<br>Bias: 1.7696", "Token: 115 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 115<br>Probability: 0.9506<br>Alibi: 0.0<br>Attention: 0.5820<br>Bias: 1.7696", "Token: 116 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 116<br>Probability: 0.9613<br>Alibi: 0.0<br>Attention: 0.6803<br>Bias: 1.7696", "Token: 117 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 117<br>Probability: 0.9610<br>Alibi: 0.0<br>Attention: 0.7042<br>Bias: 1.7696", "Token: 118 ( pregnant)<br>Attend to token: 0 (By)<br>Tokens in past: 118<br>Probability: 0.9625<br>Alibi: 0.0<br>Attention: 0.1379<br>Bias: 1.7696", "Token: 119 ( women)<br>Attend to token: 0 (By)<br>Tokens in past: 119<br>Probability: 0.9689<br>Alibi: 0.0<br>Attention: 0.4390<br>Bias: 1.7696", "Token: 120 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 120<br>Probability: 0.9733<br>Alibi: 0.0<br>Attention: 0.5125<br>Bias: 1.7696", "Token: 121 ( newborn)<br>Attend to token: 0 (By)<br>Tokens in past: 121<br>Probability: 0.9850<br>Alibi: 0.0<br>Attention: -0.1039<br>Bias: 1.7696", "Token: 122 (s)<br>Attend to token: 0 (By)<br>Tokens in past: 122<br>Probability: 0.9799<br>Alibi: 0.0<br>Attention: 0.0123<br>Bias: 1.7696", "Token: 123 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 123<br>Probability: 0.9872<br>Alibi: 0.0<br>Attention: 0.6895<br>Bias: 1.7696", "Token: 124 ( infants)<br>Attend to token: 0 (By)<br>Tokens in past: 124<br>Probability: 0.9760<br>Alibi: 0.0<br>Attention: 0.2199<br>Bias: 1.7696", "Token: 125 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 125<br>Probability: 0.9897<br>Alibi: 0.0<br>Attention: 0.2926<br>Bias: 1.7696", "Token: 126 ( high)<br>Attend to token: 0 (By)<br>Tokens in past: 126<br>Probability: 0.9753<br>Alibi: 0.0<br>Attention: 0.1144<br>Bias: 1.7696", "Token: 127 ( risk)<br>Attend to token: 0 (By)<br>Tokens in past: 127<br>Probability: 0.9645<br>Alibi: 0.0<br>Attention: 0.0512<br>Bias: 1.7696", "Token: 128 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 128<br>Probability: 0.9813<br>Alibi: 0.0<br>Attention: 0.4053<br>Bias: 1.7696", "Token: 129 ( malnutrition)<br>Attend to token: 0 (By)<br>Tokens in past: 129<br>Probability: 0.9766<br>Alibi: 0.0<br>Attention: 0.1337<br>Bias: 1.7696", "Token: 130 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 130<br>Probability: 0.9737<br>Alibi: 0.0<br>Attention: 0.2745<br>Bias: 1.7696", "Token: 131 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 131<br>Probability: 0.9732<br>Alibi: 0.0<br>Attention: 0.1138<br>Bias: 1.7696", "Token: 132 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 132<br>Probability: 0.9809<br>Alibi: 0.0<br>Attention: 0.3465<br>Bias: 1.7696", "Token: 133 ( obtain)<br>Attend to token: 0 (By)<br>Tokens in past: 133<br>Probability: 0.9917<br>Alibi: 0.0<br>Attention: 0.6294<br>Bias: 1.7696", "Token: 134 ( proper)<br>Attend to token: 0 (By)<br>Tokens in past: 134<br>Probability: 0.9939<br>Alibi: 0.0<br>Attention: 0.5210<br>Bias: 1.7696", "Token: 135 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 135<br>Probability: 0.9640<br>Alibi: 0.0<br>Attention: 0.3762<br>Bias: 1.7696", "Token: 136 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 136<br>Probability: 0.9589<br>Alibi: 0.0<br>Attention: 0.3121<br>Bias: 1.7696", "Token: 137 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 137<br>Probability: 0.9607<br>Alibi: 0.0<br>Attention: 0.4828<br>Bias: 1.7696", "Token: 138 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 138<br>Probability: 0.9908<br>Alibi: 0.0<br>Attention: 1.0668<br>Bias: 1.7696", "Token: 139 ( food)<br>Attend to token: 0 (By)<br>Tokens in past: 139<br>Probability: 0.9424<br>Alibi: 0.0<br>Attention: 0.0384<br>Bias: 1.7696", "Token: 140 ( assistance)<br>Attend to token: 0 (By)<br>Tokens in past: 140<br>Probability: 0.9227<br>Alibi: 0.0<br>Attention: 0.1886<br>Bias: 1.7696", "Token: 141 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 141<br>Probability: 0.9834<br>Alibi: 0.0<br>Attention: 0.9595<br>Bias: 1.7696", "Token: 142 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 142<br>Probability: 0.9706<br>Alibi: 0.0<br>Attention: 0.3977<br>Bias: 1.7696", "Token: 143 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 143<br>Probability: 0.9171<br>Alibi: 0.0<br>Attention: 0.3619<br>Bias: 1.7696", "Token: 144 ( They)<br>Attend to token: 0 (By)<br>Tokens in past: 144<br>Probability: 0.9579<br>Alibi: 0.0<br>Attention: 0.4386<br>Bias: 1.7696", "Token: 145 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 145<br>Probability: 0.9683<br>Alibi: 0.0<br>Attention: 0.5706<br>Bias: 1.7696", "Token: 146 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 146<br>Probability: 0.9669<br>Alibi: 0.0<br>Attention: 0.6216<br>Bias: 1.7696", "Token: 147 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 147<br>Probability: 0.9787<br>Alibi: 0.0<br>Attention: 0.8385<br>Bias: 1.7696", "Token: 148 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 148<br>Probability: 0.9738<br>Alibi: 0.0<br>Attention: 0.7133<br>Bias: 1.7696", "Token: 149 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 149<br>Probability: 0.9881<br>Alibi: 0.0<br>Attention: 0.9152<br>Bias: 1.7696", "Token: 150 ( certain)<br>Attend to token: 0 (By)<br>Tokens in past: 150<br>Probability: 0.9861<br>Alibi: 0.0<br>Attention: 0.9606<br>Bias: 1.7696", "Token: 151 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 151<br>Probability: 0.9795<br>Alibi: 0.0<br>Attention: 0.9139<br>Bias: 1.7696", "Token: 152 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 152<br>Probability: 0.9804<br>Alibi: 0.0<br>Attention: 0.7712<br>Bias: 1.7696", "Token: 153 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 153<br>Probability: 0.9722<br>Alibi: 0.0<br>Attention: 0.9410<br>Bias: 1.7696", "Token: 154 ( HIV)<br>Attend to token: 0 (By)<br>Tokens in past: 154<br>Probability: 0.9476<br>Alibi: 0.0<br>Attention: 0.6021<br>Bias: 1.7696", "Token: 155 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 155<br>Probability: 0.9803<br>Alibi: 0.0<br>Attention: 0.9350<br>Bias: 1.7696", "Token: 156 ( Tu)<br>Attend to token: 0 (By)<br>Tokens in past: 156<br>Probability: 0.9660<br>Alibi: 0.0<br>Attention: 0.6284<br>Bias: 1.7696", "Token: 157 (ber)<br>Attend to token: 0 (By)<br>Tokens in past: 157<br>Probability: 0.9941<br>Alibi: 0.0<br>Attention: 1.0526<br>Bias: 1.7696", "Token: 158 (culosis)<br>Attend to token: 0 (By)<br>Tokens in past: 158<br>Probability: 0.9681<br>Alibi: 0.0<br>Attention: 0.4481<br>Bias: 1.7696", "Token: 159 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 159<br>Probability: 0.9800<br>Alibi: 0.0<br>Attention: 0.9685<br>Bias: 1.7696", "Token: 160 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 160<br>Probability: 0.9701<br>Alibi: 0.0<br>Attention: 0.8071<br>Bias: 1.7696", "Token: 161 ( Mal)<br>Attend to token: 0 (By)<br>Tokens in past: 161<br>Probability: 0.9122<br>Alibi: 0.0<br>Attention: 0.9322<br>Bias: 1.7696", "Token: 162 (aria)<br>Attend to token: 0 (By)<br>Tokens in past: 162<br>Probability: 0.9655<br>Alibi: 0.0<br>Attention: 0.5816<br>Bias: 1.7696", "Token: 163 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 163<br>Probability: 0.9696<br>Alibi: 0.0<br>Attention: 0.6462<br>Bias: 1.7696", "Token: 164 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 164<br>Probability: 0.9779<br>Alibi: 0.0<br>Attention: 0.5648<br>Bias: 1.7696", "Token: 165 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 165<br>Probability: 0.9849<br>Alibi: 0.0<br>Attention: 0.9531<br>Bias: 1.7696", "Token: 166 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 166<br>Probability: 0.9804<br>Alibi: 0.0<br>Attention: 0.9554<br>Bias: 1.7696", "Token: 167 ( available)<br>Attend to token: 0 (By)<br>Tokens in past: 167<br>Probability: 0.9871<br>Alibi: 0.0<br>Attention: 1.0171<br>Bias: 1.7696", "Token: 168 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 168<br>Probability: 0.9668<br>Alibi: 0.0<br>Attention: 0.6362<br>Bias: 1.7696", "Token: 169 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 169<br>Probability: 0.9045<br>Alibi: 0.0<br>Attention: 0.4939<br>Bias: 1.7696"], "legendgroup": "0", "marker": {"color": [1.0, 0.965794026851654, 0.9915454387664795, 0.9970557689666748, 0.9731595516204834, 0.9580503106117249, 0.9837104082107544, 0.9801274538040161, 0.985032320022583, 0.9825423359870911, 0.9596517086029053, 0.941765546798706, 0.9187855124473572, 0.9514147043228149, 0.9501104354858398, 0.8082461953163147, 0.9076592922210693, 0.9350070357322693, 0.9357526302337646, 0.9624205827713013, 0.9665094614028931, 0.9774083495140076, 0.9492436647415161, 0.972601592540741, 0.9857608079910278, 0.9740265607833862, 0.9358669519424438, 0.9472870826721191, 0.9325307011604309, 0.9681743383407593, 0.835053563117981, 0.9228563904762268, 0.965957760810852, 0.9529579877853394, 0.9513742327690125, 0.9134911894798279, 0.8576323986053467, 0.9408270716667175, 0.9296624064445496, 0.9554761052131653, 0.9708139300346375, 0.9572229385375977, 0.9621075391769409, 0.9726113677024841, 0.9790323972702026, 0.7427666783332825, 0.9589365720748901, 0.970458447933197, 0.9595808982849121, 0.9641690254211426, 0.946139395236969, 0.9694362878799438, 0.9794940948486328, 0.9640557765960693, 0.9681278467178345, 0.9714054465293884, 0.9644089937210083, 0.9402599334716797, 0.955242395401001, 0.9458088874816895, 0.6755540370941162, 0.9339632987976074, 0.9007891416549683, 0.9420830607414246, 0.9549022316932678, 0.9360060691833496, 0.9439737796783447, 0.6805283427238464, 0.92823725938797, 0.9551176428794861, 0.9538430571556091, 0.7996079921722412, 0.9342482089996338, 0.9076056480407715, 0.8958870768547058, 0.9236614108085632, 0.896533727645874, 0.9025641083717346, 0.9314836263656616, 0.9645440578460693, 0.9618656039237976, 0.9586702585220337, 0.9263479113578796, 0.9653512239456177, 0.8337791562080383, 0.9174583554267883, 0.9525158405303955, 0.9697443842887878, 0.9568215012550354, 0.9735296368598938, 0.9688172340393066, 0.9846068620681763, 0.9644561409950256, 0.9751851558685303, 0.9721179604530334, 0.9433411955833435, 0.9563713073730469, 0.958909809589386, 0.9655025601387024, 0.9425742030143738, 0.9680900573730469, 0.9723776578903198, 0.974811851978302, 0.9793334603309631, 0.9732561707496643, 0.8152086734771729, 0.9055015444755554, 0.9846481084823608, 0.9891370534896851, 0.9744267463684082, 0.9743004441261292, 0.9111143946647644, 0.9716702103614807, 0.8248451948165894, 0.9528536796569824, 0.9505890607833862, 0.9612894654273987, 0.9609768390655518, 0.9624826908111572, 0.9689128398895264, 0.9732873439788818, 0.9850409626960754, 0.9798845052719116, 0.9872013330459595, 0.9760118722915649, 0.9897034764289856, 0.9752500057220459, 0.9645302295684814, 0.9812659621238708, 0.9766420125961304, 0.9736831188201904, 0.9732301831245422, 0.980946958065033, 0.9917365908622742, 0.9938715696334839, 0.9639511108398438, 0.958919882774353, 0.9606782793998718, 0.9907922744750977, 0.94244384765625, 0.9226896166801453, 0.9834421277046204, 0.9706101417541504, 0.9171131253242493, 0.9579173922538757, 0.9683471322059631, 0.9668951034545898, 0.9787341356277466, 0.9737546443939209, 0.9880828261375427, 0.9861277341842651, 0.9794515371322632, 0.9804121255874634, 0.972220778465271, 0.947596549987793, 0.9803025722503662, 0.9660372734069824, 0.9941360950469971, 0.9681187868118286, 0.9799930453300476, 0.9701418280601501, 0.912213146686554, 0.9655106067657471, 0.9695932865142822, 0.9779016971588135, 0.9849306344985962, 0.9804481863975525, 0.9870784282684326, 0.9667616486549377, 0.9045226573944092], "coloraxis": "coloraxis", "opacity": 0.5, "symbol": "circle"}, "mode": "markers", "name": "0", "showlegend": true, "subplot": "ternary", "type": "scatterternary"}], "layout": {"coloraxis": {"colorbar": {"title": {"text": "prob"}}, "colorscale": [[0.0, "rgb(0,0,255)"], [1.0, "rgb(255,0,0)"]]}, "legend": {"orientation": "h", "title": {"text": "sort_idx"}, "tracegroupgap": 0}, "margin": {"t": 60}, "template": {"data": {"candlestick": [{"decreasing": {"line": {"color": "#ff2b2b"}}, "increasing": {"line": {"color": "#29b09d"}}, "type": "candlestick"}], "contourcarpet": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contourcarpet"}], "contour": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contour"}], "heatmap": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "heatmap"}], "histogram2d": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "histogram2d"}], "icicle": [{"textfont": {"color": "white"}, "type": "icicle"}], "sankey": [{"textfont": {"color": "#808495"}, "type": "sankey"}], "scatter": [{"marker": {"line": {"width": 0}}, "type": "scatter"}], "table": [{"cells": {"fill": {"color": "#ffffff"}, "font": {"color": "#262730"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "header": {"fill": {"color": "rgba(248, 249, 251, 1)"}, "font": {"color": "#808495"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "type": "table"}], "waterfall": [{"connector": {"line": {"color": "#808495", "width": 2}}, "decreasing": {"marker": {"color": "#ff2b2b"}}, "increasing": {"marker": {"color": "#29b09d"}}, "totals": {"marker": {"color": "#0068c9"}}, "type": "waterfall"}]}, "layout": {"coloraxis": {"colorbar": {"len": 0.75, "outlinecolor": "rgba(0,0,0,0)", "outlinewidth": 8, "thickness": 16, "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}}, "xpad": 24, "y": 0.5745}}, "colorscale": {"diverging": [[0.0, "#7d353b"], [0.1, "#bd4043"], [0.2, "#ff4b4b"], [0.3, "#ff8c8c"], [0.4, "#ffc7c7"], [0.5, "#a6dcff"], [0.6, "#60b4ff"], [0.7, "#1c83e1"], [0.8, "#0054a3"], [0.9, "#004280"], [1.0, "#000031"]], "sequential": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "sequentialminus": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]]}, "colorway": ["#0068c9", "#83c9ff", "#ff2b2b", "#ffabab", "#29b09d", "#7defa1", "#ff8700", "#ffd16a", "#6d3fc0", "#d5dae5"], "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}, "hoverlabel": {"bgcolor": "#ffffff", "bordercolor": "rgba(49, 51, 63, 0.2)", "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "legend": {"bordercolor": "rgba(0,0,0,0)", "borderwidth": 0, "font": {"color": "#262730", "size": 12}, "title": {"font": {"color": "#808495", "size": 12}, "side": "top"}, "valign": "top"}, "margin": {"l": 0, "pad": 8, "r": 0}, "paper_bgcolor": "#ffffff", "plot_bgcolor": "#ffffff", "ternary": {"aaxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "baxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "bgcolor": "#ffffff", "caxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}}, "title": {"font": {"color": "#31333F", "family": "\"Source Sans Pro\", sans-serif", "size": 16}, "pad": {"l": 4}, "x": 0, "xanchor": "left"}, "xaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "rangeselector": {"bgcolor": "#ffffff", "bordercolor": "#e6eaf1", "borderwidth": 1, "x": 0}, "showgrid": false, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "title": {"font": {"color": "#808495", "size": 14}, "standoff": 20}, "zeroline": false, "zerolinecolor": "#e6eaf1"}, "yaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}, "standoff": 24}, "zerolinecolor": "#e6eaf1"}}}, "ternary": {"aaxis": {"title": {"text": "attention"}}, "baxis": {"title": {"text": "bias"}}, "caxis": {"title": {"text": "alibi"}}, "domain": {"x": [0.0, 1.0], "y": [0.0, 1.0]}}, "title": {"text": "Attention Breakdown (Layer 21, Head 30)"}}, "metadata": {"sentence_id": 0, "layer_id": 21, "head_id": 30, "accounted_probability": 0.5, "max_tokens_per_row": 11, "creation_date": "2025-01-23 00:10:31.185078", "page": {"page_script_hash": "a81f7f5ae171c15a95155bca2157e9b6", "page_name": "ATTN_-_Attention_Focus", "icon": "", "script_path": "/workspaces/llm-research/app/pages/301_ATTN - Attention Focus.py"}}}