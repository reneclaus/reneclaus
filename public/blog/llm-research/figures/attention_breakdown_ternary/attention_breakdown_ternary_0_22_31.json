{"data": [{"a": [0.0, 1.3798853158950806, 0.7694778442382812, 1.2550677061080933, 1.003071665763855, 1.007775902748108, 1.2259289026260376, 0.8022043704986572, 0.8185242414474487, 1.1792792081832886, 0.985474705696106, 0.7132896184921265, 0.7818583250045776, 0.9482622146606445, 0.950739860534668, 0.6496801376342773, 0.9797102212905884, 0.7905499935150146, 0.8549642562866211, 0.8119087219238281, 0.9119994640350342, 0.8730320930480957, 1.0605555772781372, 1.491085410118103, 1.1725598573684692, 0.9881068468093872, 0.9987345933914185, 1.0096901655197144, 0.7167993783950806, 0.9801183938980103, 0.9470298290252686, 1.0653668642044067, 0.9111237525939941, 0.8392233848571777, 0.9653072357177734, 0.9097604751586914, 0.9860941171646118, 0.8295376300811768, 0.7837297916412354, 1.0196563005447388, 0.8391711711883545, 0.8324373960494995, 0.8771278858184814, 0.6713674068450928, 0.9850598573684692, 1.356524109840393, 0.897186279296875, 1.0407952070236206, 1.3235610723495483, 0.93904709815979, 0.8691062927246094, 1.290197491645813, 0.8016109466552734, 0.9118678569793701, 0.887836217880249, 0.7302637100219727, 0.9915627241134644, 0.9942499399185181, 0.749417781829834, 0.9841963052749634, 1.02114737033844, 0.8323314189910889, 0.7024117708206177, 1.0603140592575073, 0.7702229022979736, 1.1597880125045776, 1.130560040473938, 1.1405240297317505, 0.8723056316375732, 0.8339762687683105, 1.1026369333267212, 0.525770902633667, 0.637660026550293, 0.8942475318908691, 0.9415206909179688, 0.6123566627502441, 0.9988113641738892, 0.609094500541687, 0.552473783493042, 0.8191794157028198, 0.9336175918579102, 0.8407547473907471, 0.992221474647522, 0.8869965076446533, 0.7725867033004761, 0.505940318107605, 0.7876390218734741, 0.9127860069274902, 0.9204409122467041, 0.9255475997924805, 0.7007184028625488, 0.9296407699584961, 1.099295735359192, 0.9224870204925537, 1.0263592004776, 0.8839676380157471, 0.942523717880249, 0.8072044849395752, 1.333844780921936, 0.8784880638122559, 1.2592946290969849, 0.958747148513794, 0.8761250972747803, 1.237975001335144, 1.161967396736145, 1.320834994316101, 1.015018105506897, 0.9952489137649536, 1.081624150276184, 0.9220280647277832, 0.7906477451324463, 1.0240083932876587, 0.9143533706665039, 1.2099608182907104, 1.2831162214279175, 0.9046335220336914, 0.9901100397109985, 1.0330506563186646, 0.891425609588623, 0.7413949966430664, 0.9083826541900635, 0.4276726245880127, 0.5684459209442139, 0.8945529460906982, 0.6200923919677734, 0.6388969421386719, 0.6109795570373535, 0.6313186883926392, 0.7525694370269775, 0.4049760103225708, 0.7120121717453003, 0.6812120676040649, 0.6885395050048828, 0.9775091409683228, 0.8580989837646484, 0.7603732347488403, 0.7664859294891357, 0.711578369140625, 1.206032395362854, 0.8366752862930298, 0.8393752574920654, 1.2577615976333618, 0.7391142845153809, 0.9801946878433228, 0.9003539085388184, 0.9067709445953369, 0.9321119785308838, 1.1010361909866333, 0.9549140930175781, 1.2133592367172241, 1.0834308862686157, 0.8250293731689453, 1.1983591318130493, 1.50359308719635, 0.8346196413040161, 1.411441683769226, 0.9971946477890015, 1.417646050453186, 0.8327264785766602, 1.6015831232070923, 1.3602935075759888, 1.569968581199646, 0.8528804779052734, 0.9720374345779419, 0.8535990715026855, 0.9556927680969238, 1.325612187385559, 1.286171555519104, 0.9710029363632202, 1.131653904914856], "b": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "c": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "hovertemplate": "<b>%{hovertext}</b><br><br>sort_idx=0<br>a=%{a}<br>b=%{b}<br>alibi=%{c}<br>prob=%{marker.color}<extra></extra>", "hovertext": ["Token: 0 (By)<br>Attend to token: 0 (By)<br>Tokens in past: 0<br>Probability: 1.0000<br>Alibi: 0.0<br>Attention: 1.9525<br>Bias: -0.9189", "Token: 1 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 1<br>Probability: 0.9610<br>Alibi: 0.0<br>Attention: 3.3324<br>Bias: -0.9189", "Token: 2 ( end)<br>Attend to token: 0 (By)<br>Tokens in past: 2<br>Probability: 0.9263<br>Alibi: 0.0<br>Attention: 2.7220<br>Bias: -0.9189", "Token: 3 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 3<br>Probability: 0.9639<br>Alibi: 0.0<br>Attention: 3.2076<br>Bias: -0.9189", "Token: 4 ( 2014)<br>Attend to token: 0 (By)<br>Tokens in past: 4<br>Probability: 0.9097<br>Alibi: 0.0<br>Attention: 2.9556<br>Bias: -0.9189", "Token: 5 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 5<br>Probability: 0.8652<br>Alibi: 0.0<br>Attention: 2.9603<br>Bias: -0.9189", "Token: 6 ( we)<br>Attend to token: 0 (By)<br>Tokens in past: 6<br>Probability: 0.9716<br>Alibi: 0.0<br>Attention: 3.1784<br>Bias: -0.9189", "Token: 7 ( plan)<br>Attend to token: 0 (By)<br>Tokens in past: 7<br>Probability: 0.8830<br>Alibi: 0.0<br>Attention: 2.7547<br>Bias: -0.9189", "Token: 8 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 8<br>Probability: 0.8893<br>Alibi: 0.0<br>Attention: 2.7710<br>Bias: -0.9189", "Token: 9 ( rev)<br>Attend to token: 0 (By)<br>Tokens in past: 9<br>Probability: 0.9538<br>Alibi: 0.0<br>Attention: 3.1318<br>Bias: -0.9189", "Token: 10 (amp)<br>Attend to token: 0 (By)<br>Tokens in past: 10<br>Probability: 0.8255<br>Alibi: 0.0<br>Attention: 2.9380<br>Bias: -0.9189", "Token: 11 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 11<br>Probability: 0.8677<br>Alibi: 0.0<br>Attention: 2.6658<br>Bias: -0.9189", "Token: 12 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 12<br>Probability: 0.8807<br>Alibi: 0.0<br>Attention: 2.7343<br>Bias: -0.9189", "Token: 13 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 13<br>Probability: 0.9180<br>Alibi: 0.0<br>Attention: 2.9008<br>Bias: -0.9189", "Token: 14 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 14<br>Probability: 0.9642<br>Alibi: 0.0<br>Attention: 2.9032<br>Bias: -0.9189", "Token: 15 ( disease)<br>Attend to token: 0 (By)<br>Tokens in past: 15<br>Probability: 0.9228<br>Alibi: 0.0<br>Attention: 2.6022<br>Bias: -0.9189", "Token: 16 ( prevention)<br>Attend to token: 0 (By)<br>Tokens in past: 16<br>Probability: 0.9035<br>Alibi: 0.0<br>Attention: 2.9322<br>Bias: -0.9189", "Token: 17 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 17<br>Probability: 0.9519<br>Alibi: 0.0<br>Attention: 2.7430<br>Bias: -0.9189", "Token: 18 ( program)<br>Attend to token: 0 (By)<br>Tokens in past: 18<br>Probability: 0.8602<br>Alibi: 0.0<br>Attention: 2.8075<br>Bias: -0.9189", "Token: 19 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 19<br>Probability: 0.9170<br>Alibi: 0.0<br>Attention: 2.7644<br>Bias: -0.9189", "Token: 20 ( which)<br>Attend to token: 0 (By)<br>Tokens in past: 20<br>Probability: 0.9350<br>Alibi: 0.0<br>Attention: 2.8645<br>Bias: -0.9189", "Token: 21 ( was)<br>Attend to token: 0 (By)<br>Tokens in past: 21<br>Probability: 0.9314<br>Alibi: 0.0<br>Attention: 2.8255<br>Bias: -0.9189", "Token: 22 ( suspended)<br>Attend to token: 0 (By)<br>Tokens in past: 22<br>Probability: 0.9505<br>Alibi: 0.0<br>Attention: 3.0130<br>Bias: -0.9189", "Token: 23 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 23<br>Probability: 0.9802<br>Alibi: 0.0<br>Attention: 3.4436<br>Bias: -0.9189", "Token: 24 ( September)<br>Attend to token: 0 (By)<br>Tokens in past: 24<br>Probability: 0.9657<br>Alibi: 0.0<br>Attention: 3.1250<br>Bias: -0.9189", "Token: 25 ( 2013)<br>Attend to token: 0 (By)<br>Tokens in past: 25<br>Probability: 0.9175<br>Alibi: 0.0<br>Attention: 2.9406<br>Bias: -0.9189", "Token: 26 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 26<br>Probability: 0.9468<br>Alibi: 0.0<br>Attention: 2.9512<br>Bias: -0.9189", "Token: 27 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 27<br>Probability: 0.9407<br>Alibi: 0.0<br>Attention: 2.9622<br>Bias: -0.9189", "Token: 28 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 28<br>Probability: 0.9160<br>Alibi: 0.0<br>Attention: 2.6693<br>Bias: -0.9189", "Token: 29 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 29<br>Probability: 0.9690<br>Alibi: 0.0<br>Attention: 2.9326<br>Bias: -0.9189", "Token: 30 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 30<br>Probability: 0.9657<br>Alibi: 0.0<br>Attention: 2.8995<br>Bias: -0.9189", "Token: 31 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 31<br>Probability: 0.9295<br>Alibi: 0.0<br>Attention: 3.0179<br>Bias: -0.9189", "Token: 32 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 32<br>Probability: 0.9308<br>Alibi: 0.0<br>Attention: 2.8636<br>Bias: -0.9189", "Token: 33 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 33<br>Probability: 0.9221<br>Alibi: 0.0<br>Attention: 2.7917<br>Bias: -0.9189", "Token: 34 ( at)<br>Attend to token: 0 (By)<br>Tokens in past: 34<br>Probability: 0.9272<br>Alibi: 0.0<br>Attention: 2.9178<br>Bias: -0.9189", "Token: 35 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 35<br>Probability: 0.9229<br>Alibi: 0.0<br>Attention: 2.8623<br>Bias: -0.9189", "Token: 36 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 36<br>Probability: 0.9681<br>Alibi: 0.0<br>Attention: 2.9386<br>Bias: -0.9189", "Token: 37 ( centers)<br>Attend to token: 0 (By)<br>Tokens in past: 37<br>Probability: 0.9233<br>Alibi: 0.0<br>Attention: 2.7820<br>Bias: -0.9189", "Token: 38 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 38<br>Probability: 0.9376<br>Alibi: 0.0<br>Attention: 2.7362<br>Bias: -0.9189", "Token: 39 ( group)<br>Attend to token: 0 (By)<br>Tokens in past: 39<br>Probability: 0.9652<br>Alibi: 0.0<br>Attention: 2.9721<br>Bias: -0.9189", "Token: 40 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 40<br>Probability: 0.9009<br>Alibi: 0.0<br>Attention: 2.7917<br>Bias: -0.9189", "Token: 41 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 41<br>Probability: 0.9467<br>Alibi: 0.0<br>Attention: 2.7849<br>Bias: -0.9189", "Token: 42 ( specific)<br>Attend to token: 0 (By)<br>Tokens in past: 42<br>Probability: 0.9570<br>Alibi: 0.0<br>Attention: 2.8296<br>Bias: -0.9189", "Token: 43 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 43<br>Probability: 0.8719<br>Alibi: 0.0<br>Attention: 2.6239<br>Bias: -0.9189", "Token: 44 ( ()<br>Attend to token: 0 (By)<br>Tokens in past: 44<br>Probability: 0.9553<br>Alibi: 0.0<br>Attention: 2.9375<br>Bias: -0.9189", "Token: 45 (Di)<br>Attend to token: 0 (By)<br>Tokens in past: 45<br>Probability: 0.9897<br>Alibi: 0.0<br>Attention: 3.3090<br>Bias: -0.9189", "Token: 46 (abetes)<br>Attend to token: 0 (By)<br>Tokens in past: 46<br>Probability: 0.9773<br>Alibi: 0.0<br>Attention: 2.8497<br>Bias: -0.9189", "Token: 47 (,.)<br>Attend to token: 0 (By)<br>Tokens in past: 47<br>Probability: 0.9675<br>Alibi: 0.0<br>Attention: 2.9933<br>Bias: -0.9189", "Token: 48 ( Hy)<br>Attend to token: 0 (By)<br>Tokens in past: 48<br>Probability: 0.9826<br>Alibi: 0.0<br>Attention: 3.2761<br>Bias: -0.9189", "Token: 49 (pert)<br>Attend to token: 0 (By)<br>Tokens in past: 49<br>Probability: 0.9857<br>Alibi: 0.0<br>Attention: 2.8915<br>Bias: -0.9189", "Token: 50 (ension)<br>Attend to token: 0 (By)<br>Tokens in past: 50<br>Probability: 0.9155<br>Alibi: 0.0<br>Attention: 2.8216<br>Bias: -0.9189", "Token: 51 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 51<br>Probability: 0.9727<br>Alibi: 0.0<br>Attention: 3.2427<br>Bias: -0.9189", "Token: 52 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 52<br>Probability: 0.7528<br>Alibi: 0.0<br>Attention: 2.7541<br>Bias: -0.9189", "Token: 53 (.),)<br>Attend to token: 0 (By)<br>Tokens in past: 53<br>Probability: 0.9460<br>Alibi: 0.0<br>Attention: 2.8644<br>Bias: -0.9189", "Token: 54 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 54<br>Probability: 0.9686<br>Alibi: 0.0<br>Attention: 2.8403<br>Bias: -0.9189", "Token: 55 ( well)<br>Attend to token: 0 (By)<br>Tokens in past: 55<br>Probability: 0.9111<br>Alibi: 0.0<br>Attention: 2.6828<br>Bias: -0.9189", "Token: 56 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 56<br>Probability: 0.9554<br>Alibi: 0.0<br>Attention: 2.9441<br>Bias: -0.9189", "Token: 57 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 57<br>Probability: 0.9610<br>Alibi: 0.0<br>Attention: 2.9467<br>Bias: -0.9189", "Token: 58 ( forums)<br>Attend to token: 0 (By)<br>Tokens in past: 58<br>Probability: 0.9096<br>Alibi: 0.0<br>Attention: 2.7019<br>Bias: -0.9189", "Token: 59 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 59<br>Probability: 0.9512<br>Alibi: 0.0<br>Attention: 2.9367<br>Bias: -0.9189", "Token: 60 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 60<br>Probability: 0.9684<br>Alibi: 0.0<br>Attention: 2.9736<br>Bias: -0.9189", "Token: 61 ( fair)<br>Attend to token: 0 (By)<br>Tokens in past: 61<br>Probability: 0.9465<br>Alibi: 0.0<br>Attention: 2.7848<br>Bias: -0.9189", "Token: 62 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 62<br>Probability: 0.9249<br>Alibi: 0.0<br>Attention: 2.6549<br>Bias: -0.9189", "Token: 63 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 63<br>Probability: 0.9362<br>Alibi: 0.0<br>Attention: 3.0128<br>Bias: -0.9189", "Token: 64 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 64<br>Probability: 0.9353<br>Alibi: 0.0<br>Attention: 2.7227<br>Bias: -0.9189", "Token: 65 ( recruit)<br>Attend to token: 0 (By)<br>Tokens in past: 65<br>Probability: 0.9641<br>Alibi: 0.0<br>Attention: 3.1123<br>Bias: -0.9189", "Token: 66 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 66<br>Probability: 0.9724<br>Alibi: 0.0<br>Attention: 3.0830<br>Bias: -0.9189", "Token: 67 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 67<br>Probability: 0.9683<br>Alibi: 0.0<br>Attention: 3.0930<br>Bias: -0.9189", "Token: 68 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 68<br>Probability: 0.9255<br>Alibi: 0.0<br>Attention: 2.8248<br>Bias: -0.9189", "Token: 69 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 69<br>Probability: 0.9444<br>Alibi: 0.0<br>Attention: 2.7865<br>Bias: -0.9189", "Token: 70 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 70<br>Probability: 0.9645<br>Alibi: 0.0<br>Attention: 3.0551<br>Bias: -0.9189", "Token: 71 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 71<br>Probability: 0.9434<br>Alibi: 0.0<br>Attention: 2.4783<br>Bias: -0.9189", "Token: 72 ( assessment)<br>Attend to token: 0 (By)<br>Tokens in past: 72<br>Probability: 0.9039<br>Alibi: 0.0<br>Attention: 2.5901<br>Bias: -0.9189", "Token: 73 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 73<br>Probability: 0.9153<br>Alibi: 0.0<br>Attention: 2.8467<br>Bias: -0.9189", "Token: 74 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 74<br>Probability: 0.9333<br>Alibi: 0.0<br>Attention: 2.8940<br>Bias: -0.9189", "Token: 75 ( area)<br>Attend to token: 0 (By)<br>Tokens in past: 75<br>Probability: 0.8900<br>Alibi: 0.0<br>Attention: 2.5648<br>Bias: -0.9189", "Token: 76 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 76<br>Probability: 0.8557<br>Alibi: 0.0<br>Attention: 2.9513<br>Bias: -0.9189", "Token: 77 ( intervention)<br>Attend to token: 0 (By)<br>Tokens in past: 77<br>Probability: 0.8980<br>Alibi: 0.0<br>Attention: 2.5616<br>Bias: -0.9189", "Token: 78 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 78<br>Probability: 0.9249<br>Alibi: 0.0<br>Attention: 2.5050<br>Bias: -0.9189", "Token: 79 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 79<br>Probability: 0.9080<br>Alibi: 0.0<br>Attention: 2.7717<br>Bias: -0.9189", "Token: 80 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 80<br>Probability: 0.9364<br>Alibi: 0.0<br>Attention: 2.8861<br>Bias: -0.9189", "Token: 81 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 81<br>Probability: 0.9080<br>Alibi: 0.0<br>Attention: 2.7932<br>Bias: -0.9189", "Token: 82 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 82<br>Probability: 0.8410<br>Alibi: 0.0<br>Attention: 2.9447<br>Bias: -0.9189", "Token: 83 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 83<br>Probability: 0.9357<br>Alibi: 0.0<br>Attention: 2.8395<br>Bias: -0.9189", "Token: 84 ( economic)<br>Attend to token: 0 (By)<br>Tokens in past: 84<br>Probability: 0.8835<br>Alibi: 0.0<br>Attention: 2.7251<br>Bias: -0.9189", "Token: 85 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 85<br>Probability: 0.8909<br>Alibi: 0.0<br>Attention: 2.4584<br>Bias: -0.9189", "Token: 86 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 86<br>Probability: 0.9188<br>Alibi: 0.0<br>Attention: 2.7401<br>Bias: -0.9189", "Token: 87 ( educate)<br>Attend to token: 0 (By)<br>Tokens in past: 87<br>Probability: 0.9352<br>Alibi: 0.0<br>Attention: 2.8653<br>Bias: -0.9189", "Token: 88 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 88<br>Probability: 0.9360<br>Alibi: 0.0<br>Attention: 2.8729<br>Bias: -0.9189", "Token: 89 ( encourage)<br>Attend to token: 0 (By)<br>Tokens in past: 89<br>Probability: 0.9508<br>Alibi: 0.0<br>Attention: 2.8780<br>Bias: -0.9189", "Token: 90 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 90<br>Probability: 0.8823<br>Alibi: 0.0<br>Attention: 2.6532<br>Bias: -0.9189", "Token: 91 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 91<br>Probability: 0.9174<br>Alibi: 0.0<br>Attention: 2.8821<br>Bias: -0.9189", "Token: 92 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 92<br>Probability: 0.8943<br>Alibi: 0.0<br>Attention: 3.0518<br>Bias: -0.9189", "Token: 93 ( preventive)<br>Attend to token: 0 (By)<br>Tokens in past: 93<br>Probability: 0.8766<br>Alibi: 0.0<br>Attention: 2.8750<br>Bias: -0.9189", "Token: 94 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 94<br>Probability: 0.9197<br>Alibi: 0.0<br>Attention: 2.9788<br>Bias: -0.9189", "Token: 95 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 95<br>Probability: 0.9184<br>Alibi: 0.0<br>Attention: 2.8365<br>Bias: -0.9189", "Token: 96 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 96<br>Probability: 0.9121<br>Alibi: 0.0<br>Attention: 2.8950<br>Bias: -0.9189", "Token: 97 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 97<br>Probability: 0.9085<br>Alibi: 0.0<br>Attention: 2.7597<br>Bias: -0.9189", "Token: 98 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 98<br>Probability: 0.9563<br>Alibi: 0.0<br>Attention: 3.2863<br>Bias: -0.9189", "Token: 99 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 99<br>Probability: 0.9242<br>Alibi: 0.0<br>Attention: 2.8310<br>Bias: -0.9189", "Token: 100 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 100<br>Probability: 0.9447<br>Alibi: 0.0<br>Attention: 3.2118<br>Bias: -0.9189", "Token: 101 ( prenatal)<br>Attend to token: 0 (By)<br>Tokens in past: 101<br>Probability: 0.9550<br>Alibi: 0.0<br>Attention: 2.9112<br>Bias: -0.9189", "Token: 102 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 102<br>Probability: 0.8925<br>Alibi: 0.0<br>Attention: 2.8286<br>Bias: -0.9189", "Token: 103 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 103<br>Probability: 0.9471<br>Alibi: 0.0<br>Attention: 3.1905<br>Bias: -0.9189", "Token: 104 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 104<br>Probability: 0.9457<br>Alibi: 0.0<br>Attention: 3.1145<br>Bias: -0.9189", "Token: 105 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 105<br>Probability: 0.9213<br>Alibi: 0.0<br>Attention: 3.2733<br>Bias: -0.9189", "Token: 106 ( maintenance)<br>Attend to token: 0 (By)<br>Tokens in past: 106<br>Probability: 0.9202<br>Alibi: 0.0<br>Attention: 2.9675<br>Bias: -0.9189", "Token: 107 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 107<br>Probability: 0.9484<br>Alibi: 0.0<br>Attention: 2.9477<br>Bias: -0.9189", "Token: 108 ( chronic)<br>Attend to token: 0 (By)<br>Tokens in past: 108<br>Probability: 0.9288<br>Alibi: 0.0<br>Attention: 3.0341<br>Bias: -0.9189", "Token: 109 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 109<br>Probability: 0.9377<br>Alibi: 0.0<br>Attention: 2.8745<br>Bias: -0.9189", "Token: 110 ( diseases)<br>Attend to token: 0 (By)<br>Tokens in past: 110<br>Probability: 0.8841<br>Alibi: 0.0<br>Attention: 2.7431<br>Bias: -0.9189", "Token: 111 (..)<br>Attend to token: 0 (By)<br>Tokens in past: 111<br>Probability: 0.9391<br>Alibi: 0.0<br>Attention: 2.9765<br>Bias: -0.9189", "Token: 112 ( The)<br>Attend to token: 0 (By)<br>Tokens in past: 112<br>Probability: 0.9065<br>Alibi: 0.0<br>Attention: 2.8668<br>Bias: -0.9189", "Token: 113 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 113<br>Probability: 0.8785<br>Alibi: 0.0<br>Attention: 3.1625<br>Bias: -0.9189", "Token: 114 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 114<br>Probability: 0.9485<br>Alibi: 0.0<br>Attention: 3.2356<br>Bias: -0.9189", "Token: 115 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 115<br>Probability: 0.9178<br>Alibi: 0.0<br>Attention: 2.8571<br>Bias: -0.9189", "Token: 116 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 116<br>Probability: 0.9112<br>Alibi: 0.0<br>Attention: 2.9426<br>Bias: -0.9189", "Token: 117 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 117<br>Probability: 0.8678<br>Alibi: 0.0<br>Attention: 2.9855<br>Bias: -0.9189", "Token: 118 ( pregnant)<br>Attend to token: 0 (By)<br>Tokens in past: 118<br>Probability: 0.9552<br>Alibi: 0.0<br>Attention: 2.8439<br>Bias: -0.9189", "Token: 119 ( women)<br>Attend to token: 0 (By)<br>Tokens in past: 119<br>Probability: 0.8822<br>Alibi: 0.0<br>Attention: 2.6939<br>Bias: -0.9189", "Token: 120 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 120<br>Probability: 0.8879<br>Alibi: 0.0<br>Attention: 2.8609<br>Bias: -0.9189", "Token: 121 ( newborn)<br>Attend to token: 0 (By)<br>Tokens in past: 121<br>Probability: 0.9279<br>Alibi: 0.0<br>Attention: 2.3802<br>Bias: -0.9189", "Token: 122 (s)<br>Attend to token: 0 (By)<br>Tokens in past: 122<br>Probability: 0.8421<br>Alibi: 0.0<br>Attention: 2.5209<br>Bias: -0.9189", "Token: 123 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 123<br>Probability: 0.8900<br>Alibi: 0.0<br>Attention: 2.8470<br>Bias: -0.9189", "Token: 124 ( infants)<br>Attend to token: 0 (By)<br>Tokens in past: 124<br>Probability: 0.7966<br>Alibi: 0.0<br>Attention: 2.5726<br>Bias: -0.9189", "Token: 125 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 125<br>Probability: 0.8248<br>Alibi: 0.0<br>Attention: 2.5914<br>Bias: -0.9189", "Token: 126 ( high)<br>Attend to token: 0 (By)<br>Tokens in past: 126<br>Probability: 0.9126<br>Alibi: 0.0<br>Attention: 2.5635<br>Bias: -0.9189", "Token: 127 ( risk)<br>Attend to token: 0 (By)<br>Tokens in past: 127<br>Probability: 0.8634<br>Alibi: 0.0<br>Attention: 2.5838<br>Bias: -0.9189", "Token: 128 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 128<br>Probability: 0.8595<br>Alibi: 0.0<br>Attention: 2.7051<br>Bias: -0.9189", "Token: 129 ( malnutrition)<br>Attend to token: 0 (By)<br>Tokens in past: 129<br>Probability: 0.8615<br>Alibi: 0.0<br>Attention: 2.3575<br>Bias: -0.9189", "Token: 130 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 130<br>Probability: 0.8442<br>Alibi: 0.0<br>Attention: 2.6645<br>Bias: -0.9189", "Token: 131 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 131<br>Probability: 0.9250<br>Alibi: 0.0<br>Attention: 2.6337<br>Bias: -0.9189", "Token: 132 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 132<br>Probability: 0.8594<br>Alibi: 0.0<br>Attention: 2.6410<br>Bias: -0.9189", "Token: 133 ( obtain)<br>Attend to token: 0 (By)<br>Tokens in past: 133<br>Probability: 0.8763<br>Alibi: 0.0<br>Attention: 2.9300<br>Bias: -0.9189", "Token: 134 ( proper)<br>Attend to token: 0 (By)<br>Tokens in past: 134<br>Probability: 0.9044<br>Alibi: 0.0<br>Attention: 2.8106<br>Bias: -0.9189", "Token: 135 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 135<br>Probability: 0.8865<br>Alibi: 0.0<br>Attention: 2.7129<br>Bias: -0.9189", "Token: 136 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 136<br>Probability: 0.8411<br>Alibi: 0.0<br>Attention: 2.7190<br>Bias: -0.9189", "Token: 137 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 137<br>Probability: 0.8978<br>Alibi: 0.0<br>Attention: 2.6641<br>Bias: -0.9189", "Token: 138 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 138<br>Probability: 0.8815<br>Alibi: 0.0<br>Attention: 3.1585<br>Bias: -0.9189", "Token: 139 ( food)<br>Attend to token: 0 (By)<br>Tokens in past: 139<br>Probability: 0.7251<br>Alibi: 0.0<br>Attention: 2.7892<br>Bias: -0.9189", "Token: 140 ( assistance)<br>Attend to token: 0 (By)<br>Tokens in past: 140<br>Probability: 0.9011<br>Alibi: 0.0<br>Attention: 2.7919<br>Bias: -0.9189", "Token: 141 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 141<br>Probability: 0.9008<br>Alibi: 0.0<br>Attention: 3.2103<br>Bias: -0.9189", "Token: 142 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 142<br>Probability: 0.7221<br>Alibi: 0.0<br>Attention: 2.6916<br>Bias: -0.9189", "Token: 143 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 143<br>Probability: 0.9430<br>Alibi: 0.0<br>Attention: 2.9327<br>Bias: -0.9189", "Token: 144 ( They)<br>Attend to token: 0 (By)<br>Tokens in past: 144<br>Probability: 0.9017<br>Alibi: 0.0<br>Attention: 2.8528<br>Bias: -0.9189", "Token: 145 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 145<br>Probability: 0.9011<br>Alibi: 0.0<br>Attention: 2.8593<br>Bias: -0.9189", "Token: 146 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 146<br>Probability: 0.8996<br>Alibi: 0.0<br>Attention: 2.8846<br>Bias: -0.9189", "Token: 147 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 147<br>Probability: 0.8943<br>Alibi: 0.0<br>Attention: 3.0535<br>Bias: -0.9189", "Token: 148 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 148<br>Probability: 0.8485<br>Alibi: 0.0<br>Attention: 2.9074<br>Bias: -0.9189", "Token: 149 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 149<br>Probability: 0.9200<br>Alibi: 0.0<br>Attention: 3.1658<br>Bias: -0.9189", "Token: 150 ( certain)<br>Attend to token: 0 (By)<br>Tokens in past: 150<br>Probability: 0.9185<br>Alibi: 0.0<br>Attention: 3.0359<br>Bias: -0.9189", "Token: 151 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 151<br>Probability: 0.8264<br>Alibi: 0.0<br>Attention: 2.7775<br>Bias: -0.9189", "Token: 152 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 152<br>Probability: 0.9492<br>Alibi: 0.0<br>Attention: 3.1508<br>Bias: -0.9189", "Token: 153 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 153<br>Probability: 0.9547<br>Alibi: 0.0<br>Attention: 3.4561<br>Bias: -0.9189", "Token: 154 ( HIV)<br>Attend to token: 0 (By)<br>Tokens in past: 154<br>Probability: 0.8474<br>Alibi: 0.0<br>Attention: 2.7871<br>Bias: -0.9189", "Token: 155 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 155<br>Probability: 0.9639<br>Alibi: 0.0<br>Attention: 3.3639<br>Bias: -0.9189", "Token: 156 ( Tu)<br>Attend to token: 0 (By)<br>Tokens in past: 156<br>Probability: 0.9102<br>Alibi: 0.0<br>Attention: 2.9497<br>Bias: -0.9189", "Token: 157 (ber)<br>Attend to token: 0 (By)<br>Tokens in past: 157<br>Probability: 0.9866<br>Alibi: 0.0<br>Attention: 3.3701<br>Bias: -0.9189", "Token: 158 (culosis)<br>Attend to token: 0 (By)<br>Tokens in past: 158<br>Probability: 0.8735<br>Alibi: 0.0<br>Attention: 2.7852<br>Bias: -0.9189", "Token: 159 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 159<br>Probability: 0.9768<br>Alibi: 0.0<br>Attention: 3.5541<br>Bias: -0.9189", "Token: 160 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 160<br>Probability: 0.9659<br>Alibi: 0.0<br>Attention: 3.3128<br>Bias: -0.9189", "Token: 161 ( Mal)<br>Attend to token: 0 (By)<br>Tokens in past: 161<br>Probability: 0.9845<br>Alibi: 0.0<br>Attention: 3.5225<br>Bias: -0.9189", "Token: 162 (aria)<br>Attend to token: 0 (By)<br>Tokens in past: 162<br>Probability: 0.8905<br>Alibi: 0.0<br>Attention: 2.8054<br>Bias: -0.9189", "Token: 163 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 163<br>Probability: 0.8729<br>Alibi: 0.0<br>Attention: 2.9245<br>Bias: -0.9189", "Token: 164 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 164<br>Probability: 0.9368<br>Alibi: 0.0<br>Attention: 2.8061<br>Bias: -0.9189", "Token: 165 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 165<br>Probability: 0.9295<br>Alibi: 0.0<br>Attention: 2.9082<br>Bias: -0.9189", "Token: 166 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 166<br>Probability: 0.8354<br>Alibi: 0.0<br>Attention: 3.2781<br>Bias: -0.9189", "Token: 167 ( available)<br>Attend to token: 0 (By)<br>Tokens in past: 167<br>Probability: 0.8873<br>Alibi: 0.0<br>Attention: 3.2387<br>Bias: -0.9189", "Token: 168 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 168<br>Probability: 0.8915<br>Alibi: 0.0<br>Attention: 2.9235<br>Bias: -0.9189", "Token: 169 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 169<br>Probability: 0.9464<br>Alibi: 0.0<br>Attention: 3.0841<br>Bias: -0.9189"], "legendgroup": "0", "marker": {"color": [1.0, 0.9610129594802856, 0.9263359904289246, 0.9638789892196655, 0.909675657749176, 0.8651983141899109, 0.9716466069221497, 0.8829706311225891, 0.8892858624458313, 0.953758716583252, 0.825514554977417, 0.8677247762680054, 0.880736231803894, 0.9179905652999878, 0.9642197489738464, 0.9228252172470093, 0.903451144695282, 0.9519280791282654, 0.8602189421653748, 0.9169667363166809, 0.9350452423095703, 0.9313943386077881, 0.9505065083503723, 0.9802447557449341, 0.9656815528869629, 0.9174695014953613, 0.9468252062797546, 0.9406799077987671, 0.916000485420227, 0.9690369367599487, 0.9656750559806824, 0.9295134544372559, 0.9308079481124878, 0.9221368432044983, 0.9272339940071106, 0.9229399561882019, 0.9680857062339783, 0.9233481884002686, 0.9376492500305176, 0.965218186378479, 0.9009391069412231, 0.9467493295669556, 0.9569991827011108, 0.8719489574432373, 0.9553424715995789, 0.9897148013114929, 0.9772860407829285, 0.9674832820892334, 0.9825907349586487, 0.9857482314109802, 0.9154728055000305, 0.9726816415786743, 0.7527657151222229, 0.9459971785545349, 0.9686493277549744, 0.9110750555992126, 0.9553791284561157, 0.9609771966934204, 0.9096430540084839, 0.951154887676239, 0.9683559536933899, 0.9464761018753052, 0.9249104857444763, 0.9361763000488281, 0.9353235363960266, 0.9640766978263855, 0.9724178910255432, 0.9682810306549072, 0.925540030002594, 0.9443915486335754, 0.9644578099250793, 0.9434094429016113, 0.9038631916046143, 0.9152888655662537, 0.9332892298698425, 0.889967143535614, 0.8557037115097046, 0.8979999423027039, 0.9249359965324402, 0.9079885482788086, 0.9363679885864258, 0.907971203327179, 0.841049313545227, 0.9357042908668518, 0.8834964632987976, 0.8908870816230774, 0.9188082218170166, 0.9352195262908936, 0.9360320568084717, 0.9508361220359802, 0.8823049664497375, 0.9174051880836487, 0.8943291306495667, 0.8765584230422974, 0.9197071194648743, 0.9184447526931763, 0.9121299386024475, 0.9084603190422058, 0.9563019275665283, 0.9242465496063232, 0.9447420835494995, 0.955025851726532, 0.8924663662910461, 0.9471192955970764, 0.9456689953804016, 0.9213320016860962, 0.9201954007148743, 0.948401153087616, 0.9288076162338257, 0.9376590251922607, 0.8840539455413818, 0.9390808343887329, 0.9065073132514954, 0.8784634470939636, 0.9484752416610718, 0.9178462624549866, 0.9111820459365845, 0.8678460717201233, 0.9551922678947449, 0.8822034001350403, 0.8878546953201294, 0.9279072284698486, 0.8420681357383728, 0.8900419473648071, 0.7966412305831909, 0.8248459100723267, 0.9126036763191223, 0.8633591532707214, 0.8594632744789124, 0.861519992351532, 0.8442448973655701, 0.9249756932258606, 0.8594284653663635, 0.8762508630752563, 0.904445230960846, 0.8864880800247192, 0.8410987854003906, 0.8977924585342407, 0.881454348564148, 0.7250751256942749, 0.9010872840881348, 0.9007785320281982, 0.722131073474884, 0.9430412650108337, 0.9016523361206055, 0.9010558128356934, 0.8995930552482605, 0.8942888975143433, 0.8484969735145569, 0.920007050037384, 0.9185220003128052, 0.8264110088348389, 0.9492008090019226, 0.9546840190887451, 0.8473829627037048, 0.9639325737953186, 0.9101564288139343, 0.9866442084312439, 0.8735170960426331, 0.9767932891845703, 0.9659491777420044, 0.9845444560050964, 0.8905090689659119, 0.8729080557823181, 0.9367901086807251, 0.9295308589935303, 0.8353509306907654, 0.8872542381286621, 0.891494631767273, 0.9464324116706848], "coloraxis": "coloraxis", "opacity": 0.5, "symbol": "circle"}, "mode": "markers", "name": "0", "showlegend": true, "subplot": "ternary", "type": "scatterternary"}], "layout": {"coloraxis": {"colorbar": {"title": {"text": "prob"}}, "colorscale": [[0.0, "rgb(0,0,255)"], [1.0, "rgb(255,0,0)"]]}, "legend": {"orientation": "h", "title": {"text": "sort_idx"}, "tracegroupgap": 0}, "margin": {"t": 60}, "template": {"data": {"candlestick": [{"decreasing": {"line": {"color": "#ff2b2b"}}, "increasing": {"line": {"color": "#29b09d"}}, "type": "candlestick"}], "contourcarpet": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contourcarpet"}], "contour": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contour"}], "heatmap": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "heatmap"}], "histogram2d": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "histogram2d"}], "icicle": [{"textfont": {"color": "white"}, "type": "icicle"}], "sankey": [{"textfont": {"color": "#808495"}, "type": "sankey"}], "scatter": [{"marker": {"line": {"width": 0}}, "type": "scatter"}], "table": [{"cells": {"fill": {"color": "#ffffff"}, "font": {"color": "#262730"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "header": {"fill": {"color": "rgba(248, 249, 251, 1)"}, "font": {"color": "#808495"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "type": "table"}], "waterfall": [{"connector": {"line": {"color": "#808495", "width": 2}}, "decreasing": {"marker": {"color": "#ff2b2b"}}, "increasing": {"marker": {"color": "#29b09d"}}, "totals": {"marker": {"color": "#0068c9"}}, "type": "waterfall"}]}, "layout": {"coloraxis": {"colorbar": {"len": 0.75, "outlinecolor": "rgba(0,0,0,0)", "outlinewidth": 8, "thickness": 16, "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}}, "xpad": 24, "y": 0.5745}}, "colorscale": {"diverging": [[0.0, "#7d353b"], [0.1, "#bd4043"], [0.2, "#ff4b4b"], [0.3, "#ff8c8c"], [0.4, "#ffc7c7"], [0.5, "#a6dcff"], [0.6, "#60b4ff"], [0.7, "#1c83e1"], [0.8, "#0054a3"], [0.9, "#004280"], [1.0, "#000031"]], "sequential": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "sequentialminus": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]]}, "colorway": ["#0068c9", "#83c9ff", "#ff2b2b", "#ffabab", "#29b09d", "#7defa1", "#ff8700", "#ffd16a", "#6d3fc0", "#d5dae5"], "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}, "hoverlabel": {"bgcolor": "#ffffff", "bordercolor": "rgba(49, 51, 63, 0.2)", "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "legend": {"bordercolor": "rgba(0,0,0,0)", "borderwidth": 0, "font": {"color": "#262730", "size": 12}, "title": {"font": {"color": "#808495", "size": 12}, "side": "top"}, "valign": "top"}, "margin": {"l": 0, "pad": 8, "r": 0}, "paper_bgcolor": "#ffffff", "plot_bgcolor": "#ffffff", "ternary": {"aaxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "baxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "bgcolor": "#ffffff", "caxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}}, "title": {"font": {"color": "#31333F", "family": "\"Source Sans Pro\", sans-serif", "size": 16}, "pad": {"l": 4}, "x": 0, "xanchor": "left"}, "xaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "rangeselector": {"bgcolor": "#ffffff", "bordercolor": "#e6eaf1", "borderwidth": 1, "x": 0}, "showgrid": false, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "title": {"font": {"color": "#808495", "size": 14}, "standoff": 20}, "zeroline": false, "zerolinecolor": "#e6eaf1"}, "yaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}, "standoff": 24}, "zerolinecolor": "#e6eaf1"}}}, "ternary": {"aaxis": {"title": {"text": "attention"}}, "baxis": {"title": {"text": "bias"}}, "caxis": {"title": {"text": "alibi"}}, "domain": {"x": [0.0, 1.0], "y": [0.0, 1.0]}}, "title": {"text": "Attention Breakdown (Layer 22, Head 31)"}}, "metadata": {"sentence_id": 0, "layer_id": 22, "head_id": 31, "accounted_probability": 0.5, "max_tokens_per_row": 11, "creation_date": "2025-01-23 00:11:57.057596", "page": {"page_script_hash": "a81f7f5ae171c15a95155bca2157e9b6", "page_name": "ATTN_-_Attention_Focus", "icon": "", "script_path": "/workspaces/llm-research/app/pages/301_ATTN - Attention Focus.py"}}}