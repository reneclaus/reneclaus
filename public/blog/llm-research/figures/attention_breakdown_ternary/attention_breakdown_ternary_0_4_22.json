{"data": [{"a": [0.0, 2.9815886169672012, 3.046539083123207, 3.441150203347206, 3.5945112854242325, 3.525302901864052, 3.140859618782997, 2.936025157570839, 3.626724973320961, 3.042287603020668, 3.7589450031518936, 3.1287443786859512, 3.3057286888360977, 3.346185937523842, 3.172451987862587, 3.5888731628656387, 3.7177033573389053, 2.9872205406427383, 3.0069277435541153, 2.677271857857704, 2.903535380959511, 2.7569239288568497, 3.577028527855873, 2.7268383651971817, 3.305957093834877, 3.3885882049798965, 2.2831335216760635, 2.706547036767006, 2.6483049541711807, 3.2132103592157364, 2.8161981254816055, 3.0003459602594376, 2.201467052102089, 3.567191854119301, 2.864625468850136, 2.2150681167840958, 3.072295442223549, 3.4753472954034805, 2.5014040619134903, 3.215474382042885, 3.5950653702020645, 2.8797516971826553, 3.0767340809106827, 3.3757071644067764, 2.8324384838342667, 2.9633307605981827, 3.158528581261635, 2.3734941631555557, 2.9735629707574844, 3.2985804229974747, 3.3498196750879288, 2.4239714294672012, 3.0465285927057266, 3.071997180581093, 2.8669610172510147, 2.464855447411537, 2.767904296517372, 2.913329854607582, 3.491193786263466, 2.894462361931801, 2.9616725593805313, 3.7840953022241592, 2.0201206356287003, 2.77662493288517, 2.949116960167885, 3.6235034614801407, 2.309206023812294, 2.945863977074623, 3.3150546699762344, 2.963134780526161, 3.1602645069360733, 2.6227734237909317, 3.248039498925209, 2.5168297439813614, 2.7730252891778946, 3.1597392708063126, 3.2943403869867325, 3.3323581367731094, 2.564954534173012, 3.002347245812416, 2.13518525660038, 2.525838151574135, 2.7263994365930557, 2.951573148369789, 2.7221310287714005, 2.6843578964471817, 2.5350797325372696, 3.1974091678857803, 2.7358081489801407, 3.039057031273842, 2.7915423065423965, 3.040409579873085, 2.8766210228204727, 3.2717640548944473, 2.0836305767297745, 2.9729480892419815, 2.929800048470497, 2.9967892318964005, 3.033460393548012, 3.356264606118202, 2.791590228676796, 3.3023307472467422, 3.4895336776971817, 2.7998173385858536, 2.8908162266016006, 2.7588622719049454, 2.9609217792749405, 2.878952279686928, 3.0641224533319473, 2.391401305794716, 3.3278584629297256, 2.8391337543725967, 2.3736679702997208, 2.861649051308632, 3.3934238106012344, 3.2556059509515762, 3.565607562661171, 3.2276010662317276, 3.1668024212121964, 3.6284089237451553, 2.716552034020424, 3.961984172463417, 3.5259685665369034, 2.7475757747888565, 3.517551675438881, 2.9212649017572403, 2.961408868432045, 3.288690820336342, 3.4764030128717422, 3.0858674198389053, 2.887411132454872, 3.000567689538002, 3.3384916931390762, 2.7011063247919083, 3.349684253334999, 3.601593032479286, 2.6439192444086075, 3.486048236489296, 3.0067122131586075, 3.891711488366127, 3.3935790210962296, 3.140131250023842, 3.6279447227716446, 2.9656775146722794, 3.36624313890934, 3.547229066491127, 3.7644310146570206, 3.4836661964654922, 3.446197286248207, 3.422553315758705, 3.57551671564579, 3.67699171602726, 3.6351442486047745, 3.8962309509515762, 3.2599301487207413, 3.094169393181801, 2.9226768165826797, 3.872293248772621, 3.41393806040287, 3.3067310005426407, 3.3298247009515762, 3.4399867206811905, 3.450568214058876, 3.635904088616371, 3.571173444390297, 3.9239432960748672, 3.2116899639368057, 3.52877976000309, 3.8495824486017227, 2.7429070621728897], "b": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "c": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "hovertemplate": "<b>%{hovertext}</b><br><br>sort_idx=0<br>a=%{a}<br>b=%{b}<br>alibi=%{c}<br>prob=%{marker.color}<extra></extra>", "hovertext": ["Token: 0 (By)<br>Attend to token: 0 (By)<br>Tokens in past: 0<br>Probability: 1.0000<br>Alibi: 0.0<br>Attention: -1.9759<br>Bias: 1.9188", "Token: 1 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 1<br>Probability: 0.9547<br>Alibi: 0.0<br>Attention: 1.0057<br>Bias: 1.9188", "Token: 2 ( end)<br>Attend to token: 0 (By)<br>Tokens in past: 2<br>Probability: 0.9413<br>Alibi: 0.0<br>Attention: 1.0707<br>Bias: 1.9188", "Token: 3 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 3<br>Probability: 0.9612<br>Alibi: 0.0<br>Attention: 1.4653<br>Bias: 1.9188", "Token: 4 ( 2014)<br>Attend to token: 0 (By)<br>Tokens in past: 4<br>Probability: 0.9293<br>Alibi: 0.0<br>Attention: 1.6187<br>Bias: 1.9188", "Token: 5 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 5<br>Probability: 0.9031<br>Alibi: 0.0<br>Attention: 1.5494<br>Bias: 1.9188", "Token: 6 ( we)<br>Attend to token: 0 (By)<br>Tokens in past: 6<br>Probability: 0.8641<br>Alibi: 0.0<br>Attention: 1.1650<br>Bias: 1.9188", "Token: 7 ( plan)<br>Attend to token: 0 (By)<br>Tokens in past: 7<br>Probability: 0.8559<br>Alibi: 0.0<br>Attention: 0.9602<br>Bias: 1.9188", "Token: 8 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 8<br>Probability: 0.8944<br>Alibi: 0.0<br>Attention: 1.6509<br>Bias: 1.9188", "Token: 9 ( rev)<br>Attend to token: 0 (By)<br>Tokens in past: 9<br>Probability: 0.9205<br>Alibi: 0.0<br>Attention: 1.0664<br>Bias: 1.9188", "Token: 10 (amp)<br>Attend to token: 0 (By)<br>Tokens in past: 10<br>Probability: 0.9027<br>Alibi: 0.0<br>Attention: 1.7831<br>Bias: 1.9188", "Token: 11 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 11<br>Probability: 0.9241<br>Alibi: 0.0<br>Attention: 1.1529<br>Bias: 1.9188", "Token: 12 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 12<br>Probability: 0.9204<br>Alibi: 0.0<br>Attention: 1.3299<br>Bias: 1.9188", "Token: 13 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 13<br>Probability: 0.8999<br>Alibi: 0.0<br>Attention: 1.3703<br>Bias: 1.9188", "Token: 14 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 14<br>Probability: 0.9488<br>Alibi: 0.0<br>Attention: 1.1966<br>Bias: 1.9188", "Token: 15 ( disease)<br>Attend to token: 0 (By)<br>Tokens in past: 15<br>Probability: 0.9545<br>Alibi: 0.0<br>Attention: 1.6130<br>Bias: 1.9188", "Token: 16 ( prevention)<br>Attend to token: 0 (By)<br>Tokens in past: 16<br>Probability: 0.9205<br>Alibi: 0.0<br>Attention: 1.7418<br>Bias: 1.9188", "Token: 17 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 17<br>Probability: 0.8144<br>Alibi: 0.0<br>Attention: 1.0114<br>Bias: 1.9188", "Token: 18 ( program)<br>Attend to token: 0 (By)<br>Tokens in past: 18<br>Probability: 0.8698<br>Alibi: 0.0<br>Attention: 1.0311<br>Bias: 1.9188", "Token: 19 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 19<br>Probability: 0.8433<br>Alibi: 0.0<br>Attention: 0.7014<br>Bias: 1.9188", "Token: 20 ( which)<br>Attend to token: 0 (By)<br>Tokens in past: 20<br>Probability: 0.9017<br>Alibi: 0.0<br>Attention: 0.9277<br>Bias: 1.9188", "Token: 21 ( was)<br>Attend to token: 0 (By)<br>Tokens in past: 21<br>Probability: 0.8513<br>Alibi: 0.0<br>Attention: 0.7811<br>Bias: 1.9188", "Token: 22 ( suspended)<br>Attend to token: 0 (By)<br>Tokens in past: 22<br>Probability: 0.9150<br>Alibi: 0.0<br>Attention: 1.6012<br>Bias: 1.9188", "Token: 23 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 23<br>Probability: 0.8365<br>Alibi: 0.0<br>Attention: 0.7510<br>Bias: 1.9188", "Token: 24 ( September)<br>Attend to token: 0 (By)<br>Tokens in past: 24<br>Probability: 0.8127<br>Alibi: 0.0<br>Attention: 1.3301<br>Bias: 1.9188", "Token: 25 ( 2013)<br>Attend to token: 0 (By)<br>Tokens in past: 25<br>Probability: 0.8702<br>Alibi: 0.0<br>Attention: 1.4127<br>Bias: 1.9188", "Token: 26 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 26<br>Probability: 0.7088<br>Alibi: 0.0<br>Attention: 0.3073<br>Bias: 1.9188", "Token: 27 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 27<br>Probability: 0.7437<br>Alibi: 0.0<br>Attention: 0.7307<br>Bias: 1.9188", "Token: 28 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 28<br>Probability: 0.6963<br>Alibi: 0.0<br>Attention: 0.6724<br>Bias: 1.9188", "Token: 29 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 29<br>Probability: 0.7850<br>Alibi: 0.0<br>Attention: 1.2374<br>Bias: 1.9188", "Token: 30 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 30<br>Probability: 0.9033<br>Alibi: 0.0<br>Attention: 0.8403<br>Bias: 1.9188", "Token: 31 ( education)<br>Attend to token: 0 (By)<br>Tokens in past: 31<br>Probability: 0.8805<br>Alibi: 0.0<br>Attention: 1.0245<br>Bias: 1.9188", "Token: 32 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 32<br>Probability: 0.7651<br>Alibi: 0.0<br>Attention: 0.2256<br>Bias: 1.9188", "Token: 33 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 33<br>Probability: 0.8401<br>Alibi: 0.0<br>Attention: 1.5913<br>Bias: 1.9188", "Token: 34 ( at)<br>Attend to token: 0 (By)<br>Tokens in past: 34<br>Probability: 0.8347<br>Alibi: 0.0<br>Attention: 0.8888<br>Bias: 1.9188", "Token: 35 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 35<br>Probability: 0.7476<br>Alibi: 0.0<br>Attention: 0.2392<br>Bias: 1.9188", "Token: 36 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 36<br>Probability: 0.7873<br>Alibi: 0.0<br>Attention: 1.0964<br>Bias: 1.9188", "Token: 37 ( centers)<br>Attend to token: 0 (By)<br>Tokens in past: 37<br>Probability: 0.9097<br>Alibi: 0.0<br>Attention: 1.4995<br>Bias: 1.9188", "Token: 38 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 38<br>Probability: 0.8064<br>Alibi: 0.0<br>Attention: 0.5255<br>Bias: 1.9188", "Token: 39 ( group)<br>Attend to token: 0 (By)<br>Tokens in past: 39<br>Probability: 0.8854<br>Alibi: 0.0<br>Attention: 1.2396<br>Bias: 1.9188", "Token: 40 ( sessions)<br>Attend to token: 0 (By)<br>Tokens in past: 40<br>Probability: 0.9046<br>Alibi: 0.0<br>Attention: 1.6192<br>Bias: 1.9188", "Token: 41 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 41<br>Probability: 0.8792<br>Alibi: 0.0<br>Attention: 0.9039<br>Bias: 1.9188", "Token: 42 ( specific)<br>Attend to token: 0 (By)<br>Tokens in past: 42<br>Probability: 0.8780<br>Alibi: 0.0<br>Attention: 1.1009<br>Bias: 1.9188", "Token: 43 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 43<br>Probability: 0.8733<br>Alibi: 0.0<br>Attention: 1.3999<br>Bias: 1.9188", "Token: 44 ( ()<br>Attend to token: 0 (By)<br>Tokens in past: 44<br>Probability: 0.8117<br>Alibi: 0.0<br>Attention: 0.8566<br>Bias: 1.9188", "Token: 45 (Di)<br>Attend to token: 0 (By)<br>Tokens in past: 45<br>Probability: 0.8329<br>Alibi: 0.0<br>Attention: 0.9875<br>Bias: 1.9188", "Token: 46 (abetes)<br>Attend to token: 0 (By)<br>Tokens in past: 46<br>Probability: 0.8683<br>Alibi: 0.0<br>Attention: 1.1827<br>Bias: 1.9188", "Token: 47 (,.)<br>Attend to token: 0 (By)<br>Tokens in past: 47<br>Probability: 0.6299<br>Alibi: 0.0<br>Attention: 0.3976<br>Bias: 1.9188", "Token: 48 ( Hy)<br>Attend to token: 0 (By)<br>Tokens in past: 48<br>Probability: 0.8672<br>Alibi: 0.0<br>Attention: 0.9977<br>Bias: 1.9188", "Token: 49 (pert)<br>Attend to token: 0 (By)<br>Tokens in past: 49<br>Probability: 0.9279<br>Alibi: 0.0<br>Attention: 1.3227<br>Bias: 1.9188", "Token: 50 (ension)<br>Attend to token: 0 (By)<br>Tokens in past: 50<br>Probability: 0.8140<br>Alibi: 0.0<br>Attention: 1.3740<br>Bias: 1.9188", "Token: 51 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 51<br>Probability: 0.6896<br>Alibi: 0.0<br>Attention: 0.4481<br>Bias: 1.9188", "Token: 52 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 52<br>Probability: 0.7614<br>Alibi: 0.0<br>Attention: 1.0707<br>Bias: 1.9188", "Token: 53 (.),)<br>Attend to token: 0 (By)<br>Tokens in past: 53<br>Probability: 0.7790<br>Alibi: 0.0<br>Attention: 1.0961<br>Bias: 1.9188", "Token: 54 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 54<br>Probability: 0.8051<br>Alibi: 0.0<br>Attention: 0.8911<br>Bias: 1.9188", "Token: 55 ( well)<br>Attend to token: 0 (By)<br>Tokens in past: 55<br>Probability: 0.6881<br>Alibi: 0.0<br>Attention: 0.4890<br>Bias: 1.9188", "Token: 56 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 56<br>Probability: 0.7984<br>Alibi: 0.0<br>Attention: 0.7920<br>Bias: 1.9188", "Token: 57 ( community)<br>Attend to token: 0 (By)<br>Tokens in past: 57<br>Probability: 0.8708<br>Alibi: 0.0<br>Attention: 0.9375<br>Bias: 1.9188", "Token: 58 ( forums)<br>Attend to token: 0 (By)<br>Tokens in past: 58<br>Probability: 0.9135<br>Alibi: 0.0<br>Attention: 1.5153<br>Bias: 1.9188", "Token: 59 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 59<br>Probability: 0.8432<br>Alibi: 0.0<br>Attention: 0.9186<br>Bias: 1.9188", "Token: 60 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 60<br>Probability: 0.9078<br>Alibi: 0.0<br>Attention: 0.9858<br>Bias: 1.9188", "Token: 61 ( fair)<br>Attend to token: 0 (By)<br>Tokens in past: 61<br>Probability: 0.9400<br>Alibi: 0.0<br>Attention: 1.8082<br>Bias: 1.9188", "Token: 62 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 62<br>Probability: 0.5849<br>Alibi: 0.0<br>Attention: 0.0443<br>Bias: 1.9188", "Token: 63 ( We)<br>Attend to token: 0 (By)<br>Tokens in past: 63<br>Probability: 0.7227<br>Alibi: 0.0<br>Attention: 0.8008<br>Bias: 1.9188", "Token: 64 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 64<br>Probability: 0.7416<br>Alibi: 0.0<br>Attention: 0.9733<br>Bias: 1.9188", "Token: 65 ( recruit)<br>Attend to token: 0 (By)<br>Tokens in past: 65<br>Probability: 0.8591<br>Alibi: 0.0<br>Attention: 1.6476<br>Bias: 1.9188", "Token: 66 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 66<br>Probability: 0.7184<br>Alibi: 0.0<br>Attention: 0.3334<br>Bias: 1.9188", "Token: 67 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 67<br>Probability: 0.8354<br>Alibi: 0.0<br>Attention: 0.9700<br>Bias: 1.9188", "Token: 68 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 68<br>Probability: 0.8392<br>Alibi: 0.0<br>Attention: 1.3392<br>Bias: 1.9188", "Token: 69 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 69<br>Probability: 0.6992<br>Alibi: 0.0<br>Attention: 0.9873<br>Bias: 1.9188", "Token: 70 ( conduct)<br>Attend to token: 0 (By)<br>Tokens in past: 70<br>Probability: 0.7210<br>Alibi: 0.0<br>Attention: 1.1844<br>Bias: 1.9188", "Token: 71 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 71<br>Probability: 0.7708<br>Alibi: 0.0<br>Attention: 0.6469<br>Bias: 1.9188", "Token: 72 ( assessment)<br>Attend to token: 0 (By)<br>Tokens in past: 72<br>Probability: 0.9059<br>Alibi: 0.0<br>Attention: 1.2722<br>Bias: 1.9188", "Token: 73 ( in)<br>Attend to token: 0 (By)<br>Tokens in past: 73<br>Probability: 0.7393<br>Alibi: 0.0<br>Attention: 0.5410<br>Bias: 1.9188", "Token: 74 ( our)<br>Attend to token: 0 (By)<br>Tokens in past: 74<br>Probability: 0.7836<br>Alibi: 0.0<br>Attention: 0.7972<br>Bias: 1.9188", "Token: 75 ( area)<br>Attend to token: 0 (By)<br>Tokens in past: 75<br>Probability: 0.8256<br>Alibi: 0.0<br>Attention: 1.1839<br>Bias: 1.9188", "Token: 76 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 76<br>Probability: 0.8244<br>Alibi: 0.0<br>Attention: 1.3185<br>Bias: 1.9188", "Token: 77 ( intervention)<br>Attend to token: 0 (By)<br>Tokens in past: 77<br>Probability: 0.8441<br>Alibi: 0.0<br>Attention: 1.3565<br>Bias: 1.9188", "Token: 78 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 78<br>Probability: 0.7787<br>Alibi: 0.0<br>Attention: 0.5891<br>Bias: 1.9188", "Token: 79 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 79<br>Probability: 0.8423<br>Alibi: 0.0<br>Attention: 1.0265<br>Bias: 1.9188", "Token: 80 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 80<br>Probability: 0.5627<br>Alibi: 0.0<br>Attention: 0.1593<br>Bias: 1.9188", "Token: 81 ( the)<br>Attend to token: 0 (By)<br>Tokens in past: 81<br>Probability: 0.6714<br>Alibi: 0.0<br>Attention: 0.5500<br>Bias: 1.9188", "Token: 82 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 82<br>Probability: 0.8485<br>Alibi: 0.0<br>Attention: 0.7505<br>Bias: 1.9188", "Token: 83 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 83<br>Probability: 0.8237<br>Alibi: 0.0<br>Attention: 0.9757<br>Bias: 1.9188", "Token: 84 ( economic)<br>Attend to token: 0 (By)<br>Tokens in past: 84<br>Probability: 0.8614<br>Alibi: 0.0<br>Attention: 0.7463<br>Bias: 1.9188", "Token: 85 ( needs)<br>Attend to token: 0 (By)<br>Tokens in past: 85<br>Probability: 0.8138<br>Alibi: 0.0<br>Attention: 0.7085<br>Bias: 1.9188", "Token: 86 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 86<br>Probability: 0.7349<br>Alibi: 0.0<br>Attention: 0.5592<br>Bias: 1.9188", "Token: 87 ( educate)<br>Attend to token: 0 (By)<br>Tokens in past: 87<br>Probability: 0.7960<br>Alibi: 0.0<br>Attention: 1.2216<br>Bias: 1.9188", "Token: 88 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 88<br>Probability: 0.7803<br>Alibi: 0.0<br>Attention: 0.7600<br>Bias: 1.9188", "Token: 89 ( encourage)<br>Attend to token: 0 (By)<br>Tokens in past: 89<br>Probability: 0.7906<br>Alibi: 0.0<br>Attention: 1.0632<br>Bias: 1.9188", "Token: 90 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 90<br>Probability: 0.6466<br>Alibi: 0.0<br>Attention: 0.8157<br>Bias: 1.9188", "Token: 91 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 91<br>Probability: 0.7815<br>Alibi: 0.0<br>Attention: 1.0646<br>Bias: 1.9188", "Token: 92 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 92<br>Probability: 0.7691<br>Alibi: 0.0<br>Attention: 0.9008<br>Bias: 1.9188", "Token: 93 ( preventive)<br>Attend to token: 0 (By)<br>Tokens in past: 93<br>Probability: 0.8566<br>Alibi: 0.0<br>Attention: 1.2959<br>Bias: 1.9188", "Token: 94 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 94<br>Probability: 0.5694<br>Alibi: 0.0<br>Attention: 0.1078<br>Bias: 1.9188", "Token: 95 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 95<br>Probability: 0.7598<br>Alibi: 0.0<br>Attention: 0.9971<br>Bias: 1.9188", "Token: 96 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 96<br>Probability: 0.7868<br>Alibi: 0.0<br>Attention: 0.9539<br>Bias: 1.9188", "Token: 97 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 97<br>Probability: 0.5996<br>Alibi: 0.0<br>Attention: 1.0209<br>Bias: 1.9188", "Token: 98 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 98<br>Probability: 0.8167<br>Alibi: 0.0<br>Attention: 1.0576<br>Bias: 1.9188", "Token: 99 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 99<br>Probability: 0.7973<br>Alibi: 0.0<br>Attention: 1.3804<br>Bias: 1.9188", "Token: 100 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 100<br>Probability: 0.7633<br>Alibi: 0.0<br>Attention: 0.8157<br>Bias: 1.9188", "Token: 101 ( prenatal)<br>Attend to token: 0 (By)<br>Tokens in past: 101<br>Probability: 0.8416<br>Alibi: 0.0<br>Attention: 1.3265<br>Bias: 1.9188", "Token: 102 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 102<br>Probability: 0.8713<br>Alibi: 0.0<br>Attention: 1.5137<br>Bias: 1.9188", "Token: 103 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 103<br>Probability: 0.7379<br>Alibi: 0.0<br>Attention: 0.8240<br>Bias: 1.9188", "Token: 104 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 104<br>Probability: 0.7708<br>Alibi: 0.0<br>Attention: 0.9150<br>Bias: 1.9188", "Token: 105 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 105<br>Probability: 0.8455<br>Alibi: 0.0<br>Attention: 0.7830<br>Bias: 1.9188", "Token: 106 ( maintenance)<br>Attend to token: 0 (By)<br>Tokens in past: 106<br>Probability: 0.8666<br>Alibi: 0.0<br>Attention: 0.9851<br>Bias: 1.9188", "Token: 107 ( for)<br>Attend to token: 0 (By)<br>Tokens in past: 107<br>Probability: 0.8510<br>Alibi: 0.0<br>Attention: 0.9031<br>Bias: 1.9188", "Token: 108 ( chronic)<br>Attend to token: 0 (By)<br>Tokens in past: 108<br>Probability: 0.8929<br>Alibi: 0.0<br>Attention: 1.0883<br>Bias: 1.9188", "Token: 109 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 109<br>Probability: 0.6658<br>Alibi: 0.0<br>Attention: 0.4155<br>Bias: 1.9188", "Token: 110 ( diseases)<br>Attend to token: 0 (By)<br>Tokens in past: 110<br>Probability: 0.8774<br>Alibi: 0.0<br>Attention: 1.3520<br>Bias: 1.9188", "Token: 111 (..)<br>Attend to token: 0 (By)<br>Tokens in past: 111<br>Probability: 0.6618<br>Alibi: 0.0<br>Attention: 0.8633<br>Bias: 1.9188", "Token: 112 ( The)<br>Attend to token: 0 (By)<br>Tokens in past: 112<br>Probability: 0.5937<br>Alibi: 0.0<br>Attention: 0.3978<br>Bias: 1.9188", "Token: 113 ( health)<br>Attend to token: 0 (By)<br>Tokens in past: 113<br>Probability: 0.8004<br>Alibi: 0.0<br>Attention: 0.8858<br>Bias: 1.9188", "Token: 114 ( agents)<br>Attend to token: 0 (By)<br>Tokens in past: 114<br>Probability: 0.7932<br>Alibi: 0.0<br>Attention: 1.4176<br>Bias: 1.9188", "Token: 115 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 115<br>Probability: 0.7777<br>Alibi: 0.0<br>Attention: 1.2798<br>Bias: 1.9188", "Token: 116 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 116<br>Probability: 0.5841<br>Alibi: 0.0<br>Attention: 1.5898<br>Bias: 1.9188", "Token: 117 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 117<br>Probability: 0.7827<br>Alibi: 0.0<br>Attention: 1.2517<br>Bias: 1.9188", "Token: 118 ( pregnant)<br>Attend to token: 0 (By)<br>Tokens in past: 118<br>Probability: 0.8071<br>Alibi: 0.0<br>Attention: 1.1909<br>Bias: 1.9188", "Token: 119 ( women)<br>Attend to token: 0 (By)<br>Tokens in past: 119<br>Probability: 0.8678<br>Alibi: 0.0<br>Attention: 1.6526<br>Bias: 1.9188", "Token: 120 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 120<br>Probability: 0.7907<br>Alibi: 0.0<br>Attention: 0.7407<br>Bias: 1.9188", "Token: 121 ( newborn)<br>Attend to token: 0 (By)<br>Tokens in past: 121<br>Probability: 0.9261<br>Alibi: 0.0<br>Attention: 1.9861<br>Bias: 1.9188", "Token: 122 (s)<br>Attend to token: 0 (By)<br>Tokens in past: 122<br>Probability: 0.8710<br>Alibi: 0.0<br>Attention: 1.5501<br>Bias: 1.9188", "Token: 123 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 123<br>Probability: 0.7916<br>Alibi: 0.0<br>Attention: 0.7717<br>Bias: 1.9188", "Token: 124 ( infants)<br>Attend to token: 0 (By)<br>Tokens in past: 124<br>Probability: 0.8891<br>Alibi: 0.0<br>Attention: 1.5417<br>Bias: 1.9188", "Token: 125 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 125<br>Probability: 0.8183<br>Alibi: 0.0<br>Attention: 0.9454<br>Bias: 1.9188", "Token: 126 ( high)<br>Attend to token: 0 (By)<br>Tokens in past: 126<br>Probability: 0.8291<br>Alibi: 0.0<br>Attention: 0.9856<br>Bias: 1.9188", "Token: 127 ( risk)<br>Attend to token: 0 (By)<br>Tokens in past: 127<br>Probability: 0.8205<br>Alibi: 0.0<br>Attention: 1.3128<br>Bias: 1.9188", "Token: 128 ( of)<br>Attend to token: 0 (By)<br>Tokens in past: 128<br>Probability: 0.8855<br>Alibi: 0.0<br>Attention: 1.5005<br>Bias: 1.9188", "Token: 129 ( malnutrition)<br>Attend to token: 0 (By)<br>Tokens in past: 129<br>Probability: 0.8067<br>Alibi: 0.0<br>Attention: 1.1100<br>Bias: 1.9188", "Token: 130 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 130<br>Probability: 0.8037<br>Alibi: 0.0<br>Attention: 0.9116<br>Bias: 1.9188", "Token: 131 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 131<br>Probability: 0.6678<br>Alibi: 0.0<br>Attention: 1.0247<br>Bias: 1.9188", "Token: 132 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 132<br>Probability: 0.7667<br>Alibi: 0.0<br>Attention: 1.3626<br>Bias: 1.9188", "Token: 133 ( obtain)<br>Attend to token: 0 (By)<br>Tokens in past: 133<br>Probability: 0.7281<br>Alibi: 0.0<br>Attention: 0.7253<br>Bias: 1.9188", "Token: 134 ( proper)<br>Attend to token: 0 (By)<br>Tokens in past: 134<br>Probability: 0.8213<br>Alibi: 0.0<br>Attention: 1.3738<br>Bias: 1.9188", "Token: 135 ( care)<br>Attend to token: 0 (By)<br>Tokens in past: 135<br>Probability: 0.8263<br>Alibi: 0.0<br>Attention: 1.6257<br>Bias: 1.9188", "Token: 136 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 136<br>Probability: 0.7246<br>Alibi: 0.0<br>Attention: 0.6681<br>Bias: 1.9188", "Token: 137 ( vaccination)<br>Attend to token: 0 (By)<br>Tokens in past: 137<br>Probability: 0.8103<br>Alibi: 0.0<br>Attention: 1.5102<br>Bias: 1.9188", "Token: 138 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 138<br>Probability: 0.7680<br>Alibi: 0.0<br>Attention: 1.0309<br>Bias: 1.9188", "Token: 139 ( food)<br>Attend to token: 0 (By)<br>Tokens in past: 139<br>Probability: 0.9101<br>Alibi: 0.0<br>Attention: 1.9159<br>Bias: 1.9188", "Token: 140 ( assistance)<br>Attend to token: 0 (By)<br>Tokens in past: 140<br>Probability: 0.8807<br>Alibi: 0.0<br>Attention: 1.4177<br>Bias: 1.9188", "Token: 141 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 141<br>Probability: 0.7271<br>Alibi: 0.0<br>Attention: 1.1643<br>Bias: 1.9188", "Token: 142 ( etc)<br>Attend to token: 0 (By)<br>Tokens in past: 142<br>Probability: 0.7149<br>Alibi: 0.0<br>Attention: 1.6521<br>Bias: 1.9188", "Token: 143 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 143<br>Probability: 0.6638<br>Alibi: 0.0<br>Attention: 0.9898<br>Bias: 1.9188", "Token: 144 ( They)<br>Attend to token: 0 (By)<br>Tokens in past: 144<br>Probability: 0.5490<br>Alibi: 0.0<br>Attention: 1.3904<br>Bias: 1.9188", "Token: 145 ( will)<br>Attend to token: 0 (By)<br>Tokens in past: 145<br>Probability: 0.7071<br>Alibi: 0.0<br>Attention: 1.5714<br>Bias: 1.9188", "Token: 146 ( also)<br>Attend to token: 0 (By)<br>Tokens in past: 146<br>Probability: 0.5444<br>Alibi: 0.0<br>Attention: 1.7886<br>Bias: 1.9188", "Token: 147 ( identify)<br>Attend to token: 0 (By)<br>Tokens in past: 147<br>Probability: 0.8042<br>Alibi: 0.0<br>Attention: 1.5078<br>Bias: 1.9188", "Token: 148 ( people)<br>Attend to token: 0 (By)<br>Tokens in past: 148<br>Probability: 0.6723<br>Alibi: 0.0<br>Attention: 1.4703<br>Bias: 1.9188", "Token: 149 ( with)<br>Attend to token: 0 (By)<br>Tokens in past: 149<br>Probability: 0.7954<br>Alibi: 0.0<br>Attention: 1.4467<br>Bias: 1.9188", "Token: 150 ( certain)<br>Attend to token: 0 (By)<br>Tokens in past: 150<br>Probability: 0.7713<br>Alibi: 0.0<br>Attention: 1.5997<br>Bias: 1.9188", "Token: 151 ( conditions)<br>Attend to token: 0 (By)<br>Tokens in past: 151<br>Probability: 0.8563<br>Alibi: 0.0<br>Attention: 1.7011<br>Bias: 1.9188", "Token: 152 ( such)<br>Attend to token: 0 (By)<br>Tokens in past: 152<br>Probability: 0.5286<br>Alibi: 0.0<br>Attention: 1.6593<br>Bias: 1.9188", "Token: 153 ( as)<br>Attend to token: 0 (By)<br>Tokens in past: 153<br>Probability: 0.8182<br>Alibi: 0.0<br>Attention: 1.9204<br>Bias: 1.9188", "Token: 154 ( HIV)<br>Attend to token: 0 (By)<br>Tokens in past: 154<br>Probability: 0.8108<br>Alibi: 0.0<br>Attention: 1.2841<br>Bias: 1.9188", "Token: 155 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 155<br>Probability: 0.8254<br>Alibi: 0.0<br>Attention: 1.1183<br>Bias: 1.9188", "Token: 156 ( Tu)<br>Attend to token: 0 (By)<br>Tokens in past: 156<br>Probability: 0.8225<br>Alibi: 0.0<br>Attention: 0.9468<br>Bias: 1.9188", "Token: 157 (ber)<br>Attend to token: 0 (By)<br>Tokens in past: 157<br>Probability: 0.9353<br>Alibi: 0.0<br>Attention: 1.8964<br>Bias: 1.9188", "Token: 158 (culosis)<br>Attend to token: 0 (By)<br>Tokens in past: 158<br>Probability: 0.8887<br>Alibi: 0.0<br>Attention: 1.4381<br>Bias: 1.9188", "Token: 159 (,)<br>Attend to token: 0 (By)<br>Tokens in past: 159<br>Probability: 0.8021<br>Alibi: 0.0<br>Attention: 1.3309<br>Bias: 1.9188", "Token: 160 ( and)<br>Attend to token: 0 (By)<br>Tokens in past: 160<br>Probability: 0.7670<br>Alibi: 0.0<br>Attention: 1.3540<br>Bias: 1.9188", "Token: 161 ( Mal)<br>Attend to token: 0 (By)<br>Tokens in past: 161<br>Probability: 0.8727<br>Alibi: 0.0<br>Attention: 1.4641<br>Bias: 1.9188", "Token: 162 (aria)<br>Attend to token: 0 (By)<br>Tokens in past: 162<br>Probability: 0.8849<br>Alibi: 0.0<br>Attention: 1.4747<br>Bias: 1.9188", "Token: 163 ( to)<br>Attend to token: 0 (By)<br>Tokens in past: 163<br>Probability: 0.7922<br>Alibi: 0.0<br>Attention: 1.6600<br>Bias: 1.9188", "Token: 164 ( help)<br>Attend to token: 0 (By)<br>Tokens in past: 164<br>Probability: 0.7066<br>Alibi: 0.0<br>Attention: 1.5953<br>Bias: 1.9188", "Token: 165 ( them)<br>Attend to token: 0 (By)<br>Tokens in past: 165<br>Probability: 0.7777<br>Alibi: 0.0<br>Attention: 1.9481<br>Bias: 1.9188", "Token: 166 ( access)<br>Attend to token: 0 (By)<br>Tokens in past: 166<br>Probability: 0.7641<br>Alibi: 0.0<br>Attention: 1.2358<br>Bias: 1.9188", "Token: 167 ( available)<br>Attend to token: 0 (By)<br>Tokens in past: 167<br>Probability: 0.7556<br>Alibi: 0.0<br>Attention: 1.5529<br>Bias: 1.9188", "Token: 168 ( services)<br>Attend to token: 0 (By)<br>Tokens in past: 168<br>Probability: 0.8861<br>Alibi: 0.0<br>Attention: 1.8737<br>Bias: 1.9188", "Token: 169 (.)<br>Attend to token: 0 (By)<br>Tokens in past: 169<br>Probability: 0.5559<br>Alibi: 0.0<br>Attention: 0.7671<br>Bias: 1.9188"], "legendgroup": "0", "marker": {"color": [1.0, 0.9546557068824768, 0.9412956833839417, 0.9612320065498352, 0.9293265342712402, 0.9031228423118591, 0.8640854358673096, 0.8559137582778931, 0.8944182395935059, 0.9205316305160522, 0.902733325958252, 0.9240947961807251, 0.9204094409942627, 0.8999044895172119, 0.9487847089767456, 0.9545228481292725, 0.9205044507980347, 0.8144064545631409, 0.8697918057441711, 0.8432674407958984, 0.9016883969306946, 0.8512725234031677, 0.9150063395500183, 0.8365470170974731, 0.8126537203788757, 0.8701916933059692, 0.7087554335594177, 0.7437227964401245, 0.6963450312614441, 0.7850419282913208, 0.9032872319221497, 0.8805475234985352, 0.765149712562561, 0.840114414691925, 0.8347086310386658, 0.7476456761360168, 0.7872797846794128, 0.9097477197647095, 0.80640709400177, 0.885391116142273, 0.9046065211296082, 0.8792465329170227, 0.8779659867286682, 0.8733382821083069, 0.8116514086723328, 0.8329271674156189, 0.8683161735534668, 0.6298651099205017, 0.8671953678131104, 0.92787766456604, 0.8139632940292358, 0.6895973086357117, 0.7614144682884216, 0.7789911031723022, 0.8050631284713745, 0.6881222128868103, 0.7984384298324585, 0.870759129524231, 0.9134842753410339, 0.8431828618049622, 0.9077891707420349, 0.9400020837783813, 0.5848674178123474, 0.7227419018745422, 0.741638720035553, 0.8591163754463196, 0.7184037566184998, 0.835414707660675, 0.8392407298088074, 0.6992419958114624, 0.7209744453430176, 0.7707938551902771, 0.9059234261512756, 0.7392844557762146, 0.7835957407951355, 0.8255636096000671, 0.8244020342826843, 0.8441261053085327, 0.7787261605262756, 0.8422549366950989, 0.5626562237739563, 0.6713548898696899, 0.8484621644020081, 0.8236545324325562, 0.8614089488983154, 0.8138107657432556, 0.7349275350570679, 0.796008825302124, 0.7803134322166443, 0.790641188621521, 0.6466012597084045, 0.7814634442329407, 0.7691000699996948, 0.8565648794174194, 0.569429874420166, 0.7597991228103638, 0.7868024706840515, 0.5996113419532776, 0.8167045712471008, 0.7972521185874939, 0.7632958292961121, 0.8415544629096985, 0.8712774515151978, 0.737881064414978, 0.7707890868186951, 0.8454992175102234, 0.8665937185287476, 0.8509937524795532, 0.8929132223129272, 0.6658150553703308, 0.8773826360702515, 0.6617562174797058, 0.5937324166297913, 0.8004193305969238, 0.7931832671165466, 0.7777310013771057, 0.5840631723403931, 0.782721757888794, 0.8070876002311707, 0.8677845597267151, 0.7906960844993591, 0.926132321357727, 0.8710001707077026, 0.7916240096092224, 0.8890833258628845, 0.8182886838912964, 0.8290876150131226, 0.8204977512359619, 0.8854773044586182, 0.806670606136322, 0.8036532402038574, 0.6678304672241211, 0.7666605114936829, 0.7280884981155396, 0.8212965726852417, 0.826339602470398, 0.7246100902557373, 0.8102955222129822, 0.7680224776268005, 0.9100890159606934, 0.8806841373443604, 0.7271040081977844, 0.7148874402046204, 0.6638155579566956, 0.5490057468414307, 0.7071036696434021, 0.5443751215934753, 0.8041638135910034, 0.6723001003265381, 0.7954238653182983, 0.7712970972061157, 0.8563205599784851, 0.5286310315132141, 0.8182147741317749, 0.8107679486274719, 0.8253920674324036, 0.8224709033966064, 0.9352661371231079, 0.8886587619781494, 0.8021246194839478, 0.7669548392295837, 0.8726583123207092, 0.8848819732666016, 0.7921918034553528, 0.7065954208374023, 0.7776716947555542, 0.7641330361366272, 0.7556418180465698, 0.8860510587692261, 0.5559194684028625], "coloraxis": "coloraxis", "opacity": 0.5, "symbol": "circle"}, "mode": "markers", "name": "0", "showlegend": true, "subplot": "ternary", "type": "scatterternary"}], "layout": {"coloraxis": {"colorbar": {"title": {"text": "prob"}}, "colorscale": [[0.0, "rgb(0,0,255)"], [1.0, "rgb(255,0,0)"]]}, "legend": {"orientation": "h", "title": {"text": "sort_idx"}, "tracegroupgap": 0}, "margin": {"t": 60}, "template": {"data": {"candlestick": [{"decreasing": {"line": {"color": "#ff2b2b"}}, "increasing": {"line": {"color": "#29b09d"}}, "type": "candlestick"}], "contourcarpet": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contourcarpet"}], "contour": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "contour"}], "heatmap": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "heatmap"}], "histogram2d": [{"colorscale": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "type": "histogram2d"}], "icicle": [{"textfont": {"color": "white"}, "type": "icicle"}], "sankey": [{"textfont": {"color": "#808495"}, "type": "sankey"}], "scatter": [{"marker": {"line": {"width": 0}}, "type": "scatter"}], "table": [{"cells": {"fill": {"color": "#ffffff"}, "font": {"color": "#262730"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "header": {"fill": {"color": "rgba(248, 249, 251, 1)"}, "font": {"color": "#808495"}, "line": {"color": "rgba(49, 51, 63, 0.1)"}}, "type": "table"}], "waterfall": [{"connector": {"line": {"color": "#808495", "width": 2}}, "decreasing": {"marker": {"color": "#ff2b2b"}}, "increasing": {"marker": {"color": "#29b09d"}}, "totals": {"marker": {"color": "#0068c9"}}, "type": "waterfall"}]}, "layout": {"coloraxis": {"colorbar": {"len": 0.75, "outlinecolor": "rgba(0,0,0,0)", "outlinewidth": 8, "thickness": 16, "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}}, "xpad": 24, "y": 0.5745}}, "colorscale": {"diverging": [[0.0, "#7d353b"], [0.1, "#bd4043"], [0.2, "#ff4b4b"], [0.3, "#ff8c8c"], [0.4, "#ffc7c7"], [0.5, "#a6dcff"], [0.6, "#60b4ff"], [0.7, "#1c83e1"], [0.8, "#0054a3"], [0.9, "#004280"], [1.0, "#000031"]], "sequential": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]], "sequentialminus": [[0.0, "#e4f5ff"], [0.1111111111111111, "#c7ebff"], [0.2222222222222222, "#a6dcff"], [0.3333333333333333, "#83c9ff"], [0.4444444444444444, "#60b4ff"], [0.5555555555555556, "#3d9df3"], [0.6666666666666666, "#1c83e1"], [0.7777777777777778, "#0068c9"], [0.8888888888888888, "#0054a3"], [1.0, "#004280"]]}, "colorway": ["#0068c9", "#83c9ff", "#ff2b2b", "#ffabab", "#29b09d", "#7defa1", "#ff8700", "#ffd16a", "#6d3fc0", "#d5dae5"], "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}, "hoverlabel": {"bgcolor": "#ffffff", "bordercolor": "rgba(49, 51, 63, 0.2)", "font": {"color": "#808495", "family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "legend": {"bordercolor": "rgba(0,0,0,0)", "borderwidth": 0, "font": {"color": "#262730", "size": 12}, "title": {"font": {"color": "#808495", "size": 12}, "side": "top"}, "valign": "top"}, "margin": {"l": 0, "pad": 8, "r": 0}, "paper_bgcolor": "#ffffff", "plot_bgcolor": "#ffffff", "ternary": {"aaxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "baxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}, "bgcolor": "#ffffff", "caxis": {"gridcolor": "#808495", "linecolor": "#808495", "tickfont": {"family": "\"Source Sans Pro\", sans-serif", "size": 12}}}, "title": {"font": {"color": "#31333F", "family": "\"Source Sans Pro\", sans-serif", "size": 16}, "pad": {"l": 4}, "x": 0, "xanchor": "left"}, "xaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "rangeselector": {"bgcolor": "#ffffff", "bordercolor": "#e6eaf1", "borderwidth": 1, "x": 0}, "showgrid": false, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "title": {"font": {"color": "#808495", "size": 14}, "standoff": 20}, "zeroline": false, "zerolinecolor": "#e6eaf1"}, "yaxis": {"automargin": true, "gridcolor": "#e6eaf1", "minor": {"gridcolor": "#e6eaf1"}, "tickcolor": "#e6eaf1", "tickfont": {"color": "#808495", "size": 12}, "ticklabelposition": "outside", "title": {"font": {"color": "#808495", "size": 14}, "standoff": 24}, "zerolinecolor": "#e6eaf1"}}}, "ternary": {"aaxis": {"title": {"text": "attention"}}, "baxis": {"title": {"text": "bias"}}, "caxis": {"title": {"text": "alibi"}}, "domain": {"x": [0.0, 1.0], "y": [0.0, 1.0]}}, "title": {"text": "Attention Breakdown (Layer 4, Head 22)"}}, "metadata": {"sentence_id": 0, "layer_id": 4, "head_id": 22, "accounted_probability": 0.5, "max_tokens_per_row": 11, "creation_date": "2025-01-22 23:46:31.779008", "page": {"page_script_hash": "a81f7f5ae171c15a95155bca2157e9b6", "page_name": "ATTN_-_Attention_Focus", "icon": "", "script_path": "/workspaces/llm-research/app/pages/301_ATTN - Attention Focus.py"}}}